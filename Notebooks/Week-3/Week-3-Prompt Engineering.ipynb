{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "656cfedc-d075-4e57-903e-5b3a996a4e9f",
   "metadata": {},
   "source": [
    "# Week 3: Prompt Engineering Best Practices\n",
    "\n",
    "- Topics: Advanced prompt engineering techniques, designing effective prompts, common pitfalls, and improvement strategies.\n",
    "- Hands-on: Experimenting with prompts to achieve desired responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5153a9c-e8a8-430d-95c5-3b044e1adc66",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In recent years, **prompt engineering** has emerged as a key process in the effective use of large language models. As Phoenix and Taylor (2024) describe it:\n",
    "\n",
    "> \"Prompt engineering is the process of discovering prompts that reliably yield useful or desired results.\"\n",
    "\n",
    "This iterative approach focuses on refining prompts to optimize interactions with generative AI systems, achieving consistent and meaningful outputs (Phoenix and Taylor, 2024).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f77b9a-0519-4fea-89da-46865834283f",
   "metadata": {},
   "source": [
    "## Definitions of Prompt Engineering\n",
    "\n",
    "To gain a comprehensive understanding of prompt engineering, here are several authoritative definitions from recent literature:\n",
    "\n",
    "- **Phoenix and Taylor (2024):**\n",
    "  \n",
    "  \"Prompt engineering is the process of discovering prompts that reliably yield useful or desired results.\"\n",
    "  \n",
    "  *(Phoenix and Taylor, 2024)*\n",
    "\n",
    "- **Liu et al. (2023):**\n",
    "\n",
    "  \"Prompt engineering involves crafting input prompts that guide pre-trained language models to produce desired outputs, effectively leveraging their knowledge without the need for fine-tuning.\"\n",
    "\n",
    "  *(Liu et al., 2023)*\n",
    "\n",
    "- **Brown et al. (2020):**\n",
    "\n",
    "  \"Prompt engineering is the process of designing task-specific prompts to elicit desired behavior from language models, enabling them to perform a wide range of tasks without explicit training.\"\n",
    "\n",
    "  *(Brown et al., 2020)*\n",
    "\n",
    "- **Reynolds and McDonell (2021):**\n",
    "\n",
    "  \"Prompt engineering is the art of designing prompts that effectively communicate the user's intent to a language model, facilitating accurate and relevant responses.\"\n",
    "\n",
    "  *(Reynolds and McDonell, 2021)*\n",
    "\n",
    "- **White et al. (2023):**\n",
    "\n",
    "  \"Prompt engineering is a methodology for structuring inputs to large language models to achieve desired outcomes, often involving iterative refinement and understanding of model behavior.\"\n",
    "\n",
    "  *(White et al., 2023)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4186b421-18d6-4e04-8bc5-2a8d961c0d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from anthropic import Anthropic \n",
    "from dotenv import load_dotenv\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Function to load environment variables or raise an error if not found\n",
    "def get_env_var(var: str):\n",
    "    value = os.getenv(var)\n",
    "    if value is None:\n",
    "        raise ValueError(f\"{var} not found in environment variables. Make sure it is set in your .env file.\")\n",
    "    return value\n",
    "\n",
    "# Load API keys from the environment\n",
    "langchain_api_key = get_env_var(\"LANGCHAIN_API_KEY\")\n",
    "langchain_tracing_v2 = get_env_var(\"LANGCHAIN_TRACING_V2\")\n",
    "openai_api_key = get_env_var(\"OPENAI_API_KEY\")\n",
    "tavily_api_key = get_env_var(\"TAVILY_API_KEY\")\n",
    "anthropic_api_key = get_env_var(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "# Set up OpenAI models\n",
    "from langchain_openai import ChatOpenAI\n",
    "gpt4o_chat = ChatOpenAI(model=\"gpt-4o\", temperature=0, openai_api_key=openai_api_key)\n",
    "gpt35_chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0, openai_api_key=openai_api_key)\n",
    "\n",
    "# Direct Anthropic client\n",
    "claude = Anthropic(api_key=anthropic_api_key)\n",
    "\n",
    "# LangChain integration\n",
    "claude_chat = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\", temperature=0, anthropic_api_key=anthropic_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6685adb3-bf1b-4c43-8d77-e87154ad97e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "694abf57-858e-4128-943c-f8e57efd3278",
   "metadata": {},
   "source": [
    "## We can then use Claude in two ways:\n",
    "\n",
    "1. Direct Anthropic client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68846d11-6650-4026-9d0d-3988c0bb997e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TextBlock(text='Hello! How can I assist you today? Feel free to ask me any questions or let me know if you need help with anything.', type='text')]\n"
     ]
    }
   ],
   "source": [
    "response = claude.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20240620\",  # Using base model identifier\n",
    "    max_tokens=1024,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello!\"}]\n",
    ")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d664bd0-c2e6-4cff-8b23-3ae9d7077512",
   "metadata": {},
   "source": [
    "2. LangChain integration (similar to how we're using OpenAI):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7983bfc1-2254-4757-aebc-c2613423cc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today? Feel free to ask me any questions or let me know if you need help with anything.\n"
     ]
    }
   ],
   "source": [
    "response = claude_chat.invoke(\"Hello!\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926b40e6-bacf-4980-a81d-4fe37fc2d4bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31494d1-2f67-4833-92f0-5988d8e7f771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_responses(prompt: str, include_claude=True, include_gpt4=True, include_gpt35=True):\n",
    "    \"\"\"\n",
    "    Compare responses from different models for the same prompt.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    if include_claude:\n",
    "        claude_response = claude_chat.invoke(prompt)\n",
    "        results[\"Claude-3.5-Sonnet\"] = claude_response.content\n",
    "\n",
    "    if include_gpt4:\n",
    "        gpt4_response = gpt4o_chat.invoke(prompt)\n",
    "        results[\"GPT-4o\"] = gpt4_response.content\n",
    "\n",
    "    if include_gpt35:\n",
    "        gpt35_response = gpt35_chat.invoke(prompt)\n",
    "        results[\"GPT-3.5\"] = gpt35_response.content\n",
    "\n",
    "    # Print results in a formatted way\n",
    "    print(f\"\\nPrompt: {prompt}\\n\")\n",
    "    print(\"-\" * 80)\n",
    "    for model, response in results.items():\n",
    "        print(f\"\\n{model}:\\n\")\n",
    "        print(response)\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "# Let's test with some example prompts\n",
    "test_prompts = [\n",
    "    \"Generate a list of creative product names for a new eco-friendly cleaning brand.\"\n",
    "]\n",
    "\n",
    "# Run comparisons for each prompt\n",
    "for prompt in test_prompts:\n",
    "    compare_responses(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51025b7f-360e-4a56-a622-f9e5a0f1203f",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Phoenix, J., and Taylor, M. 2024. *Prompt Engineering for Generative AI*. Sebastopol, CA: Saxifrage, LLC, Just Understanding Data LTD, & O'Reilly Media, Inc. Available at: [O'Reilly Media](https://www.oreilly.com/library/view/prompt-engineering-for/9781098153427/)\n",
    "\n",
    "- Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., et al. 2020. Language Models are Few-Shot Learners. In *Advances in Neural Information Processing Systems*, 33, 1877–1901. Available at: [NeurIPS Proceedings](https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf)\n",
    "\n",
    "- Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., and Neubig, G. 2023. Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing. *Trans. Assoc. Comput. Linguistics*. 11, 630–676. Available at: [ACL Anthology](https://aclanthology.org/2023.tacl-1.88.pdf)\n",
    "\n",
    "- Reynolds, L., and McDonell, K. 2021. Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm. *arXiv preprint arXiv:2102.07350*. Available at: [arXiv](https://arxiv.org/abs/2102.07350)\n",
    "\n",
    "- White, J., Narayanan, A., Chiu, S., Huang, Y., and Schmidt, D. 2023. A Comprehensive Survey on Prompt Engineering for Large Language Models. *arXiv preprint arXiv:2302.07842*. Available at: [arXiv](https://arxiv.org/abs/2302.07842)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fc88e3-566e-462d-a664-e0c31582ee62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
