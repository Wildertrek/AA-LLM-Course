{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "656cfedc-d075-4e57-903e-5b3a996a4e9f",
   "metadata": {},
   "source": [
    "# Week 3: Prompt Engineering Best Practices\n",
    "\n",
    "- Topics: Advanced prompt engineering techniques, designing effective prompts, common pitfalls, and improvement strategies.\n",
    "- Hands-on: Experimenting with prompts to achieve desired responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5153a9c-e8a8-430d-95c5-3b044e1adc66",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In recent years, **prompt engineering** has emerged as a key process in the effective use of large language models. As Phoenix and Taylor (2024) describe it:\n",
    "\n",
    "> \"Prompt engineering is the process of discovering prompts that reliably yield useful or desired results.\"\n",
    "\n",
    "This iterative approach focuses on refining prompts to optimize interactions with generative AI systems, achieving consistent and meaningful outputs (Phoenix and Taylor, 2024).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f77b9a-0519-4fea-89da-46865834283f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Definitions of Prompt Engineering\n",
    "\n",
    "To gain a comprehensive understanding of prompt engineering, here are several authoritative definitions from recent literature:\n",
    "\n",
    "- **Phoenix and Taylor (2024):**\n",
    "  \n",
    "  \"Prompt engineering is the process of discovering prompts that reliably yield useful or desired results.\"\n",
    "  \n",
    "  *(Phoenix and Taylor, 2024)*\n",
    "\n",
    "- **Liu et al. (2023):**\n",
    "\n",
    "  \"Prompt engineering involves crafting input prompts that guide pre-trained language models to produce desired outputs, effectively leveraging their knowledge without the need for fine-tuning.\"\n",
    "\n",
    "  *(Liu et al., 2023)*\n",
    "\n",
    "- **Brown et al. (2020):**\n",
    "\n",
    "  \"Prompt engineering is the process of designing task-specific prompts to elicit desired behavior from language models, enabling them to perform a wide range of tasks without explicit training.\"\n",
    "\n",
    "  *(Brown et al., 2020)*\n",
    "\n",
    "- **Reynolds and McDonell (2021):**\n",
    "\n",
    "  \"Prompt engineering is the art of designing prompts that effectively communicate the user's intent to a language model, facilitating accurate and relevant responses.\"\n",
    "\n",
    "  *(Reynolds and McDonell, 2021)*\n",
    "\n",
    "- **White et al. (2023):**\n",
    "\n",
    "  \"Prompt engineering is a methodology for structuring inputs to large language models to achieve desired outcomes, often involving iterative refinement and understanding of model behavior.\"\n",
    "\n",
    "  *(White et al., 2023)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4186b421-18d6-4e04-8bc5-2a8d961c0d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from anthropic import Anthropic \n",
    "from dotenv import load_dotenv\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Function to load environment variables or raise an error if not found\n",
    "def get_env_var(var: str):\n",
    "    value = os.getenv(var)\n",
    "    if value is None:\n",
    "        raise ValueError(f\"{var} not found in environment variables. Make sure it is set in your .env file.\")\n",
    "    return value\n",
    "\n",
    "# Load API keys from the environment\n",
    "langchain_api_key = get_env_var(\"LANGCHAIN_API_KEY\")\n",
    "langchain_tracing_v2 = get_env_var(\"LANGCHAIN_TRACING_V2\")\n",
    "openai_api_key = get_env_var(\"OPENAI_API_KEY\")\n",
    "tavily_api_key = get_env_var(\"TAVILY_API_KEY\")\n",
    "anthropic_api_key = get_env_var(\"ANTHROPIC_API_KEY\")\n",
    "grok_api_key = get_env_var(\"GROK_API_KEY\")\n",
    "\n",
    "# Set up OpenAI models\n",
    "from langchain_openai import ChatOpenAI\n",
    "gpt4o_chat = ChatOpenAI(model=\"gpt-4o\", temperature=0, openai_api_key=openai_api_key)\n",
    "gpt35_chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0, openai_api_key=openai_api_key)\n",
    "\n",
    "# Direct Anthropic client\n",
    "claude = Anthropic(api_key=anthropic_api_key)\n",
    "\n",
    "# LangChain integration\n",
    "claude_chat = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\", temperature=0, anthropic_api_key=anthropic_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0ae54ef-cf6c-4112-9110-ee93c82b0335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: {'id': '8289e74c-f380-4bb8-a123-431990509628', 'object': 'chat.completion', 'created': 1731499306, 'model': 'grok-beta', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'The answer to life, the universe, and everything is **42**. However, this answer was famously provided by Deep Thought, the supercomputer from Douglas Adams\\' \"The Hitchhiker\\'s Guide to the Galaxy,\" and it\\'s meant to be humorous and thought-provoking rather than a literal solution. The real fun comes from pondering what the question might be, as the characters in the story realize they don\\'t actually know the ultimate question to which 42 is the answer. So, in a way, the search for meaning continues, both in the story and in our lives, often with a humorous twist.', 'refusal': None}, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 37, 'completion_tokens': 124, 'total_tokens': 161}, 'system_fingerprint': 'fp_14b89b2dfc'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Load the Grok API key from environment variables\n",
    "grok_api_key = os.getenv(\"GROK_API_KEY\")\n",
    "\n",
    "# Define the Grok API endpoint and headers\n",
    "url = \"https://api.x.ai/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {grok_api_key}\"\n",
    "}\n",
    "\n",
    "# Define the payload as shown in the example\n",
    "payload = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are Grok, a chatbot inspired by the Hitchhikers Guide to the Galaxy.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the answer to life and universe?\"\n",
    "        }\n",
    "    ],\n",
    "    \"model\": \"grok-beta\",\n",
    "    \"stream\": False,\n",
    "    \"temperature\": 0\n",
    "}\n",
    "\n",
    "# Send the request to the Grok API\n",
    "try:\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    response.raise_for_status()  # Raise an error if the request fails\n",
    "    print(\"Response:\", response.json())\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(\"Error:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694abf57-858e-4128-943c-f8e57efd3278",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## We can then use Claude in two ways:\n",
    "\n",
    "1. Direct Anthropic client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68846d11-6650-4026-9d0d-3988c0bb997e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TextBlock(text='Hello! How can I assist you today? Feel free to ask me any questions or let me know if you need help with anything.', type='text')]\n"
     ]
    }
   ],
   "source": [
    "response = claude.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20240620\",  # Using base model identifier\n",
    "    max_tokens=1024,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello!\"}]\n",
    ")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d664bd0-c2e6-4cff-8b23-3ae9d7077512",
   "metadata": {},
   "source": [
    "2. LangChain integration (similar to how we're using OpenAI):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7983bfc1-2254-4757-aebc-c2613423cc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today? Feel free to ask me any questions or let me know if you need help with anything.\n"
     ]
    }
   ],
   "source": [
    "response = claude_chat.invoke(\"Hello!\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926b40e6-bacf-4980-a81d-4fe37fc2d4bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f31494d1-2f67-4833-92f0-5988d8e7f771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: Generate a list of creative product names for a new eco-friendly cleaning brand.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Claude-3.5-Sonnet:\n",
      "\n",
      "Here's a list of creative product names for a new eco-friendly cleaning brand:\n",
      "\n",
      "1. GreenSweep\n",
      "2. EcoShine\n",
      "3. NatureBright\n",
      "4. PurifyEarth\n",
      "5. CleanCanvas\n",
      "6. BioBliss\n",
      "7. EcoGlow\n",
      "8. TerraSpark\n",
      "9. PristinePlanet\n",
      "10. VerdantVibe\n",
      "11. AquaPure\n",
      "12. EcoLuster\n",
      "13. GaiaGleam\n",
      "14. ZenClean\n",
      "15. EarthErase\n",
      "16. BotaniBlast\n",
      "17. CrystalClear\n",
      "18. HarmonyHouse\n",
      "19. NectarNeat\n",
      "20. OzoneOasis\n",
      "21. EcoEssence\n",
      "22. PurePolish\n",
      "23. GreenGuard\n",
      "24. BioBubble\n",
      "25. EarthEmber\n",
      "26. FreshFusion\n",
      "27. NatureNurture\n",
      "28. EcoElixir\n",
      "29. PurePixie\n",
      "30. TerraTidy\n",
      "31. AquaAura\n",
      "32. EcoEnergy\n",
      "33. GreenGenie\n",
      "34. BioBoost\n",
      "35. EarthEcho\n",
      "36. CleanConscious\n",
      "37. NaturalNimbus\n",
      "38. PurePetal\n",
      "39. EcoEden\n",
      "40. VitalVapor\n",
      "\n",
      "These names combine eco-friendly themes, natural elements, and cleaning concepts to create unique and memorable brand identities.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "GPT-4o:\n",
      "\n",
      "Creating a memorable and meaningful name for an eco-friendly cleaning brand can help convey the brand's commitment to sustainability and effectiveness. Here are some creative product name ideas:\n",
      "\n",
      "1. **GreenGleam**\n",
      "2. **EcoShine**\n",
      "3. **PureSpruce**\n",
      "4. **Nature's Cleanse**\n",
      "5. **EarthEssence**\n",
      "6. **FreshLeaf**\n",
      "7. **BioBrite**\n",
      "8. **EcoLuster**\n",
      "9. **SustainScrub**\n",
      "10. **VerdantVibe**\n",
      "11. **PlanetPolish**\n",
      "12. **GreenGlow**\n",
      "13. **EcoElixir**\n",
      "14. **NatureNurture**\n",
      "15. **PurelyGreen**\n",
      "16. **EcoEclipse**\n",
      "17. **CleanConscience**\n",
      "18. **EarthlyEssence**\n",
      "19. **BioBliss**\n",
      "20. **EcoRadiance**\n",
      "\n",
      "These names aim to reflect the brand's eco-friendly mission while also suggesting cleanliness and freshness.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "GPT-3.5:\n",
      "\n",
      "1. GreenGlow Clean\n",
      "2. EarthSweep\n",
      "3. EcoShine Solutions\n",
      "4. PureGreen Clean\n",
      "5. Nature's Touch Cleaning Co.\n",
      "6. CleanEarth Essentials\n",
      "7. GreenLeaf Cleaners\n",
      "8. EcoFresh Cleaning\n",
      "9. Earthly Clean Co.\n",
      "10. GreenWave Cleaning Solutions\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def compare_responses(prompt: str, include_claude=True, include_gpt4=True, include_gpt35=True):\n",
    "    \"\"\"\n",
    "    Compare responses from different models for the same prompt.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    if include_claude:\n",
    "        claude_response = claude_chat.invoke(prompt)\n",
    "        results[\"Claude-3.5-Sonnet\"] = claude_response.content\n",
    "\n",
    "    if include_gpt4:\n",
    "        gpt4_response = gpt4o_chat.invoke(prompt)\n",
    "        results[\"GPT-4o\"] = gpt4_response.content\n",
    "\n",
    "    if include_gpt35:\n",
    "        gpt35_response = gpt35_chat.invoke(prompt)\n",
    "        results[\"GPT-3.5\"] = gpt35_response.content\n",
    "\n",
    "    # Print results in a formatted way\n",
    "    print(f\"\\nPrompt: {prompt}\\n\")\n",
    "    print(\"-\" * 80)\n",
    "    for model, response in results.items():\n",
    "        print(f\"\\n{model}:\\n\")\n",
    "        print(response)\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "# Let's test with some example prompts\n",
    "test_prompts = [\n",
    "    \"Generate a list of creative product names for a new eco-friendly cleaning brand.\"\n",
    "]\n",
    "\n",
    "# Run comparisons for each prompt\n",
    "for prompt in test_prompts:\n",
    "    compare_responses(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaf5aa3-69d8-4ab7-beef-7d0b247af814",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Overview of the Five Principles to Improve the Prompt (Phoenix and Taylor, 2024)\n",
    "\n",
    "The Five Principles of Prompting are as follows:\n",
    "\n",
    "### Give Direction\n",
    "Describe the desired style in detail, or reference a relevant persona\n",
    "\n",
    "### Specify Format\n",
    "Define what rules to follow, and the required structure of the response\n",
    "\n",
    "### Provide Examples\n",
    "Insert a diverse set of test cases where the task was done correctly\n",
    "\n",
    "### Evaluate Quality\n",
    "Identify errors and rate responses, testing what drives performance.\n",
    "\n",
    "### Divide Labor\n",
    "Split tasks into multiple steps, chained together for complex goals\n",
    "\n",
    "These principles are not short-lived tips or hacks but are generally accepted conventions that are useful for working with any level of intelligence, biological or artificial. These principles are model-agnostic and should work to improve your prompt no matter which generative text or image model you’re using. We first published these principles in July 2022 in the blog post [“Prompt Engineering: From Words to Art and Copy”](https://oreil.ly/RYYiV), and they have stood the test of time, including mapping quite closely to OpenAI’s own [Prompt Engineering Guide](https://oreil.ly/dF8q-), which came a year later. Anyone who works closely with generative AI models is likely to converge on a similar set of strategies for solving common issues, and throughout this book you’ll see hundreds of demonstrative examples of how they can be useful for improving your prompts.\n",
    "\n",
    "Popular Udemy course [The Complete Prompt Engineering for AI Bootcamp (70,000+ students)](https://oreil.ly/V40zg), which was based on the same principles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd29e08-d8f7-4034-8ef3-283581669448",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Here’s a simple example of a prompt we could use as a starting point:\n",
    "\n",
    "> **Simple Prompt**: “Generate a list of creative product names for a new eco-friendly cleaning brand.”\n",
    "\n",
    "Using this prompt, the AI might return names like *EcoShine*, *GreenClean*, or *NatureBright*. However, based on the principles from Phoenix and Taylor’s (2024) book, this prompt could be refined to produce more consistent and higher-quality results.\n",
    "\n",
    "---\n",
    "\n",
    "### Five Principles to Improve the Prompt (Phoenix and Taylor, 2024)\n",
    "\n",
    "1. **Provide Clear and Specific Direction**:\n",
    "   - **Issue**: The simple prompt is vague about the style, tone, or specific attributes the product name should reflect.\n",
    "   - **Improvement**: You could specify whether you want a single word or compound names, whether the names should be in plain English, or if they can include newly coined terms.\n",
    "   - **Refined Prompt Example**: “Generate a list of catchy, eco-friendly product names that evoke freshness and cleanliness. Names should be easy to pronounce, memorable, and consist of one or two words in English.”\n",
    "\n",
    "2. **Format the Output**:\n",
    "   - **Issue**: The unformatted output might be inconsistent or hard to parse programmatically.\n",
    "   - **Improvement**: Request a specific format, such as a numbered list or JSON format, to ensure predictability.\n",
    "   - **Refined Prompt Example**: “Generate a numbered list of 5 eco-friendly product names for a cleaning brand. Each name should be in its own line.”\n",
    "\n",
    "3. **Provide Examples**:\n",
    "   - **Issue**: Without examples, the AI is basing its suggestions solely on its general training data, which may not align with the desired tone or style.\n",
    "   - **Improvement**: Include examples of existing product names that fit your criteria to give the AI a clearer understanding of the desired output.\n",
    "   - **Refined Prompt Example**: “Generate a list of eco-friendly product names similar in style to ‘EcoFresh,’ ‘GreenWave,’ and ‘PureClean.’ Each name should reflect qualities of sustainability and effectiveness.”\n",
    "\n",
    "4. **Establish Evaluation Criteria**:\n",
    "   - **Issue**: There’s no objective way to determine whether the output names meet the desired criteria.\n",
    "   - **Improvement**: Define specific characteristics or ratings criteria to assess the quality of generated names.\n",
    "   - **Refined Prompt Example**: “Generate a list of 5 eco-friendly product names that are short, memorable, and unique. The names should ideally not be found in a simple Google search for existing cleaning products.”\n",
    "\n",
    "5. **Divide Complex Tasks into Subtasks**:\n",
    "   - **Issue**: The prompt tries to handle multiple aspects of naming in one go, potentially leading to suboptimal results.\n",
    "   - **Improvement**: Break down the task by asking the AI for individual qualities or styles first, then combine them.\n",
    "   - **Refined Prompt Example**: “First, generate a list of adjectives associated with eco-friendliness (e.g., ‘Green,’ ‘Pure,’ ‘Eco’). Next, generate a list of words related to cleaning. Finally, combine these words to create a list of 5 unique product names.”\n",
    "\n",
    "---\n",
    "\n",
    "These principles offer a systematic approach to refining your prompt for production use, aligning with Phoenix and Taylor’s advice on cost-effectiveness and reducing iterative corrections (Phoenix and Taylor, 2024)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51025b7f-360e-4a56-a622-f9e5a0f1203f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## References\n",
    "\n",
    "- Phoenix, J., and Taylor, M. 2024. *Prompt Engineering for Generative AI*. Sebastopol, CA: Saxifrage, LLC, Just Understanding Data LTD, & O'Reilly Media, Inc. Available at: [O'Reilly Media](https://www.oreilly.com/library/view/prompt-engineering-for/9781098153427/)\n",
    "\n",
    "- Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., et al. 2020. Language Models are Few-Shot Learners. In *Advances in Neural Information Processing Systems*, 33, 1877–1901. Available at: [NeurIPS Proceedings](https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf)\n",
    "\n",
    "- Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., and Neubig, G. 2023. Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing. *Trans. Assoc. Comput. Linguistics*. 11, 630–676. Available at: [ACL Anthology](https://aclanthology.org/2023.tacl-1.88.pdf)\n",
    "\n",
    "- Reynolds, L., and McDonell, K. 2021. Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm. *arXiv preprint arXiv:2102.07350*. Available at: [arXiv](https://arxiv.org/abs/2102.07350)\n",
    "\n",
    "- White, J., Narayanan, A., Chiu, S., Huang, Y., and Schmidt, D. 2023. A Comprehensive Survey on Prompt Engineering for Large Language Models. *arXiv preprint arXiv:2302.07842*. Available at: [arXiv](https://arxiv.org/abs/2302.07842)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fc88e3-566e-462d-a664-e0c31582ee62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
