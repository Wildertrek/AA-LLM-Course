{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f5dbf34-2146-4c57-aca2-b20c8b460d70",
   "metadata": {},
   "source": [
    "# **Week 4: Retrieval-Augmented Generation (RAG)**\n",
    "\n",
    "- **Topics:** RAG architecture and concepts, vector search concepts, similarity and distance metrics, indexing strategies, using vectors in document retrieval and LLMs.\n",
    "- **Hands-on:** Building a basic RAG pipeline with pre-trained models, implementing a vector search mechanism with a document corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ba2da8-4bd9-4453-8fa0-71cd40d19e9d",
   "metadata": {},
   "source": [
    "## **Designing the RAG Pipeline for the Medical AI Assistant**\n",
    "\n",
    "### **Objective**\n",
    "The goal is to design a scalable and efficient RAG pipeline for the VA's Medical AI Assistant. This pipeline will:\n",
    "1. Retrieve relevant clinical and medical knowledge (e.g., TIU notes, ICD codes, guidelines).\n",
    "2. Generate accurate, contextually relevant, and actionable responses.\n",
    "3. Support both experimentation (open-source) and production (Azure services) environments.\n",
    "\n",
    "---\n",
    "\n",
    "### **Core Components of the RAG Pipeline**\n",
    "\n",
    "1. **Document Corpus**  \n",
    "   - A centralized repository of all relevant medical knowledge, including:\n",
    "     - TIU notes (real-world clinical context).\n",
    "     - ICD codes (structured disease classifications).\n",
    "     - Evidence-based guidelines (e.g., VA/DoD clinical practice guidelines).\n",
    "     - General medical encyclopedias (e.g., MedlinePlus).\n",
    "\n",
    "2. **Embedding Model**\n",
    "   - Converts text into dense vector representations for similarity-based retrieval.\n",
    "   - **Azure Option**: Azure OpenAI embeddings (`text-embedding-ada-002`).\n",
    "   - **Open-Source Option**: SentenceTransformers (e.g., `all-MiniLM-L6-v2`).\n",
    "\n",
    "3. **Vector Store**\n",
    "   - A scalable repository to store and search embeddings.\n",
    "   - **Azure Option**: Azure AI Search (with vector search enabled).\n",
    "   - **Open-Source Option**: FAISS or Milvus for local/experimental setups.\n",
    "\n",
    "4. **Metadata and Indexing**\n",
    "   - Enables filtering and relevance ranking during retrieval.\n",
    "   - Key metadata fields:\n",
    "     - **Document Type**: TIU note, ICD code, guideline, etc.\n",
    "     - **Specialty**: Cardiology, gastroenterology, mental health.\n",
    "     - **Source**: EHR, MedlinePlus, PubMed, etc.\n",
    "     - **Date**: Timeliness of the document.\n",
    "   - **Azure Option**: Use Azure AI Search’s metadata and indexing features.\n",
    "   - **Open-Source Option**: Store metadata in a database (e.g., MongoDB or PostgreSQL) alongside embeddings.\n",
    "\n",
    "5. **Retrieval Mechanism**\n",
    "   - Fetches top-k documents relevant to the query.\n",
    "   - Supports similarity-based searches and metadata filtering.\n",
    "   - **Azure Option**: Azure AI Search with semantic ranking.\n",
    "   - **Open-Source Option**: FAISS/Milvus queries combined with metadata filtering logic.\n",
    "\n",
    "6. **Context-Aware Generation**\n",
    "   - Combines retrieved documents with the query to generate a final response.\n",
    "   - **Azure Option**: Azure OpenAI Service (e.g., GPT-4).\n",
    "   - **Open-Source Option**: OpenAI API or Hugging Face transformers.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step-by-Step Design Framework**\n",
    "\n",
    "#### **Step 1: Data Collection and Preparation**\n",
    "- **Sources**:\n",
    "  - Clinical data: TIU notes, radiology reports, lab results (anonymized).\n",
    "  - Structured data: ICD-10, SNOMED CT, CPT codes.\n",
    "  - General knowledge: MedlinePlus, VA-specific guidelines.\n",
    "  - Behavioral health: DSM-5 criteria, PTSD scales.\n",
    "\n",
    "- **Processing**:\n",
    "  - Clean and preprocess text data to remove noise.\n",
    "  - Assign metadata tags for filtering and relevance ranking.\n",
    "\n",
    "#### **Step 2: Embedding Strategy**\n",
    "- **Azure Approach**:\n",
    "  - Use Azure OpenAI embeddings for consistency with other Azure services.\n",
    "- **Open-Source Approach**:\n",
    "  - Use domain-specific models like BioBERT or SentenceTransformers for medical data.\n",
    "\n",
    "#### **Step 3: Vector Store Design**\n",
    "- **Indexes**:\n",
    "  - Organize data into logical partitions or indexes:\n",
    "    - Clinical Notes Index: TIU notes, radiology, lab reports.\n",
    "    - Terminology Index: ICD, SNOMED CT, CPT.\n",
    "    - General Knowledge Index: MedlinePlus, guidelines, FAQs.\n",
    "\n",
    "- **Metadata Schema**:\n",
    "  - Example:\n",
    "    - Document Type: \"TIU Note\", \"ICD Code\".\n",
    "    - Specialty: \"Cardiology\", \"Gastroenterology\".\n",
    "    - Date: \"2023-10-01\".\n",
    "\n",
    "- **Storage Options**:\n",
    "  - **Azure**: Use Azure AI Search with vector and metadata capabilities.\n",
    "  - **Open-Source**: Use FAISS or Weaviate with metadata stored separately.\n",
    "\n",
    "#### **Step 4: Retrieval Logic**\n",
    "- Use similarity search (based on embeddings) combined with metadata filtering.\n",
    "- **Query Examples**:\n",
    "  - \"What are the causes of chest pain?\"\n",
    "    - Retrieve relevant TIU notes, ICD codes, and guidelines tagged with \"cardiology\".\n",
    "  - \"What guidelines exist for PTSD management?\"\n",
    "    - Retrieve VA/DoD guidelines and DSM-5 criteria tagged with \"behavioral health\".\n",
    "\n",
    "#### **Step 5: Generation Logic**\n",
    "- Combine retrieved documents with the query to construct a prompt.\n",
    "- Generate a response using an LLM (e.g., GPT-4 or Claude).\n",
    "- Prompt Example:\n",
    "  ```\n",
    "  Query: \"What are the causes of chest pain?\"\n",
    "  Retrieved Context: [Document 1 content, Document 2 content]\n",
    "  Response: Summarize the retrieved context and provide a medically accurate explanation.\n",
    "  ```\n",
    "\n",
    "#### **Step 6: System Validation**\n",
    "- Test the pipeline with real-world queries:\n",
    "  - Validate retrieval accuracy (Are the top-k results relevant?).\n",
    "  - Assess generation quality (Are the responses clear and actionable?).\n",
    "- Iteratively refine embeddings, metadata schema, and retrieval logic.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Considerations**\n",
    "\n",
    "1. **Scalability**:\n",
    "   - **Azure**: Seamless scaling with Azure AI Search and Azure OpenAI.\n",
    "   - **Open-Source**: Use FAISS for smaller-scale experiments, with a transition to Milvus or Weaviate for larger datasets.\n",
    "\n",
    "2. **Security and Privacy**:\n",
    "   - Ensure all clinical data (e.g., TIU notes) is anonymized.\n",
    "   - Use secure storage options, especially for sensitive VA data.\n",
    "\n",
    "3. **Future Expansion**:\n",
    "   - Plan for adding new data sources (e.g., clinical trials, research papers).\n",
    "   - Ensure that the system supports updates to medical terminologies (e.g., new ICD revisions).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f51bd74-590d-4709-86a4-25c407993e3a",
   "metadata": {},
   "source": [
    "## **Prioritizing Data Sources for the Vector Store**\n",
    "\n",
    "To ensure the Medical AI Assistant is both relevant and effective, we need to focus on high-impact data sources. Below is a prioritized list of data sources based on **clinical relevance**, **retrieval utility**, and **ease of integration** into the vector store.\n",
    "\n",
    "---\n",
    "\n",
    "### **Tier 1: High-Priority Data Sources**\n",
    "These data sources should be integrated first as they directly impact the Assistant's ability to address medical queries.\n",
    "\n",
    "1. **TIU Notes (Text Integration Utility Notes)**  \n",
    "   - **Why**:  \n",
    "     TIU notes are critical for understanding real-world clinical scenarios, providing the assistant with patient-specific contexts (after anonymization).  \n",
    "   - **Examples**:  \n",
    "     - SOAP notes (Subjective, Objective, Assessment, Plan).\n",
    "     - Admission, discharge, and progress notes.\n",
    "   - **Challenges**:  \n",
    "     - Requires extensive preprocessing to anonymize patient data while preserving clinical relevance.\n",
    "\n",
    "2. **ICD Codes (International Classification of Diseases)**  \n",
    "   - **Why**:  \n",
    "     Structured data that links symptoms and diagnoses, making it easier to map patient complaints to clinical terms.  \n",
    "   - **Examples**:  \n",
    "     - ICD-10 Codes: \"I20\" (Angina Pectoris), \"K21\" (GERD).\n",
    "   - **Challenges**:  \n",
    "     - Keeping up-to-date with revisions (e.g., ICD-11).\n",
    "\n",
    "3. **VA/DoD Clinical Guidelines**  \n",
    "   - **Why**:  \n",
    "     Ensures responses align with evidence-based practices specific to the VA system.  \n",
    "   - **Examples**:  \n",
    "     - PTSD guidelines, diabetes management, hypertension treatment.\n",
    "   - **Challenges**:  \n",
    "     - Formatting variability and ensuring semantic consistency.\n",
    "\n",
    "---\n",
    "\n",
    "### **Tier 2: Medium-Priority Data Sources**\n",
    "Once Tier 1 data sources are integrated, these enhance the Assistant’s knowledge and ability to handle broader queries.\n",
    "\n",
    "4. **MedlinePlus Consumer Health Information**  \n",
    "   - **Why**:  \n",
    "     Provides plain-language explanations of conditions, treatments, and medications, helpful for patient-facing responses.  \n",
    "   - **Examples**:  \n",
    "     - Descriptions of GERD, treatments for hypertension.\n",
    "   - **Challenges**:  \n",
    "     - Balancing clinical depth with consumer-level simplicity.\n",
    "\n",
    "5. **SNOMED CT (Systematized Nomenclature of Medicine)**  \n",
    "   - **Why**:  \n",
    "     Adds depth to the Assistant's knowledge of medical terms and relationships between concepts (e.g., \"angina\" vs. \"unstable angina\").  \n",
    "   - **Examples**:  \n",
    "     - Hierarchies: \"Chest Pain\" → \"Cardiac Chest Pain\" → \"Angina\".\n",
    "   - **Challenges**:  \n",
    "     - Large vocabulary requires efficient indexing and filtering.\n",
    "\n",
    "6. **Drug Databases**  \n",
    "   - **Why**:  \n",
    "     Medication information is essential for addressing drug interactions, dosages, and treatment options.  \n",
    "   - **Examples**:  \n",
    "     - DailyMed (FDA-approved labels), Lexicomp.\n",
    "   - **Challenges**:  \n",
    "     - Licensing requirements for proprietary databases (e.g., Lexicomp).\n",
    "\n",
    "---\n",
    "\n",
    "### **Tier 3: Supplemental Data Sources**\n",
    "These are useful for more advanced capabilities and specialized queries but are not essential for the initial vector store.\n",
    "\n",
    "7. **DSM-5 Criteria (Mental Health)**  \n",
    "   - **Why**:  \n",
    "     Supports mental health queries, particularly for PTSD, depression, and anxiety—conditions prevalent in the VA population.  \n",
    "   - **Examples**:  \n",
    "     - PTSD diagnostic criteria, generalized anxiety disorder symptoms.\n",
    "   - **Challenges**:  \n",
    "     - Requires structured integration to avoid overwhelming the retrieval system.\n",
    "\n",
    "8. **PubMed Abstracts (Biomedical Literature)**  \n",
    "   - **Why**:  \n",
    "     Offers cutting-edge research insights, useful for clinician-facing queries.  \n",
    "   - **Examples**:  \n",
    "     - Recent studies on new treatments for atrial fibrillation.\n",
    "   - **Challenges**:  \n",
    "     - Query relevance may require additional filtering based on publication date, journal reputation.\n",
    "\n",
    "9. **Radiology and Lab Reports**  \n",
    "   - **Why**:  \n",
    "     Adds context for diagnostic queries involving imaging or laboratory findings.  \n",
    "   - **Examples**:  \n",
    "     - Common findings: \"Ground-glass opacity\" (COVID-19), elevated troponin levels (MI).\n",
    "   - **Challenges**:  \n",
    "     - Requires sophisticated preprocessing to extract key terms.\n",
    "\n",
    "---\n",
    "\n",
    "### **Proposed Integration Timeline**\n",
    "1. **Phase 1 (Essential)**:\n",
    "   - TIU Notes (preprocessed and anonymized).\n",
    "   - ICD Codes.\n",
    "   - VA/DoD Clinical Guidelines.\n",
    "\n",
    "2. **Phase 2 (Enhanced)**:\n",
    "   - MedlinePlus.\n",
    "   - SNOMED CT.\n",
    "   - Drug Databases.\n",
    "\n",
    "3. **Phase 3 (Advanced)**:\n",
    "   - DSM-5 Criteria.\n",
    "   - PubMed Abstracts.\n",
    "   - Radiology and Lab Reports.\n",
    "\n",
    "---\n",
    "\n",
    "### **Design Considerations for Integration**\n",
    "\n",
    "#### **1. Metadata Schema**\n",
    "- **Fields**:\n",
    "  - **Type**: TIU Note, ICD Code, Guideline, etc.\n",
    "  - **Specialty**: Cardiology, Gastroenterology, Mental Health.\n",
    "  - **Date**: Timestamp of document creation.\n",
    "  - **Source**: EHR, MedlinePlus, PubMed, etc.\n",
    "  - **Relevance**: Weighted score for prioritization.\n",
    "\n",
    "#### **2. Storage and Partitioning**\n",
    "- **Index Design**:\n",
    "  - Create separate indexes for structured (ICD codes) vs. unstructured (TIU notes) data.\n",
    "  - Use metadata for cross-index filtering (e.g., \"retrieve only Cardiology TIU notes\").\n",
    "- **Scaling**:\n",
    "  - Plan for incremental updates, especially for ICD revisions or new guidelines.\n",
    "\n",
    "#### **3. Embedding Strategy**\n",
    "- Generate embeddings for all data sources using:\n",
    "  - **Azure**: OpenAI embeddings for standardization across services.\n",
    "  - **Open-Source**: Domain-specific models (e.g., ClinicalBERT).\n",
    "\n",
    "#### **4. Retrieval Performance**\n",
    "- Optimize for:\n",
    "  - **Precision**: Retrieve only the most relevant results.\n",
    "  - **Latency**: Minimize query processing time for real-time use.\n",
    "\n",
    "---\n",
    "\n",
    "### **Next Steps**\n",
    "1. **Finalize Tier 1 Sources**:\n",
    "   - Confirm the scope of TIU notes, ICD codes, and VA guidelines for initial integration.\n",
    "2. **Design Metadata Schema**:\n",
    "   - Outline specific fields and values for indexing and filtering.\n",
    "3. **Embed and Index Sample Data**:\n",
    "   - Test embedding and indexing with a subset of documents to validate design assumptions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b169150-cda1-47fd-8dfa-10f77bc58e42",
   "metadata": {},
   "source": [
    "### **Openly Available Public Datasets for Medical AI Assistant**\n",
    "\n",
    "Here’s a curated list of publicly available datasets suitable for building a Medical AI Assistant, along with their descriptions, focus areas, and links for access.\n",
    "\n",
    "| **Dataset Name**               | **Description**                                                                                             | **Focus Area**                                  | **Link**                                                                 |\n",
    "|--------------------------------|-------------------------------------------------------------------------------------------------------------|------------------------------------------------|-------------------------------------------------------------------------|\n",
    "| **MIMIC-III**                  | A large database containing de-identified health data from critical care patients.                          | Clinical text, ICU data                        | [MIMIC-III Dataset](https://physionet.org/content/mimiciii/1.4/)        |\n",
    "| **MIMIC-IV**                   | The successor to MIMIC-III with more recent data, enhanced granularity, and more structured formats.        | Clinical text, ICU data                        | [MIMIC-IV Dataset](https://physionet.org/content/mimiciv/2.2/)          |\n",
    "| **eICU Collaborative Research**| A multi-center critical care database with de-identified patient data from ICUs across the United States.  | ICU data, clinical outcomes                   | [eICU Dataset](https://physionet.org/content/eicu-crd/2.0/)             |\n",
    "| **BioASQ Dataset**             | Biomedical semantic indexing and question answering dataset for natural language processing.               | Biomedical text, QA systems                   | [BioASQ Dataset](http://bioasq.org/)                                    |\n",
    "| **PubMed Central Open Access** | A large repository of free full-text biomedical and life sciences journal articles.                        | Biomedical research, text embeddings           | [PubMed Central](https://www.ncbi.nlm.nih.gov/pmc/tools/openftlist/)    |\n",
    "| **MedlinePlus**                | Consumer-friendly health information about diseases, conditions, and wellness topics.                      | Patient education, health information          | [MedlinePlus](https://medlineplus.gov/)                                 |\n",
    "| **SNOMED CT**                  | A comprehensive, multilingual clinical healthcare terminology standard.                                     | Clinical terminology, medical codes           | [SNOMED CT](https://www.nlm.nih.gov/healthit/snomedct/index.html)       |\n",
    "| **ICD-10 Dataset**             | International Classification of Diseases, Tenth Revision, used for coding diagnoses and procedures.        | Clinical terminology, disease classification   | [ICD-10](https://www.who.int/standards/classifications/classification-of-diseases) |\n",
    "| **COVID-19 Open Research Dataset (CORD-19)** | A dataset of scholarly articles about COVID-19 for text mining and natural language processing research. | Pandemic-related biomedical research           | [CORD-19 Dataset](https://www.semanticscholar.org/cord19)               |\n",
    "| **Unified Medical Language System (UMLS)** | A collection of biomedical vocabularies integrated into a single framework for interoperability.      | Medical vocabularies, terminology             | [UMLS](https://www.nlm.nih.gov/research/umls/index.html)                |\n",
    "| **Disease Ontology**           | A standardized ontology for human disease terms, their definitions, and their relationships.               | Disease classification, ontologies            | [Disease Ontology](http://www.disease-ontology.org/)                    |\n",
    "| **Open-i Medical Image Dataset** | A collection of de-identified medical images with corresponding metadata and reports.                     | Medical imaging, radiology reports             | [Open-i Dataset](https://openi.nlm.nih.gov/)                            |\n",
    "| **CheXpert**                   | A large dataset of chest X-rays labeled for various pathologies.                                           | Radiology, chest diseases                      | [CheXpert Dataset](https://stanfordmlgroup.github.io/competitions/chexpert/) |\n",
    "| **PhysioNet**                  | Open access to complex physiological signals such as ECGs and EEGs.                                         | Physiological data, signal analysis           | [PhysioNet](https://physionet.org/)                                     |\n",
    "| **OHDSI OMOP**                 | Observational health data from a global collaboration focusing on standardized medical research databases.  | Clinical observations, research data           | [OHDSI Dataset](https://www.ohdsi.org/data-standardization/the-common-data-model/) |\n",
    "| **RxNorm**                     | A normalized naming system for generic and branded drugs and their relationships.                          | Drug information, pharmacology                 | [RxNorm](https://www.nlm.nih.gov/research/umls/rxnorm/index.html)       |\n",
    "| **DrugBank Open Data**         | A comprehensive database of drug and drug target information.                                               | Pharmacology, drug-target interactions         | [DrugBank Open Data](https://www.drugbank.com/releases/latest)          |\n",
    "| **ClinicalTrials.gov**         | A database of privately and publicly funded clinical studies conducted around the world.                   | Clinical trials, research studies              | [ClinicalTrials.gov](https://clinicaltrials.gov/)                       |\n",
    "\n",
    "---\n",
    "\n",
    "### **How This Table Can Be Used**\n",
    "1. **Building the Vector Store**:\n",
    "   - Choose datasets relevant to your use case (e.g., TIU notes from MIMIC-III, disease definitions from Disease Ontology).\n",
    "   - Use embeddings to represent the dataset text and store them for retrieval.\n",
    "\n",
    "2. **Expanding the Knowledge Base**:\n",
    "   - Incorporate data from medical vocabularies (e.g., UMLS, SNOMED CT) to enhance terminology understanding.\n",
    "   - Include patient-facing resources (e.g., MedlinePlus) for consumer-level education.\n",
    "\n",
    "3. **Supporting Specific Applications**:\n",
    "   - Use imaging datasets (e.g., CheXpert) to complement textual data.\n",
    "   - Leverage pharmacological datasets (e.g., DrugBank, RxNorm) for drug-related queries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf10baa-f60c-491c-b18d-6e43ab84192d",
   "metadata": {},
   "source": [
    "## **Focus: Metadata Schema Design**\n",
    "\n",
    "Metadata is the backbone of effective document retrieval in a vector store. A well-designed schema ensures that documents are organized, searchable, and retrievable based on precise filters. For the Medical AI Assistant, we need a robust schema that supports diverse data types like TIU notes, ICD codes, and clinical guidelines.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Metadata Schema Design**\n",
    "\n",
    "#### **Core Metadata Fields**\n",
    "| **Field Name**      | **Description**                                                                 | **Example Values**                                  |\n",
    "|----------------------|---------------------------------------------------------------------------------|----------------------------------------------------|\n",
    "| **Document Type**    | The category of the document.                                                   | \"TIU Note\", \"ICD Code\", \"Guideline\"               |\n",
    "| **Specialty**        | The medical specialty relevant to the document.                                | \"Cardiology\", \"Gastroenterology\", \"Mental Health\" |\n",
    "| **Source**           | The origin of the document or data.                                             | \"EHR\", \"MedlinePlus\", \"VA Guidelines\"             |\n",
    "| **Title**            | A brief title or summary for the document.                                     | \"Managing GERD in Veterans\"                       |\n",
    "| **Keywords**         | Key terms associated with the document.                                        | \"GERD\", \"angina\", \"chest pain\"                    |\n",
    "| **Date**             | The date the document was created or last updated.                             | \"2024-11-15\"                                       |\n",
    "| **Relevance Score**  | A weight or rank indicating the document's importance for retrieval.            | \"0.85\", \"0.92\"                                    |\n",
    "| **Context Summary**  | A short summary or abstract of the document's content.                         | \"Chest pain caused by GERD, angina, and anxiety.\" |\n",
    "| **Clinical Tags**    | Specific tags for clinical features, diagnoses, or symptoms.                   | \"Chest Pain\", \"MI\", \"Pulmonary Embolism\"          |\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Metadata Examples for Tier 1 Sources**\n",
    "\n",
    "- **TIU Note Example**:\n",
    "  ```json\n",
    "  {\n",
    "      \"Document Type\": \"TIU Note\",\n",
    "      \"Specialty\": \"Cardiology\",\n",
    "      \"Source\": \"EHR\",\n",
    "      \"Title\": \"Progress Note for Chest Pain\",\n",
    "      \"Keywords\": [\"chest pain\", \"angina\", \"ECG\"],\n",
    "      \"Date\": \"2024-10-10\",\n",
    "      \"Relevance Score\": \"0.88\",\n",
    "      \"Context Summary\": \"Patient presented with chest pain; ruled out myocardial infarction.\",\n",
    "      \"Clinical Tags\": [\"Chest Pain\", \"Angina\", \"ECG\"]\n",
    "  }\n",
    "  ```\n",
    "\n",
    "- **ICD Code Example**:\n",
    "  ```json\n",
    "  {\n",
    "      \"Document Type\": \"ICD Code\",\n",
    "      \"Specialty\": \"General Medicine\",\n",
    "      \"Source\": \"ICD-10\",\n",
    "      \"Title\": \"I20 - Angina Pectoris\",\n",
    "      \"Keywords\": [\"angina\", \"ischemic heart disease\"],\n",
    "      \"Date\": \"2024-01-01\",\n",
    "      \"Relevance Score\": \"0.95\",\n",
    "      \"Context Summary\": \"ICD-10 code for angina, includes classifications like unstable angina.\",\n",
    "      \"Clinical Tags\": [\"Ischemic Heart Disease\", \"Angina\"]\n",
    "  }\n",
    "  ```\n",
    "\n",
    "- **VA Guideline Example**:\n",
    "  ```json\n",
    "  {\n",
    "      \"Document Type\": \"Guideline\",\n",
    "      \"Specialty\": \"Mental Health\",\n",
    "      \"Source\": \"VA/DoD\",\n",
    "      \"Title\": \"PTSD Treatment Guidelines\",\n",
    "      \"Keywords\": [\"PTSD\", \"mental health\", \"CBT\"],\n",
    "      \"Date\": \"2023-06-15\",\n",
    "      \"Relevance Score\": \"0.90\",\n",
    "      \"Context Summary\": \"Best practices for diagnosing and managing PTSD in veterans.\",\n",
    "      \"Clinical Tags\": [\"PTSD\", \"Mental Health\", \"CBT\"]\n",
    "  }\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Implementation Plan**\n",
    "\n",
    "#### **Step 1: Define Schema**\n",
    "- Finalize metadata fields and default values for missing information.\n",
    "\n",
    "#### **Step 2: Map Schema to Data Sources**\n",
    "- TIU Notes:\n",
    "  - Extract fields like **Date**, **Keywords**, and **Clinical Tags** from structured sections.\n",
    "  - Use NLP to summarize and tag.\n",
    "- ICD Codes:\n",
    "  - Predefined schema with codes, descriptions, and associated conditions.\n",
    "- Guidelines:\n",
    "  - Summarize key sections and tag with **Keywords** and **Clinical Tags**.\n",
    "\n",
    "#### **Step 3: Store Metadata**\n",
    "- **Azure Option**:\n",
    "  - Use **Azure Cosmos DB** or **Azure Blob Storage** with metadata as JSON objects.\n",
    "- **Open-Source Option**:\n",
    "  - Store metadata in MongoDB or a relational database (e.g., PostgreSQL).\n",
    "\n",
    "#### **Step 4: Integrate Metadata with Vector Store**\n",
    "- Ensure metadata is associated with embeddings in the vector store.\n",
    "- Enable filtering and sorting based on metadata fields during retrieval.\n",
    "\n",
    "---\n",
    "\n",
    "### **Next Steps**\n",
    "\n",
    "1. Expand this with **embedding strategies** for each data type.\n",
    "2. Move on to **vector store indexing and retrieval design**.\n",
    "3. Discuss **scalability and updating the vector store**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe8b104-4290-40c1-9db1-67cad48419f5",
   "metadata": {},
   "source": [
    "## **Standardizing on a Single Embedding Model vs. Using Multiple Models**\n",
    "\n",
    "Whether to use a single embedding model or multiple specialized models depends on your **use case**, **data diversity**, and **performance requirements**. Below is an analysis of the **pros and cons** of each approach to help you decide.\n",
    "\n",
    "---\n",
    "\n",
    "### **Option 1: Standardizing on a Single Embedding Model**\n",
    "\n",
    "#### **Description**:\n",
    "Use one embedding model for all data types, such as **Azure OpenAI’s `text-embedding-ada-002`** or an open-source alternative like **SentenceTransformers**.\n",
    "\n",
    "#### **Pros**:\n",
    "1. **Simplicity**:\n",
    "   - Easier to manage and maintain embeddings in the pipeline.\n",
    "   - Uniform embedding dimensionality simplifies vector store schema and search.\n",
    "\n",
    "2. **Consistency**:\n",
    "   - Avoids discrepancies when comparing embeddings generated by different models.\n",
    "   - Ensures that similarity scores are computed on vectors from the same feature space.\n",
    "\n",
    "3. **Efficiency**:\n",
    "   - Reduces operational complexity by eliminating the need to switch between models.\n",
    "   - Faster development and scaling, especially when embedding multiple data sources.\n",
    "\n",
    "4. **Scalability**:\n",
    "   - Optimized for cloud-native solutions (e.g., Azure AI Search), enabling seamless integration and scaling.\n",
    "\n",
    "5. **Cost-Effective**:\n",
    "   - Training, hosting, or calling a single model is often more cost-efficient than managing multiple specialized models.\n",
    "\n",
    "#### **Cons**:\n",
    "1. **Generalization**:\n",
    "   - A single model may not perform optimally on domain-specific tasks (e.g., clinical text vs. scientific abstracts).\n",
    "   - Loss of precision when embedding structured data (e.g., ICD codes).\n",
    "\n",
    "2. **Compromise in Quality**:\n",
    "   - The model may struggle to encode niche medical terms or specialized data with the same quality as a domain-specific model.\n",
    "\n",
    "3. **Limited Fine-Tuning**:\n",
    "   - Fine-tuning a single model for all data types might lead to overfitting for one type and underperformance for others.\n",
    "\n",
    "---\n",
    "\n",
    "### **Option 2: Using Multiple Specialized Models**\n",
    "\n",
    "#### **Description**:\n",
    "Employ different embedding models optimized for specific data types, such as ClinicalBERT for clinical notes or SciBERT for biomedical research.\n",
    "\n",
    "#### **Pros**:\n",
    "1. **Domain-Specific Accuracy**:\n",
    "   - Specialized models excel in their respective areas (e.g., ClinicalBERT captures medical nuances better than general-purpose models).\n",
    "\n",
    "2. **Task Optimization**:\n",
    "   - Embeddings are tailored to the unique requirements of each data type (e.g., ICD codes benefit from lightweight sentence transformers, while TIU notes require context-aware embeddings).\n",
    "\n",
    "3. **Flexibility**:\n",
    "   - Allows experimenting with various models for different tasks, optimizing performance dynamically.\n",
    "\n",
    "4. **State-of-the-Art Results**:\n",
    "   - Leveraging the latest advancements in specific domains ensures higher relevance in retrieval tasks.\n",
    "\n",
    "#### **Cons**:\n",
    "1. **Complexity**:\n",
    "   - Requires maintaining multiple embedding pipelines, increasing operational overhead.\n",
    "   - Managing different dimensionalities for embeddings adds complexity to the vector store design.\n",
    "\n",
    "2. **Inconsistent Feature Spaces**:\n",
    "   - Combining embeddings from different models may lead to inconsistencies in similarity scoring and ranking.\n",
    "\n",
    "3. **Higher Costs**:\n",
    "   - Running multiple models simultaneously can lead to higher compute and storage costs, especially in production.\n",
    "\n",
    "4. **Integration Challenges**:\n",
    "   - Integrating and optimizing workflows for multiple models requires additional engineering effort.\n",
    "\n",
    "---\n",
    "\n",
    "### **Comparison Table**\n",
    "\n",
    "| **Aspect**               | **Single Model**                          | **Multiple Models**                       |\n",
    "|--------------------------|------------------------------------------|------------------------------------------|\n",
    "| **Ease of Maintenance**   | High                                     | Low                                      |\n",
    "| **Consistency**           | High                                     | Medium (varies by model feature space)   |\n",
    "| **Embedding Quality**     | Generalized                              | Specialized                              |\n",
    "| **Scalability**           | Easier to scale                          | Complex due to varied workflows          |\n",
    "| **Cost**                  | Lower                                    | Higher                                   |\n",
    "| **Performance**           | Generalized performance                  | Optimized for each data type             |\n",
    "| **Flexibility**           | Lower (one-size-fits-all)                | High (task-specific optimization)        |\n",
    "\n",
    "---\n",
    "\n",
    "### **Recommendation for the Medical AI Assistant**\n",
    "\n",
    "Given your work with **Azure services** and the **diverse nature of medical data**, here’s a practical approach:\n",
    "\n",
    "#### **1. Start with a Single Model (Standardized Approach)**:\n",
    "   - Use **Azure OpenAI’s `text-embedding-ada-002`** for initial integration.\n",
    "   - Pros:\n",
    "     - Simplifies pipeline development.\n",
    "     - Ensures compatibility across all data types.\n",
    "     - Aligns with existing Azure infrastructure.\n",
    "\n",
    "#### **2. Evaluate Performance on Key Tasks**:\n",
    "   - Test retrieval quality across data types (e.g., TIU notes, ICD codes, guidelines).\n",
    "   - Identify gaps in performance or areas where embeddings are insufficient.\n",
    "\n",
    "#### **3. Introduce Specialized Models as Needed**:\n",
    "   - For clinical notes, consider using **ClinicalBERT**.\n",
    "   - For PubMed abstracts, try **SciBERT**.\n",
    "   - Maintain these models for high-priority or low-recall tasks only.\n",
    "\n",
    "#### **4. Long-Term Scalability**:\n",
    "   - Use **Azure AI Search** for scaling the vector store.\n",
    "   - Integrate specialized models incrementally if retrieval performance requires domain-specific improvements.\n",
    "\n",
    "---\n",
    "\n",
    "### **Next Steps**\n",
    "\n",
    "1. **Designing a single-model embedding pipeline**  \n",
    "2. **Drafting a hybrid pipeline to test both approaches** (We can do this separately as a part of advanced examples)  \n",
    "3. **Evaluating data quality and embedding strategies with example queries**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a61861a-701c-449d-9ba9-c52554bda249",
   "metadata": {},
   "source": [
    "## **Designing a Single-Model Embedding Pipeline**\n",
    "\n",
    "The single-model embedding pipeline focuses on using a **standardized embedding model** to process all types of data in a Retrieval-Augmented Generation (RAG) pipeline. This simplifies operations while ensuring compatibility and scalability.\n",
    "\n",
    "---\n",
    "\n",
    "### **Pipeline Components**\n",
    "\n",
    "#### **1. Data Ingestion**\n",
    "- **Purpose**: Collect and preprocess data from various sources (e.g., TIU notes, ICD codes, MedlinePlus).\n",
    "- **Key Steps**:\n",
    "  - Connect to data sources (e.g., EHR systems, APIs, local files).\n",
    "  - Normalize the data (e.g., remove duplicates, format for readability).\n",
    "  - Ensure sensitive data is de-identified (e.g., for TIU notes).\n",
    "\n",
    "#### **2. Preprocessing**\n",
    "- **Purpose**: Prepare data for embedding by cleaning, tokenizing, and splitting text.\n",
    "- **Key Steps**:\n",
    "  - **Text Cleaning**: Remove unnecessary punctuation, standardize casing, and handle special characters.\n",
    "  - **Chunking**:\n",
    "    - Divide long documents (e.g., TIU notes) into smaller, manageable chunks.\n",
    "    - Overlap chunks slightly to retain context across boundaries.\n",
    "  - **Metadata Enrichment**:\n",
    "    - Add fields like `source`, `specialty`, `tags`, and `date` to enrich retrieval capabilities.\n",
    "\n",
    "#### **3. Embedding Generation**\n",
    "- **Purpose**: Convert text into dense numerical vectors using a single embedding model.\n",
    "- **Model Choice**:\n",
    "  - **Azure Option**: `text-embedding-ada-002` (recommended for uniformity and scalability).\n",
    "  - **Implementation**:\n",
    "    ```python\n",
    "    import openai\n",
    "\n",
    "    def generate_embedding(text):\n",
    "        response = openai.Embedding.create(\n",
    "            input=text,\n",
    "            engine=\"text-embedding-ada-002\"\n",
    "        )\n",
    "        return response[\"data\"][0][\"embedding\"]\n",
    "    ```\n",
    "- **Batch Processing**:\n",
    "  - Embed documents in batches to improve throughput.\n",
    "  - Store embeddings alongside metadata in a scalable storage solution.\n",
    "\n",
    "#### **4. Vector Store**\n",
    "- **Purpose**: Store embeddings and metadata for efficient similarity search.\n",
    "- **Options**:\n",
    "  - **Azure AI Search**: Fully managed search service.\n",
    "  - **Open-Source**: FAISS, Milvus, or Pinecone for local or hybrid setups.\n",
    "\n",
    "#### **5. Retrieval**\n",
    "- **Purpose**: Fetch the most relevant documents based on user queries.\n",
    "- **Process**:\n",
    "  - Convert the user query into an embedding.\n",
    "  - Perform similarity search in the vector store to retrieve the top results.\n",
    "  - Return results with associated metadata for contextual understanding.\n",
    "\n",
    "#### **6. Augmentation**\n",
    "- **Purpose**: Combine retrieved data with the user query for enhanced model responses.\n",
    "- **Process**:\n",
    "  - Concatenate retrieved documents with the query.\n",
    "  - Pass the combined text to the LLM for a final answer.\n",
    "\n",
    "---\n",
    "\n",
    "### **Pipeline Flow**\n",
    "\n",
    "1. **Input**:\n",
    "   - Data sources: TIU notes, ICD codes, guidelines.\n",
    "   - Query: \"What are the causes of chest pain?\"\n",
    "\n",
    "2. **Output**:\n",
    "   - Top relevant documents (e.g., \"TIU note mentioning angina and GERD\").\n",
    "   - LLM-enhanced response: \"Common causes of chest pain include angina, GERD, and anxiety. Here are recommended diagnostic steps...\"\n",
    "\n",
    "---\n",
    "\n",
    "### **Infrastructure and Containers**\n",
    "\n",
    "**Containers** like **Docker** or **Kubernetes** can help build a robust infrastructure for this pipeline. Here's how:\n",
    "\n",
    "#### **Advantages of Containers**:\n",
    "1. **Consistency**:\n",
    "   - Containers ensure that the pipeline runs consistently across different environments (e.g., development, staging, production).\n",
    "\n",
    "2. **Scalability**:\n",
    "   - Container orchestration (e.g., Kubernetes) allows scaling individual pipeline components based on demand (e.g., increase embedding throughput during peak ingestion periods).\n",
    "\n",
    "3. **Isolation**:\n",
    "   - Each component (e.g., preprocessing, embedding, vector search) can run in isolated containers to prevent dependency conflicts.\n",
    "\n",
    "4. **Portability**:\n",
    "   - Containers make it easy to deploy the pipeline across cloud providers (e.g., Azure, AWS) or hybrid setups.\n",
    "\n",
    "5. **Integration with CI/CD**:\n",
    "   - Automated deployment pipelines can be established to update and maintain the pipeline seamlessly.\n",
    "\n",
    "---\n",
    "\n",
    "### **Pipeline Design with Containers**\n",
    "\n",
    "#### **Key Components and Their Containers**:\n",
    "| **Component**           | **Description**                                       | **Container Functionality**                          |\n",
    "|--------------------------|-------------------------------------------------------|-----------------------------------------------------|\n",
    "| **Preprocessing**        | Cleans, chunks, and enriches metadata.                | Runs NLP preprocessing libraries (e.g., spaCy).     |\n",
    "| **Embedding Generation** | Converts text to embeddings using a single model.     | Hosts the embedding model (e.g., via Azure OpenAI). |\n",
    "| **Vector Store**         | Stores embeddings and metadata for retrieval.         | Hosts FAISS, Milvus, or integrates with Azure AI Search.      |\n",
    "| **Query Handler**        | Handles user queries and performs similarity search.  | Performs search and formats results.               |\n",
    "| **LLM Interface**        | Combines retrieved documents with user queries.       | Sends augmented input to the LLM API.              |\n",
    "\n",
    "#### **Example Workflow**:\n",
    "1. **Preprocessing Container**:\n",
    "   - Reads TIU notes from EHR, cleans text, and extracts metadata.\n",
    "2. **Embedding Container**:\n",
    "   - Generates embeddings for processed text.\n",
    "3. **Vector Store Container**:\n",
    "   - Stores embeddings and metadata for later retrieval.\n",
    "4. **Query Handler Container**:\n",
    "   - Accepts user queries, retrieves relevant documents, and passes results to the LLM.\n",
    "5. **LLM Container**:\n",
    "   - Uses Azure OpenAI API to generate the final response.\n",
    "\n",
    "---\n",
    "\n",
    "### **Next Steps**\n",
    "1. **Define Preprocessing Workflow**:\n",
    "   - Standardize text cleaning and chunking logic.\n",
    "2. **Detail Embedding Storage**:\n",
    "   - Decide on storage backends (e.g., Azure AI Search vs. FAISS).\n",
    "3. **Plan Containerization**:\n",
    "   - Identify container dependencies and orchestrator requirements.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9132dcf4-8dfb-4604-9198-37cee7555450",
   "metadata": {},
   "source": [
    "### **Simplified RAG Pipeline Design Using OpenAI Embedding Model and FAISS**\n",
    "\n",
    "For a small-scale implementation, we’ll leverage the **OpenAI embedding model (`text-embedding-ada-002`)** and the open-source FAISS library for vector storage. This setup is lightweight, efficient, and ideal for prototyping or smaller deployments.\n",
    "\n",
    "---\n",
    "\n",
    "### **Pipeline Overview**\n",
    "\n",
    "1. **Data Ingestion**:\n",
    "   - Input: TIU notes, ICD codes, MedlinePlus text, and other relevant medical data.\n",
    "   - Processed into standardized text chunks.\n",
    "\n",
    "2. **Preprocessing**:\n",
    "   - Clean, tokenize, and chunk text into manageable segments.\n",
    "   - Add metadata for filtering and retrieval.\n",
    "\n",
    "3. **Embedding Generation**:\n",
    "   - Use OpenAI’s `text-embedding-ada-002` to convert text chunks into vector embeddings.\n",
    "\n",
    "4. **Vector Store**:\n",
    "   - Store embeddings and metadata in a FAISS index for similarity-based retrieval.\n",
    "\n",
    "5. **Retrieval**:\n",
    "   - Convert user queries into embeddings.\n",
    "   - Use FAISS to retrieve the top `k` relevant chunks.\n",
    "\n",
    "6. **Augmentation**:\n",
    "   - Combine retrieved data with the user query.\n",
    "   - Pass the combined input to an LLM for response generation.\n",
    "\n",
    "---\n",
    "\n",
    "### **Advantages of OpenAI + FAISS Setup**\n",
    "\n",
    "1. **Ease of Use**:\n",
    "   - OpenAI’s embedding API is simple to integrate and performs well across diverse data types.\n",
    "   - FAISS provides a fast, reliable solution for vector-based retrieval.\n",
    "\n",
    "2. **Cost Efficiency**:\n",
    "   - No need for specialized infrastructure or managed services.\n",
    "\n",
    "3. **Customizability**:\n",
    "   - FAISS allows for on-premise deployment, enabling full control over the pipeline.\n",
    "\n",
    "4. **Scalability**:\n",
    "   - Suitable for datasets with millions of vectors, with indexing options like IVF and PQ for large-scale operations.\n",
    "\n",
    "---\n",
    "\n",
    "### **Pipeline Design Steps**\n",
    "\n",
    "#### **Step 1: Preprocessing**\n",
    "- **Objective**: Standardize and prepare data for embedding.\n",
    "- **Workflow**:\n",
    "  1. Clean raw text (e.g., remove special characters, normalize casing).\n",
    "  2. Chunk long text into manageable pieces (e.g., 512 tokens).\n",
    "  3. Add metadata fields (e.g., `source`, `category`, `tags`).\n",
    "\n",
    "```python\n",
    "def preprocess_text(text, max_length=512, overlap=50):\n",
    "    \"\"\"\n",
    "    Clean and chunk text into manageable segments.\n",
    "    \"\"\"\n",
    "    # Basic cleaning (extend as needed)\n",
    "    text = text.lower().replace(\"\\n\", \" \").strip()\n",
    "    words = text.split()\n",
    "\n",
    "    # Chunking logic\n",
    "    for i in range(0, len(words), max_length - overlap):\n",
    "        yield \" \".join(words[i:i + max_length])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 2: Embedding and Indexing**\n",
    "- **Objective**: Generate embeddings and store them in a FAISS index.\n",
    "- **Workflow**:\n",
    "  - Generate embeddings for each text chunk using OpenAI’s API.\n",
    "  - Store the embeddings and associated metadata in a FAISS index.\n",
    "\n",
    "```python\n",
    "import openai\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = 1536  # Dimensionality of `text-embedding-ada-002`\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# Generate embeddings and store in FAISS\n",
    "def generate_and_store_embeddings(text_chunks):\n",
    "    embeddings = []\n",
    "    metadata = []\n",
    "\n",
    "    for chunk in text_chunks:\n",
    "        response = openai.Embedding.create(\n",
    "            input=chunk,\n",
    "            engine=\"text-embedding-ada-002\"\n",
    "        )\n",
    "        embedding = response['data'][0]['embedding']\n",
    "        embeddings.append(embedding)\n",
    "        metadata.append(chunk)  # Add chunk metadata\n",
    "\n",
    "    # Convert embeddings to numpy array and add to FAISS\n",
    "    embeddings_np = np.array(embeddings, dtype=\"float32\")\n",
    "    index.add(embeddings_np)\n",
    "\n",
    "    return metadata\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 3: Query and Retrieval**\n",
    "- **Objective**: Retrieve the top `k` relevant chunks for a user query.\n",
    "- **Workflow**:\n",
    "  - Embed the user query.\n",
    "  - Perform similarity search in the FAISS index.\n",
    "  - Return the top matches and their metadata.\n",
    "\n",
    "```python\n",
    "def retrieve_similar_chunks(query, top_k=5):\n",
    "    # Generate embedding for the query\n",
    "    query_embedding = openai.Embedding.create(\n",
    "        input=query,\n",
    "        engine=\"text-embedding-ada-002\"\n",
    "    )['data'][0]['embedding']\n",
    "\n",
    "    # Convert query to numpy array and search FAISS\n",
    "    query_np = np.array([query_embedding], dtype=\"float32\")\n",
    "    distances, indices = index.search(query_np, top_k)\n",
    "\n",
    "    # Retrieve corresponding chunks\n",
    "    results = [(metadata[i], distances[0][idx]) for idx, i in enumerate(indices[0])]\n",
    "    return results\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 4: Augmentation and Response Generation**\n",
    "- **Objective**: Use retrieved chunks to enhance the user query before passing it to an LLM.\n",
    "- **Workflow**:\n",
    "  - Combine retrieved text chunks with the user query.\n",
    "  - Generate a final response using an LLM.\n",
    "\n",
    "```python\n",
    "def generate_response(query, top_k=5):\n",
    "    # Retrieve similar chunks\n",
    "    similar_chunks = retrieve_similar_chunks(query, top_k=top_k)\n",
    "\n",
    "    # Combine query with retrieved context\n",
    "    augmented_query = query + \"\\n\\n\" + \"\\n\".join([chunk[0] for chunk in similar_chunks])\n",
    "\n",
    "    # Use LLM to generate response\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=augmented_query,\n",
    "        max_tokens=200\n",
    "    )\n",
    "    return response['choices'][0]['text']\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Next Steps**\n",
    "\n",
    "1. **Prepare Sample Data**:\n",
    "   - Use a small corpus of TIU notes, ICD codes, and MedlinePlus data for testing.\n",
    "   \n",
    "2. **Run Pipeline End-to-End**:\n",
    "   - Test the ingestion, embedding, and retrieval processes.\n",
    "\n",
    "3. **Containerize the Pipeline**:\n",
    "   - Package preprocessing, embedding, and retrieval steps in separate Docker containers.\n",
    "\n",
    "4. **Evaluate Performance**:\n",
    "   - Measure retrieval accuracy and response quality with sample queries.\n",
    "\n",
    "Would you like to proceed with implementing the code, or should we expand on containerization and orchestration for this pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b99d1dc-1f0b-4b0a-9e5a-f64cdd7231b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install sentence-transformers --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12b0d9c4-2dc2-453e-add0-f11a09811736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install faiss-cpu --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af4f593-4c0a-4819-9551-2a56eb08edac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# Initialization and Environment Setup\n",
    "# ======================================\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from anthropic import Anthropic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import openai\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Helper function to load environment variables\n",
    "def get_env_var(var: str):\n",
    "    value = os.getenv(var)\n",
    "    if value is None:\n",
    "        raise ValueError(f\"{var} not found in environment variables. Make sure it is set in your .env file.\")\n",
    "    return value\n",
    "\n",
    "# Load API keys\n",
    "langchain_api_key = get_env_var(\"LANGCHAIN_API_KEY\")\n",
    "langchain_tracing_v2 = get_env_var(\"LANGCHAIN_TRACING_V2\")\n",
    "openai_api_key = get_env_var(\"OPENAI_API_KEY\")\n",
    "anthropic_api_key = get_env_var(\"ANTHROPIC_API_KEY\")\n",
    "grok_api_key = get_env_var(\"GROK_API_KEY\")\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "# ======================================\n",
    "# Model Setup\n",
    "# ======================================\n",
    "\n",
    "# OpenAI GPT models\n",
    "gpt4o_chat = ChatOpenAI(model=\"gpt-4o\", temperature=0, openai_api_key=openai_api_key)\n",
    "gpt35_chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0, openai_api_key=openai_api_key)\n",
    "\n",
    "# Anthropic Claude models\n",
    "claude = Anthropic(api_key=anthropic_api_key)\n",
    "claude_chat = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\", temperature=0, anthropic_api_key=anthropic_api_key)\n",
    "\n",
    "# Sentence Transformer model for embeddings\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# ======================================\n",
    "# Grok API Integration (from existing code)\n",
    "# ======================================\n",
    "\n",
    "def query_grok(prompt: str, model=\"grok-beta\", stream=False, temperature=0):\n",
    "    \"\"\"\n",
    "    Query the Grok API with a user-provided prompt and return cleaned content.\n",
    "    \"\"\"\n",
    "    # Define the Grok API endpoint and headers\n",
    "    url = \"https://api.x.ai/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {grok_api_key}\"\n",
    "    }\n",
    "\n",
    "    # Define the payload\n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are Grok, a chatbot inspired by the Hitchhikers Guide to the Galaxy.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"model\": model,\n",
    "        \"stream\": stream,\n",
    "        \"temperature\": temperature\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Send the request to the Grok API\n",
    "        response = requests.post(url, headers=headers, json=payload)\n",
    "        response.raise_for_status()  # Raise an error if the request fails\n",
    "        \n",
    "        # Parse and return the relevant content\n",
    "        response_json = response.json()\n",
    "        choices = response_json.get(\"choices\", [])\n",
    "        if choices and \"content\" in choices[0].get(\"message\", {}):\n",
    "            return choices[0][\"message\"][\"content\"]  # Extract only the assistant's content\n",
    "        else:\n",
    "            return \"No content returned\"\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(\"Error querying Grok API:\", e)\n",
    "        return \"Error querying Grok API.\"\n",
    "\n",
    "\n",
    "# ======================================\n",
    "# RAG Pipeline Components\n",
    "# ======================================\n",
    "\n",
    "# Step 1: Index the Medical Corpus\n",
    "def create_faiss_index(documents):\n",
    "    \"\"\"\n",
    "    Create a FAISS index from the given corpus of documents.\n",
    "    \"\"\"\n",
    "    embeddings = embedding_model.encode(documents)\n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    index.add(np.array(embeddings))\n",
    "    return index, embeddings\n",
    "\n",
    "# Step 2: Query the Index\n",
    "def query_faiss_index(index, query, k=2):\n",
    "    \"\"\"\n",
    "    Retrieve the top-k most relevant documents for a given query.\n",
    "    \"\"\"\n",
    "    query_embedding = embedding_model.encode([query])\n",
    "    distances, indices = index.search(np.array(query_embedding), k)\n",
    "    return distances, indices\n",
    "\n",
    "# Step 3: Generate a Response\n",
    "def generate_response_with_context(context, query):\n",
    "    \"\"\"\n",
    "    Use OpenAI's GPT-4 model to generate a response based on context.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are a Medical AI Assistant. Using the following medical information, answer the query provided by the clinician.\n",
    "\n",
    "    Medical Information:\n",
    "    {context}\n",
    "\n",
    "    Clinician's Query:\n",
    "    {query}\n",
    "\n",
    "    Provide a concise response that addresses the query.\n",
    "    \"\"\"\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=150\n",
    "    )\n",
    "    return response[\"choices\"][0][\"text\"].strip()\n",
    "\n",
    "\n",
    "# ======================================\n",
    "# Unified Response Comparison with Formatting and Step-specific Saving\n",
    "# ======================================\n",
    "\n",
    "def format_response(response: str) -> str:\n",
    "    \"\"\"\n",
    "    Standardize the formatting of the model's response for consistent readability.\n",
    "    \"\"\"\n",
    "    # Split the response into sections based on categories (if applicable)\n",
    "    sections = response.split(\"\\n\")\n",
    "    formatted_response = []\n",
    "    for section in sections:\n",
    "        # Add formatting for sections that appear as headers\n",
    "        if section.strip().endswith(\":\"):\n",
    "            formatted_response.append(f\"\\n### {section.strip()}\")  # Add Markdown-style headers\n",
    "        else:\n",
    "            formatted_response.append(section.strip())  # Keep other lines as is\n",
    "    return \"\\n\".join(formatted_response)\n",
    "\n",
    "def save_comparison_to_markdown(prompt: str, results: dict, filename: str):\n",
    "    \"\"\"\n",
    "    Save the formatted output of compare_responses to a Markdown file.\n",
    "\n",
    "    Parameters:\n",
    "    - prompt: The prompt used for the comparison.\n",
    "    - results: A dictionary containing model responses.\n",
    "    - filename: The filename for the Markdown file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            # Write the prompt\n",
    "            f.write(f\"# Prompt:\\n\\n{prompt}\\n\\n\")\n",
    "            f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "            \n",
    "            # Write each model's response\n",
    "            for model, response in results.items():\n",
    "                f.write(f\"## {model} Response\\n\\n\")\n",
    "                f.write(f\"{response}\\n\\n\")\n",
    "                f.write(\"-\" * 80 + \"\\n\\n\")\n",
    "        \n",
    "        print(f\"Saved comparison results to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving comparison to {filename}: {e}\")\n",
    "\n",
    "def compare_responses(prompt: str, step_name=\"initial\", include_claude=True, include_gpt4=True, include_gpt35=True, include_grok=True, save_dir=\"outputs\"):\n",
    "    \"\"\"\n",
    "    Compare responses from different models for the same prompt, format the output, and save to step-specific Markdown files.\n",
    "\n",
    "    Parameters:\n",
    "    - prompt: The input prompt for comparison.\n",
    "    - step_name: A unique identifier for the step (e.g., \"initial\", \"step1\").\n",
    "    - include_claude: Include Claude model in the comparison.\n",
    "    - include_gpt4: Include GPT-4 model in the comparison.\n",
    "    - include_gpt35: Include GPT-3.5 model in the comparison.\n",
    "    - include_grok: Include Grok model in the comparison.\n",
    "    - save_dir: Directory to save the Markdown file.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # Collect responses from all included models\n",
    "    if include_claude:\n",
    "        claude_response = claude_chat.invoke(prompt)\n",
    "        results[\"Claude-3.5-Sonnet\"] = format_response(claude_response.content)\n",
    "\n",
    "    if include_gpt4:\n",
    "        gpt4_response = gpt4o_chat.invoke(prompt)\n",
    "        results[\"GPT-4o\"] = format_response(gpt4_response.content)\n",
    "\n",
    "    if include_gpt35:\n",
    "        gpt35_response = gpt35_chat.invoke(prompt)\n",
    "        results[\"GPT-3.5\"] = format_response(gpt35_response.content)\n",
    "\n",
    "    if include_grok:\n",
    "        grok_response = query_grok(prompt)\n",
    "        results[\"Grok-Beta\"] = format_response(grok_response)\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Generate the step-specific filename\n",
    "    output_filename = os.path.join(save_dir, f\"{step_name}_comparison_responses.md\")\n",
    "    save_comparison_to_markdown(prompt, results, output_filename)\n",
    "\n",
    "    # Display the formatted results in the console\n",
    "    print(f\"\\nPrompt: {prompt}\\n\")\n",
    "    print(\"=\" * 80)\n",
    "    for model, response in results.items():\n",
    "        print(f\"\\n{model}:\\n\")\n",
    "        print(response)\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "# ======================================\n",
    "# Medical AI Use-Case: RAG Implementation\n",
    "# ======================================\n",
    "\n",
    "# Example medical corpus\n",
    "medical_documents = [\n",
    "    \"TIU Note: Patient reported chest pain during exertion, described as pressure-like, radiating to the left arm. EKG shows ST-segment elevation, suggesting myocardial infarction. Immediate transfer to cardiology recommended.\",\n",
    "    \"TIU Note: Veteran presents with sharp pleuritic chest pain worsening with deep breaths. Imaging confirmed pulmonary embolism. Initiated anticoagulation therapy.\",\n",
    "    \"TIU Note: Veteran with a history of GERD reports chest discomfort after meals. Symptoms relieved by antacids. Endoscopy scheduled to rule out esophageal abnormalities.\",\n",
    "    \"TIU Note: Anxiety-related chest tightness reported. Symptoms associated with episodes of hyperventilation during stressful situations. Referred to behavioral health for evaluation.\",\n",
    "    \"TIU Note: Veteran complaining of acute chest pain and shortness of breath. Differential includes acute coronary syndrome, pneumonia, or musculoskeletal etiology. Labs and chest X-ray pending for further evaluation.\"\n",
    "]\n",
    "\n",
    "\n",
    "# Clinician's query\n",
    "clinician_query = \"What are the cardiovascular causes of chest pain?\"\n",
    "\n",
    "# Create FAISS index\n",
    "faiss_index, _ = create_faiss_index(medical_documents)\n",
    "\n",
    "# Query the index\n",
    "distances, indices = query_faiss_index(faiss_index, clinician_query, k=2)\n",
    "\n",
    "# Retrieve top documents\n",
    "retrieved_docs = [medical_documents[idx] for idx in indices[0]]\n",
    "\n",
    "# Combine context for generation\n",
    "context = \" \".join(retrieved_docs)\n",
    "\n",
    "# Generate response\n",
    "response = generate_response_with_context(context, clinician_query)\n",
    "\n",
    "# Display output\n",
    "print(\"Retrieved Documents:\")\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    print(f\"{i}. {doc}\")\n",
    "\n",
    "print(\"\\nGenerated Response:\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7943b891-7050-4aa7-b108-b8013c548b11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
