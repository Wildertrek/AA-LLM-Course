{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca957d72-3f50-4493-b504-28d53a041556",
   "metadata": {},
   "source": [
    "# Building a Streamlit application to act as our AI Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5708dfd4-c8b4-4db1-bf62-545b8e9133b5",
   "metadata": {},
   "source": [
    "You need to run this **Streamlit app separately** from your Jupyter notebook. **Streamlit** runs as a web app and doesn't natively integrate within a Jupyter notebook like standard Python scripts. Here's how you can run it:\n",
    "\n",
    "### **Steps to Run the Streamlit App**\n",
    "1. **Save the Code**  \n",
    "   - Save the provided code in a Python script, e.g., `app.py`.\n",
    "  \n",
    "```python\n",
    "import streamlit as st\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from anthropic import Anthropic\n",
    "from langchain_core.messages import HumanMessage  \n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "def get_env_var(var: str):\n",
    "    value = os.getenv(var)\n",
    "    if value is None:\n",
    "        raise ValueError(f\"{var} not found in environment variables. Make sure it is set in your .env file.\")\n",
    "    return value\n",
    "\n",
    "# Load API keys\n",
    "openai_api_key = get_env_var(\"OPENAI_COURSE_KEY-2\")  \n",
    "gemini_api_key = get_env_var(\"GEMINI_API_KEY\")  \n",
    "anthropic_api_key = get_env_var(\"ANTHROPIC_API_KEY\")  \n",
    "xai_api_key = get_env_var(\"XAI_API_KEY\")\n",
    "\n",
    "# Initialize LLMs\n",
    "gpt4o_chat = ChatOpenAI(model=\"gpt-4o\", temperature=0, openai_api_key=openai_api_key)\n",
    "gpt4o_mini_chat = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, openai_api_key=openai_api_key)\n",
    "claude_chat = ChatAnthropic(model=\"claude-3-5-sonnet-20241022\", temperature=0, anthropic_api_key=anthropic_api_key)\n",
    "genai.configure(api_key=gemini_api_key)  \n",
    "gemini_model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "grok_client = OpenAI(api_key=xai_api_key, base_url=\"https://api.x.ai/v1\")\n",
    "\n",
    "def query_grok(prompt: str):\n",
    "    try:\n",
    "        completion = grok_client.chat.completions.create(\n",
    "            model=\"grok-2-latest\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are Grok, a chatbot inspired by the Hitchhiker's Guide to the Galaxy.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error querying Grok: {e}\"\n",
    "\n",
    "# Streamlit App Title\n",
    "st.title(\"LLM & Agent Interaction App\")\n",
    "\n",
    "# Sidebar Configuration\n",
    "st.sidebar.header(\"Configuration\")\n",
    "llm_provider = st.sidebar.selectbox(\"Choose LLM Provider\", [\"GPT-4o\", \"GPT-4o-mini\", \"Claude-3.5-Sonnet\", \"Gemini-2.0-Flash\", \"Grok-2-Latest\"])\n",
    "user_input = st.text_area(\"Enter your prompt:\")\n",
    "\n",
    "if st.button(\"Submit Query\"):\n",
    "    if not user_input:\n",
    "        st.warning(\"Please enter a prompt before submitting.\")\n",
    "    else:\n",
    "        try:\n",
    "            if llm_provider == \"GPT-4o\":\n",
    "                response = gpt4o_chat.invoke([HumanMessage(content=user_input)]).content\n",
    "            elif llm_provider == \"GPT-4o-mini\":\n",
    "                response = gpt4o_mini_chat.invoke([HumanMessage(content=user_input)]).content\n",
    "            elif llm_provider == \"Claude-3.5-Sonnet\":\n",
    "                response = claude_chat.invoke(user_input).content\n",
    "            elif llm_provider == \"Gemini-2.0-Flash\":\n",
    "                response = gemini_model.generate_content(user_input).text\n",
    "            elif llm_provider == \"Grok-2-Latest\":\n",
    "                response = query_grok(user_input)\n",
    "            else:\n",
    "                response = \"Invalid model selection.\"\n",
    "            st.success(response)\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error: {e}\")\n",
    "\n",
    "```\n",
    "\n",
    "2. **Install Streamlit (if not installed)**\n",
    "   ```bash\n",
    "   pip install streamlit langchain openai google-generativeai langchain-anthropic\n",
    "\n",
    "\n",
    "   ```\n",
    "\n",
    "3. **Run the App**\n",
    "   Navigate to the directory where your `app.py` file is located and run:\n",
    "   ```bash\n",
    "   streamlit run app.py\n",
    "   ```\n",
    "   This will launch a web interface in your browser.\n",
    "\n",
    "### **Running in Jupyter Notebook?**\n",
    "If you want to use **Streamlit within a Jupyter Notebook**, you can try using **`ipywidgets`** or **`streamlit_jupyter`**:\n",
    "```bash\n",
    "pip install streamlit_jupyter\n",
    "```\n",
    "Then, inside your notebook:\n",
    "```python\n",
    "from streamlit_jupyter import StreamlitPatcher, magic\n",
    "\n",
    "StreamlitPatcher().jupyter()\n",
    "```\n",
    "However, **this approach is experimental**, and it's generally better to run **Streamlit as a standalone web app**.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
