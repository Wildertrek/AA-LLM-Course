{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a23547f5-875d-4d03-a58e-1b4a6f485124",
   "metadata": {},
   "source": [
    "# Autogen\n",
    "\n",
    "- [Autogen](https://www.microsoft.com/en-us/research/project/autogen/)\n",
    "- [Autogen GitHub](https://github.com/microsoft/autogen)\n",
    "- [Autogen Downloads](https://microsoft.github.io/autogen/stable/)\n",
    "- [LLF-Bench](https://github.com/microsoft/LLF-Bench)\n",
    "- [Magentic-One](https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/magentic-one.html)\n",
    "- [AgentChat](https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/index.html)\n",
    "- [Autogen Studio](https://microsoft.github.io/autogen/stable/user-guide/autogenstudio-user-guide/index.html)\n",
    "- [Autogent Core Quickstart](https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/quickstart.html)\n",
    "- [Autogen Community Extensions](https://microsoft.github.io/autogen/stable/user-guide/extensions-user-guide/discover.html)\n",
    "- [Autogen API Reference](https://microsoft.github.io/autogen/stable/reference/index.html)\n",
    "- [Autogen Notebook Examples](https://microsoft.github.io/autogen/0.2/docs/Examples/?utm_source=chatgpt.com)\n",
    "- [AG2 Github](https://github.com/ag2ai/ag2)\n",
    "- [AG2 Website](https://ag2.ai/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a452a5-ef4a-47a6-af72-53e40b52e405",
   "metadata": {},
   "source": [
    "â€‹Microsoft AutoGen is an open-source framework designed to facilitate the creation of AI agents and enable collaboration among multiple agents to address complex tasks. It provides a structured environment for developing agentic AI applications, emphasizing modularity, scalability, and ease of use. \n",
    "\n",
    "**Key Features of AutoGen:**\n",
    "\n",
    "- **Asynchronous Messaging:** Agents communicate through asynchronous messages, supporting both event-driven and request/response interaction patterns.\n",
    "\n",
    "- **Modular and Extensible Architecture:** The framework allows for easy customization with pluggable components, including custom agents, tools, memory modules, and models.\n",
    "\n",
    "- **Observability and Debugging Tools:** Built-in tools provide tracking, tracing, and debugging capabilities for agent interactions and workflows, with support for industry-standard observability protocols like OpenTelemetry.\n",
    "\n",
    "- **Scalability and Distribution:** Users can design complex, distributed agent networks that operate seamlessly across various environments.\n",
    "\n",
    "- **Cross-Language Support:** AutoGen supports interoperability between agents built in different programming languages, currently including Python and .NET, with plans for additional languages.\n",
    "\n",
    "**Developer Tools:**\n",
    "\n",
    "To complement the framework, Microsoft offers [Magentic-One](https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/magentic-one.html) and [AutoGen Studio](https://microsoft.github.io/autogen/stable/user-guide/autogenstudio-user-guide/index.html), a low-code interface that enables rapid prototyping and testing of multi-agent workflows. AutoGen Studio provides features such as a drag-and-drop team builder, real-time agent updates, and interactive debugging tools, making it accessible for developers with varying levels of coding expertise. \n",
    "\n",
    "**Getting Started:**\n",
    "\n",
    "Developers interested in utilizing AutoGen can access the framework and its resources through the official GitHub repository. The repository includes comprehensive documentation, installation guides, and examples to assist in building and deploying agentic AI applications. \n",
    "\n",
    "For a visual introduction and deeper understanding of AutoGen's capabilities, you might find the following video helpful:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2008716e-4e4b-420c-927a-5c9fd619a817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"450\"\n",
       "            src=\"https://www.youtube.com/embed/vU2S6dVf79M\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x7fbf286efb10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('vU2S6dVf79M', width=800, height=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d885989e-1b6d-44ce-a3d0-903aad8b1e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"450\"\n",
       "            src=\"https://www.youtube.com/embed/vQyjKF-DUd0\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x7fbf285197d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://youtu.be/vQyjKF-DUd0\n",
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('vQyjKF-DUd0', width=800, height=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1071db59-fadd-4388-a4ca-6baebe18226f",
   "metadata": {},
   "source": [
    "AutoGen has undergone significant changes from version 0.2 to version 0.4, focusing on enhancing scalability, flexibility, and developer experience. Here are the key differences:\n",
    "\n",
    "**1. Architectural Overhaul:**\n",
    "- **Event-Driven Actor Model:** Version 0.4 adopts an event-driven actor model, enabling distributed and highly scalable agentic systems. This design enhances composability, allowing developers to integrate agents implemented in various frameworks or programming languages. \n",
    "\n",
    "**2. API Layering:**\n",
    "- **Core API:** Provides the foundational components for building event-driven agentic systems.\n",
    "- **AgentChat API:** Built atop the Core API, it offers a high-level framework for constructing interactive agent applications, replacing the previous architecture in version 0.2.\n",
    "- **Extensions API:** Facilitates third-party integrations and implementations, such as Azure code executors and OpenAI model clients.\n",
    "\n",
    "**3. Asynchronous Communication:**\n",
    "- Version 0.4 introduces asynchronous messaging, allowing agents to communicate through both event-driven and request/response interaction patterns. This shift enhances the flexibility and responsiveness of agent interactions. \n",
    "\n",
    "**4. Modular and Extensible Design:**\n",
    "- The new version emphasizes a modular architecture, enabling developers to customize systems with pluggable components, including custom agents, tools, memory modules, and models. This design supports the creation of proactive and long-running agents using event-driven patterns.\n",
    "\n",
    "**5. Enhanced Observability and Debugging:**\n",
    "- Built-in metric tracking, message tracing, and debugging tools provide improved monitoring and control over agent interactions and workflows, addressing previous challenges in debugging and scaling agent applications.\n",
    "\n",
    "**6. Package Restructuring:**\n",
    "- With version 0.4, AutoGen has restructured its Python packages into `autogen-core`, `autogen-agentchat`, and `autogen-ext` to align with the new architecture. \n",
    "\n",
    "For users transitioning from version 0.2 to 0.4, a comprehensive migration guide is available, detailing the necessary steps and changes. \n",
    "\n",
    "These advancements in AutoGen 0.4 aim to provide a more robust, scalable, and developer-friendly framework for building AI agents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a03e4685-ac81-4cac-8ad7-66483054a490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --quiet -U 'autogen-ext[openai]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f4975ec-9887-4594-abea-41e95b77c559",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --quiet -U autogen-agentchat python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "300c949c-af3b-45ff-9bd0-db2d6ee3ab6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Hello! AutoGen is a framework that simplifies the creation and deployment of AI agents by providing tools to define, manage, and interact with them. Here's a general guide on how you can use AutoGen to build AI agents:\n",
      "\n",
      "1. **Installation**: \n",
      "   - First, ensure you have Python installed on your machine. \n",
      "   - Install AutoGen via pip:\n",
      "     ```bash\n",
      "     pip install autogen\n",
      "     ```\n",
      "\n",
      "2. **Define Your Agents**:\n",
      "   - You can define agents by specifying their behaviors, goals, and interactions. AutoGen provides a way to define these agents using configuration files or code. For example:\n",
      "     ```python\n",
      "     from autogen import Agent\n",
      "\n",
      "     class MyAgent(Agent):\n",
      "         def __init__(self):\n",
      "             super().__init__(name=\"MyAgent\")\n",
      "\n",
      "         def act(self, observation):\n",
      "             # Define how the agent acts based on observations\n",
      "             action = some_logic_based_on_observation(observation)\n",
      "             return action\n",
      "     ```\n",
      "\n",
      "3. **Create an Environment**:\n",
      "   - Agents often operate within an environment. You can define a custom environment where your agents will interact. This is crucial for testing and simulating agent behaviors.\n",
      "\n",
      "4. **Agent Interaction**:\n",
      "   - Once you have agents and the environment set up, the next step is to manage the interaction flow. This includes deciding how agents receive data, process it, and respond. In AutoGen, you can script these interactions or use high-level functions for common patterns.\n",
      "\n",
      "5. **Run Simulations**:\n",
      "   - With your agents and environment in place, you can set up simulations to see how your agents perform. This helps in testing hypotheses, refining agent logic, and ensuring that they achieve their goals.\n",
      "\n",
      "6. **Monitoring and Logging**:\n",
      "   - AutoGen allows you to set up logging for your agents' actions and decisions, which is helpful for debugging and improving their performance over time.\n",
      "\n",
      "7. **Deployment**:\n",
      "   - Once satisfied with the agentsâ€™ performance in simulations, you can deploy them in real-world applications or larger simulated environments.\n",
      "\n",
      "8. **Continuous Improvement**:\n",
      "   - Continuously gather feedback and data from agents' interactions to refine and improve their decision-making algorithms.\n",
      "\n",
      "AutoGen can significantly speed up the process of developing AI agents by handling much of the underlying complexity. The key to successful use is to thoroughly understand each agentâ€™s objectives and how they should interact within their environment. As you grow more comfortable with the framework, you'll be able to craft more sophisticated agents tailored to specific tasks.\n"
     ]
    }
   ],
   "source": [
    "# %%capture --no-stderr\n",
    "# %pip install --quiet -U autogen-agentchat 'autogen-ext[openai]' python-dotenv\n",
    "# simple test to ensure it's functional\n",
    "\n",
    "import os\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.messages import TextMessage  # Import the TextMessage class\n",
    "from autogen_core import CancellationToken  # Import CancellationToken\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the OpenAI API key from environment variables\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in environment variables. Check your .env file.\")\n",
    "\n",
    "# Initialize the OpenAI model client with the API key\n",
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o\", api_key=openai_api_key)\n",
    "\n",
    "# Create the assistant agent\n",
    "assistant = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    system_message=\"You are a helpful assistant.\",\n",
    "    model_client=model_client,\n",
    ")\n",
    "\n",
    "# Define the main asynchronous function\n",
    "async def main():\n",
    "    # Define the user's input\n",
    "    user_input = \"Hello! How can I use AutoGen to build AI agents?\"\n",
    "    \n",
    "    # Create a TextMessage object\n",
    "    user_message = TextMessage(content=user_input, source=\"user\")\n",
    "    \n",
    "    # Create a cancellation token\n",
    "    cancellation_token = CancellationToken()\n",
    "    \n",
    "    # Send the user's input to the assistant agent and get the response\n",
    "    response = await assistant.on_messages(\n",
    "        [user_message],\n",
    "        cancellation_token\n",
    "    )\n",
    "    \n",
    "    # Print the assistant's response\n",
    "    print(\"Assistant:\", response.chat_message.content)\n",
    "\n",
    "# Run the main function\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31eb7a3-a166-4a09-8a9f-ed229ee80cc6",
   "metadata": {},
   "source": [
    "Assistant: Hello! AutoGen is a framework designed to simplify the creation and management of AI agents that can interact with each other and with humans in a dynamic environment. Here's a basic step-by-step guide on how you can use AutoGen to build AI agents:\n",
    "\n",
    "1. **Installation**:\n",
    "   Make sure you have AutoGen installed. If it's available as a Python package, you can typically install it using pip:\n",
    "\n",
    "   ```bash\n",
    "   pip install autogen-framework\n",
    "   ```\n",
    "\n",
    "   Replace `autogen-framework` with the actual package name if it differs.\n",
    "\n",
    "2. **Understand the Framework**:\n",
    "   Familiarize yourself with the core concepts of AutoGen, such as:\n",
    "\n",
    "   - **Agents**: These are the AI entities that can perform actions, interact with each other, and learn from the environment.\n",
    "   - **Environment**: This is the setting in which agents operate and interact. It can include various tasks and objectives for agents.\n",
    "   - **Schedulers**: Mechanisms that manage agent interactions and sequence actions in the environment.\n",
    "\n",
    "3. **Define Your Agents**:\n",
    "   Decide what kind of agents you want to create. This involves specifying their roles, capabilities, and goals. You will need to define the logic and behavior for each agent. For example:\n",
    "\n",
    "   ```python\n",
    "   from autogen import Agent\n",
    "\n",
    "   class MyAgent(Agent):\n",
    "       def __init__(self, name):\n",
    "           super().__init__(name)\n",
    "       \n",
    "       def perform_action(self):\n",
    "           # Define what actions this agent can perform\n",
    "           print(f\"{self.name} is performing an action\")\n",
    "   ```\n",
    "\n",
    "4. **Set Up the Environment**:\n",
    "   Create the environment where your agents will operate. This involves specifying rules, resources, and any other elements that define the operational context.\n",
    "\n",
    "   ```python\n",
    "   from autogen import Environment\n",
    "\n",
    "   class MyEnvironment(Environment):\n",
    "       def __init__(self):\n",
    "           super().__init__()\n",
    "       \n",
    "       def update(self):\n",
    "           # Update the state of the environment\n",
    "           print(\"Environment is updating\")\n",
    "   ```\n",
    "\n",
    "5. **Manage Interactions**:\n",
    "   Use schedulers or other mechanisms provided by AutoGen to handle how and when agents interact with each other and the environment.\n",
    "\n",
    "   ```python\n",
    "   from autogen import Scheduler\n",
    "\n",
    "   class MyScheduler(Scheduler):\n",
    "       def __init__(self, agents, environment):\n",
    "           super().__init__(agents, environment)\n",
    "       \n",
    "       def run(self):\n",
    "           for agent in self.agents:\n",
    "               agent.perform_action()\n",
    "           self.environment.update()\n",
    "   ```\n",
    "\n",
    "6. **Execute and Iterate**:\n",
    "   Initialize your agents and environment, and use the scheduler to run your multi-agent system. You can iterate on your design by refining agent behaviors and environmental interactions.\n",
    "\n",
    "   ```python\n",
    "   agent1 = MyAgent(\"Agent1\")\n",
    "   agent2 = MyAgent(\"Agent2\")\n",
    "   environment = MyEnvironment()\n",
    "   scheduler = MyScheduler([agent1, agent2], environment)\n",
    "\n",
    "   scheduler.run()\n",
    "   ```\n",
    "\n",
    "7. **Extend and Customize**:\n",
    "   AutoGen likely provides various tools and utilities to extend functionality, like integrating machine learning models, processing human input, etc. Explore the documentation to discover additional features you can leverage to make your agents more sophisticated.\n",
    "\n",
    "By following these steps and leveraging the capabilities of AutoGen, you can build and manage your own AI agents effectively. Be sure to check the specific documentation and resources available for AutoGen to get the most out of the framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07804bbb-6eb1-4917-b487-a77e9a0a28c3",
   "metadata": {},
   "source": [
    "## Handle multiple user queries\n",
    "Here's an example of how to set up an AutoGen v0.4 assistant agent that can handle multiple user queries in a Jupyter Notebook. This example demonstrates how to initialize the agent, process user inputs, and handle multiple interactions within a single session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bcbe3624-1baa-41de-8631-abc41690c802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  What is the weather for Knoxville, TN?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: I'm not sure which city/state you want weather for. Please specify the location clearly. \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  What is the weather for Virginia Beach, VA?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: I'm not sure which city/state you want weather for. Please specify the location clearly. \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  How can I use Microsoft's Autogen Framework?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Microsoft's Autogen Framework is designed to enable seamless interactions between multiple AI models, allowing them to collaborate and enhance task performance. Here's a high-level overview of how you can use Microsoft's Autogen Framework:\n",
      "\n",
      "1. **Install the Framework**: Ensure you have the necessary environment to run the Autogen Framework, which might include Python and other dependencies specific to the framework. Installation details can typically be found in the project's documentation or repository (e.g., on GitHub).\n",
      "\n",
      "2. **Understand the Components**: Familiarize yourself with the main components of the framework. This usually includes:\n",
      "\n",
      "   - **Agents**: These are AI models designed to perform specific tasks. Each agent has capabilities and can communicate with other agents.\n",
      "   - **Orchestrator**: This component manages the flow of information between agents, ensuring they collaborate effectively.\n",
      "\n",
      "3. **Define the Task**: Establish clear objectives for what you want to achieve with the framework. This could be automating a process, improving a customer service flow, etc.\n",
      "\n",
      "4. **Configure Agents**: Set up and configure agents within the framework. This involves selecting suitable AI models for each task and tuning them as needed to improve performance and accuracy.\n",
      "\n",
      "5. **Program the Orchestrator**: Develop logic for the orchestrator to manage agent interactions. This includes deciding when and how agents should communicate and collaborate.\n",
      "\n",
      "6. **Testing and Iteration**: Implement a testing phase to ensure the framework operates as intended and agents interact without errors. Perform iterations to fine-tune the system based on performance metrics and user feedback.\n",
      "\n",
      "7. **Deployment**: Once satisfied with the framework's performance, deploy it to your intended environment, ensuring scalability and robustness of the system.\n",
      "\n",
      "8. **Monitoring and Maintenance**: Continuously monitor the system for performance issues or areas needing improvement. Be prepared to update agents or the orchestrator as new models or requirements become available.\n",
      "\n",
      "For detailed instructions, it's best to refer to the specific documentation provided by Microsoft for the Autogen Framework, as it would include comprehensive guides, code samples, and API references tailored to the framework's capabilities and use cases. \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  what is the weather for Bethesda, MD?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: I'm not sure which city/state you want weather for. Please specify the location clearly. \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  What is the weather for London, England?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: I'm not sure which city/state you want weather for. Please specify the location clearly. \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the assistant. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# good example\n",
    "import os\n",
    "import time\n",
    "import asyncio\n",
    "import logging\n",
    "import openai\n",
    "import requests\n",
    "import yaml\n",
    "import re\n",
    "from requests.utils import quote\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "# Uncomment these lines if you want *raw* HTTP-level debug output:\n",
    "\"\"\"\n",
    "import http.client as http_client\n",
    "http_client.HTTPConnection.debuglevel = 1\n",
    "logging.getLogger(\"http.client\").setLevel(logging.DEBUG)\n",
    "logging.getLogger(\"http.client\").propagate = True\n",
    "\"\"\"\n",
    "\n",
    "# ---- Constants ----\n",
    "EXIT_COMMANDS = {\"exit\", \"quit\", \"!exit\"}\n",
    "CANCEL_COMMAND = \"!cancel\"\n",
    "DEFAULT_MODEL = \"gpt-4o\"\n",
    "DEFAULT_SYSTEM_MESSAGE = \"You are a helpful assistant.\"\n",
    "CONFIG_FILE = \"config.yaml\"\n",
    "LOG_FILE = \"log.txt\"\n",
    "\n",
    "# ---- Configure Very Verbose Logging ----\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)  # Set to DEBUG for very verbose output\n",
    "\n",
    "# Remove any existing handlers (useful if re-running in Jupyter)\n",
    "for handler in logger.handlers[:]:\n",
    "    logger.removeHandler(handler)\n",
    "\n",
    "file_handler = logging.FileHandler(LOG_FILE)\n",
    "formatter = logging.Formatter(\n",
    "    '%(asctime)s - %(levelname)s - %(module)s - %(funcName)s:%(lineno)d - %(message)s'\n",
    ")\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "logger.debug(\"Logger initialized at DEBUG level. Very verbose mode is enabled.\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Verbose client for the main assistant calls (GPT). Logs raw request/response.\n",
    "# ---------------------------------------------------------------------------\n",
    "class VerboseOpenAIChatCompletionClient(OpenAIChatCompletionClient):\n",
    "    \"\"\"\n",
    "    An extension of OpenAIChatCompletionClient that logs detailed request/response data\n",
    "    at INFO level, matching your prior logging style.\n",
    "    \"\"\"\n",
    "    async def _send_request(self, messages, **kwargs):\n",
    "        url = \"https://api.openai.com/v1/chat/completions\"\n",
    "        logger.info(f\"HTTP Request: POST {url} 'HTTP/1.1 200 OK'\")\n",
    "        response = await super()._send_request(messages, **kwargs)\n",
    "\n",
    "        import json\n",
    "        log_payload = {\n",
    "            \"type\": \"LLMCall\",\n",
    "            \"messages\": messages,\n",
    "            \"response\": response\n",
    "        }\n",
    "        logger.info(json.dumps(log_payload))\n",
    "        logger.debug(\"Received response from OpenAI (debug): %s\", response)\n",
    "        return response\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# WeatherAgent for queries containing \"weather\"\n",
    "# Now uses Fahrenheit data (&u) and parses temp_F, FeelsLikeF.\n",
    "# ---------------------------------------------------------------------------\n",
    "class WeatherAgent(AssistantAgent):\n",
    "    \"\"\"\n",
    "    A specialized agent that queries wttr.in for weather data in Fahrenheit (USCS).\n",
    "    \"\"\"\n",
    "    async def on_messages(self, messages, cancellation_token=None):\n",
    "        user_message = messages[-1].content\n",
    "        logger.debug(f\"[WeatherAgent] Received message: {user_message}\")\n",
    "\n",
    "        city = self._extract_city(user_message)\n",
    "        if not city:\n",
    "            city = await self._extract_city_with_llm(user_message)\n",
    "            if not city:\n",
    "                response_text = (\n",
    "                    \"I'm not sure which city/state you want weather for. \"\n",
    "                    \"Please specify the location clearly.\"\n",
    "                )\n",
    "                return TextMessage(content=response_text, source=\"assistant\")\n",
    "\n",
    "        weather_info = self._fetch_weather(city)\n",
    "        if weather_info:\n",
    "            response_text = f\"The current weather in {city}:\\n{weather_info}\"\n",
    "        else:\n",
    "            response_text = f\"Sorry, I couldn't fetch weather data for {city}.\"\n",
    "\n",
    "        logger.debug(f\"[WeatherAgent] Responding: {response_text}\")\n",
    "        return TextMessage(content=response_text, source=\"assistant\")\n",
    "\n",
    "    def _extract_city(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Improved approach to extract the city and state from user text.\n",
    "        Handles more variations in input.\n",
    "        \"\"\"\n",
    "        match = re.search(r\"weather in\\s+([A-Za-z\\s]+(?:,\\s*[A-Za-z]{2,})?)\", text.lower())\n",
    "        if match:\n",
    "            city_name = match.group(1).strip()\n",
    "            # Remove any remaining non-alphanumeric characters except spaces and commas\n",
    "            city_name = re.sub(r\"[^\\w\\s,]\", \"\", city_name)\n",
    "            # Convert multiple spaces to single spaces\n",
    "            city_name = re.sub(r\"\\s+\", \" \", city_name)\n",
    "            city_name = city_name.strip().title()  # Title case\n",
    "            return city_name\n",
    "        return None\n",
    "\n",
    "    async def _extract_city_with_llm(self, user_text: str) -> str:\n",
    "        \"\"\"\n",
    "        Uses GPT to extract the city and state/country, if present.\n",
    "        If GPT can't find a city, returns None.\n",
    "        \"\"\"\n",
    "        system_prompt = (\n",
    "            \"You are a location extraction assistant. Your task is to identify the city and state (or country) from user queries about the weather.\\n\"\n",
    "            \"Return ONLY the city and state/country, separated by a comma and a space. For example: 'Orlando, FL' or 'Tokyo, Japan'.\\n\"\n",
    "            \"If the query does not contain a location, or if you are unsure, return 'NONE'.\\n\"\n",
    "            \"Here are some examples:\\n\"\n",
    "            \"User: What is the weather in Orlando, FL?\\n\"\n",
    "            \"Assistant: Orlando, FL\\n\"\n",
    "            \"User: What is the weather in Washington, DC?\\n\"\n",
    "            \"Assistant: Washington, DC\\n\"\n",
    "            \"User: What is the weather in Virginia Beach, VA?\\n\"\n",
    "            \"Assistant: Virginia Beach, VA\\n\"\n",
    "            \"User: What is the weather in Tokyo, Japan?\\n\"\n",
    "            \"Assistant: Tokyo, Japan\\n\"\n",
    "            \"User: Tell me a joke\\n\"\n",
    "            \"Assistant: NONE\\n\"\n",
    "        )\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_text},\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            completion = await self.parser_client.acompletion(\n",
    "                messages=messages,\n",
    "                temperature=0.0,\n",
    "                max_tokens=30,\n",
    "                top_p=1.0\n",
    "            )\n",
    "            raw_location = completion[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "            logger.debug(f\"[WeatherAgent] LLM raw location extraction: '{raw_location}'\")\n",
    "\n",
    "            if raw_location.upper() == \"NONE\":\n",
    "                logger.debug(\"[WeatherAgent] LLM returned 'NONE'.\")\n",
    "                return None\n",
    "\n",
    "            # Split the string by comma and space\n",
    "            parts = [part.strip() for part in raw_location.split(\", \")]  # Split by comma and space\n",
    "\n",
    "            if len(parts) == 2:\n",
    "                city, state = parts\n",
    "                cleaned_city = f\"{city}, {state}\"  # Reassemble with comma and space\n",
    "                logger.debug(f\"[WeatherAgent] Extracted city and state: '{cleaned_city}'\")\n",
    "                return cleaned_city\n",
    "            elif len(parts) == 1:\n",
    "                city = parts[0]\n",
    "                cleaned_city = city\n",
    "                logger.debug(f\"[WeatherAgent] Extracted city only: '{cleaned_city}'\")\n",
    "                return cleaned_city\n",
    "            else:\n",
    "                logger.warning(f\"[WeatherAgent] Unexpected LLM output format: '{raw_location}'\")  # Log unexpected output\n",
    "                return None\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error calling GPT for location extraction: {e}\", exc_info=True)\n",
    "            return None\n",
    "\n",
    "    def _fetch_weather(self, city: str) -> str:\n",
    "        \"\"\"\n",
    "        Calls wttr.in with city name (URL-encoded) requesting Fahrenheit data.\n",
    "        Prioritizes full state name for Florida.\n",
    "        If that fails for a city, state abbreviation, tries the full state name.\n",
    "        Returns a string like \"Overcast, 60Â°F (feels like 58Â°F)\"\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Prioritize full state name for Florida\n",
    "            if \"Orlando, Fl\" in city or \"Miami, Fl\" in city:\n",
    "                city_parts = city.split(\", \")\n",
    "                if len(city_parts) == 2:\n",
    "                    city_name, state_abbreviation = city_parts\n",
    "                    full_state_name = self._get_full_state_name(state_abbreviation)\n",
    "                    if full_state_name:\n",
    "                        full_city = f\"{city_name}, {full_state_name}\"\n",
    "                        city = full_city  # Use the full city for the initial request\n",
    "\n",
    "            city_encoded = quote(city)\n",
    "            # Use &u for Fahrenheit\n",
    "            url = f\"https://wttr.in/{city_encoded}?format=j1&u\"\n",
    "            logger.debug(f\"[WeatherAgent] Calling wttr.in URL: {url}\")\n",
    "\n",
    "            resp = requests.get(url, timeout=10)\n",
    "            resp.raise_for_status()\n",
    "            data = resp.json()\n",
    "            logger.debug(f\"[WeatherAgent] wttr.in response data: {data}\")  # Log the data\n",
    "\n",
    "            current = data.get(\"current_condition\", [{}])[0]\n",
    "            desc = current.get(\"weatherDesc\", [{}])[0].get(\"value\", \"Unknown\")\n",
    "            temp_f = current.get(\"temp_F\", \"?\")\n",
    "            feels_like_f = current.get(\"FeelsLikeF\", \"?\")\n",
    "            return f\"{desc}, {temp_f}Â°F (feels like {feels_like_f}Â°F)\"\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fetching weather for '{city}': {e}\", exc_info=True)\n",
    "\n",
    "            # If the city contains a state abbreviation, try the full state name\n",
    "            if \", \" in city:\n",
    "                city_parts = city.split(\", \")\n",
    "                if len(city_parts) == 2:\n",
    "                    city_name, state_abbreviation = city_parts\n",
    "                    full_state_name = self._get_full_state_name(state_abbreviation)\n",
    "                    if full_state_name:\n",
    "                        try:\n",
    "                            full_city = f\"{city_name}, {full_state_name}\"\n",
    "                            city_encoded = quote(full_city)\n",
    "                            url = f\"https://wttr.in/{city_encoded}?format=j1&u\"\n",
    "                            logger.debug(f\"[WeatherAgent] Retrying with full state name: {url}\")\n",
    "\n",
    "                            resp = requests.get(url, timeout=10)\n",
    "                            resp.raise_for_status()\n",
    "                            data = resp.json()\n",
    "                            logger.debug(f\"[WeatherAgent] wttr.in retry response data: {data}\") #Log retry data\n",
    "\n",
    "                            current = data.get(\"current_condition\", [{}])[0]\n",
    "                            desc = current.get(\"weatherDesc\", [{}])[0].get(\"value\", \"Unknown\")\n",
    "                            temp_f = current.get(\"temp_F\", \"?\")\n",
    "                            feels_like_f = current.get(\"FeelsLikeF\", \"?\")\n",
    "                            return f\"{desc}, {temp_f}Â°F (feels like {feels_like_f}Â°F)\"\n",
    "                        except Exception as e:\n",
    "                            logger.error(f\"Error fetching weather for '{full_city}': {e}\", exc_info=True)\n",
    "                            return None\n",
    "            return None\n",
    "\n",
    "    def _get_full_state_name(self, state_abbreviation: str) -> str:\n",
    "        \"\"\"\n",
    "        A simple helper function to convert state abbreviations to full names.\n",
    "        \"\"\"\n",
    "        state_map = {\n",
    "            \"AL\": \"Alabama\",\n",
    "            \"AK\": \"Alaska\",\n",
    "            \"AZ\": \"Arizona\",\n",
    "            \"AR\": \"Arkansas\",\n",
    "            \"CA\": \"California\",\n",
    "            \"CO\": \"Colorado\",\n",
    "            \"CT\": \"Connecticut\",\n",
    "            \"DE\": \"Delaware\",\n",
    "            \"FL\": \"Florida\",\n",
    "            \"GA\": \"Georgia\",\n",
    "            \"HI\": \"Hawaii\",\n",
    "            \"ID\": \"Idaho\",\n",
    "            \"IL\": \"Illinois\",\n",
    "            \"IN\": \"Indiana\",\n",
    "            \"IA\": \"Iowa\",\n",
    "            \"KS\": \"Kansas\",\n",
    "            \"KY\": \"Kentucky\",\n",
    "            \"LA\": \"Louisiana\",\n",
    "            \"ME\": \"Maine\",\n",
    "            \"MD\": \"Maryland\",\n",
    "            \"MA\": \"Massachusetts\",\n",
    "            \"MI\": \"Michigan\",\n",
    "            \"MN\": \"Minnesota\",\n",
    "            \"MS\": \"Mississippi\",\n",
    "            \"MO\": \"Missouri\",\n",
    "            \"MT\": \"Montana\",\n",
    "            \"NE\": \"Nebraska\",\n",
    "            \"NV\": \"Nevada\",\n",
    "            \"NH\": \"New Hampshire\",\n",
    "            \"NJ\": \"New Jersey\",\n",
    "            \"NM\": \"New Mexico\",\n",
    "            \"NY\": \"New York\",\n",
    "            \"NC\": \"North Carolina\",\n",
    "            \"ND\": \"North Dakota\",\n",
    "            \"OH\": \"Ohio\",\n",
    "            \"OK\": \"Oklahoma\",\n",
    "            \"OR\": \"Oregon\",\n",
    "            \"PA\": \"Pennsylvania\",\n",
    "            \"RI\": \"Rhode Island\",\n",
    "            \"SC\": \"South Carolina\",\n",
    "            \"SD\": \"South Dakota\",\n",
    "            \"TN\": \"Tennessee\",\n",
    "            \"TX\": \"Texas\",\n",
    "            \"UT\": \"Utah\",\n",
    "            \"VT\": \"Vermont\",\n",
    "            \"VA\": \"Virginia\",\n",
    "            \"WA\": \"Washington\",\n",
    "            \"WV\": \"West Virginia\",\n",
    "            \"WI\": \"Wisconsin\",\n",
    "            \"WY\": \"Wyoming\",\n",
    "            \"DC\": \"District of Columbia\",\n",
    "        }\n",
    "        return state_map.get(state_abbreviation.upper())\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Main ChatApplication\n",
    "# ---------------------------------------------------------------------------\n",
    "class ChatApplication:\n",
    "    \"\"\"\n",
    "    An interactive chat application with:\n",
    "      1) A main assistant agent (GPT-based)\n",
    "      2) A weather agent (wttr.in, Fahrenheit)\n",
    "    Logs are very verbose; any 'weather' queries route to WeatherAgent.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        logger.debug(\"Initializing ChatApplication with config: %s\", config)\n",
    "        self.config = config\n",
    "        self.openai_api_key = self._load_api_key()\n",
    "\n",
    "        # Create a verbose model client for GPT-based calls\n",
    "        self.model_client = self._create_model_client()\n",
    "\n",
    "        # The main \"assistant\" for general queries\n",
    "        self.assistant = AssistantAgent(\n",
    "            name=\"assistant\",\n",
    "            system_message=self.config.get(\"system_message\", DEFAULT_SYSTEM_MESSAGE),\n",
    "            model_client=self.model_client,\n",
    "        )\n",
    "\n",
    "        # A specialized \"weather_agent\" for weather queries\n",
    "        self.weather_agent = WeatherAgent(\n",
    "            name=\"weather_agent\",\n",
    "            system_message=\"You are a specialized weather agent.\",\n",
    "            model_client=self.model_client\n",
    "        )\n",
    "\n",
    "    def _load_api_key(self):\n",
    "        \"\"\"Loads the OpenAI API key from environment variables.\"\"\"\n",
    "        logger.debug(\"Attempting to load OPENAI_API_KEY from environment variables.\")\n",
    "        openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not openai_api_key:\n",
    "            logger.error(\"OPENAI_API_KEY not found in environment variables.\")\n",
    "            raise ValueError(\"OPENAI_API_KEY not found. Check your .env file or env settings.\")\n",
    "        logger.debug(\"Successfully loaded OPENAI_API_KEY.\")\n",
    "        return openai_api_key\n",
    "\n",
    "    def _create_model_client(self):\n",
    "        \"\"\"Creates the OpenAI client based on the configuration.\"\"\"\n",
    "        model = self.config.get(\"model\", DEFAULT_MODEL)\n",
    "        logger.debug(\"Creating VerboseOpenAIChatCompletionClient with model: %s\", model)\n",
    "        return VerboseOpenAIChatCompletionClient(model=model, api_key=self.openai_api_key)\n",
    "\n",
    "    async def run(self):\n",
    "        \"\"\"\n",
    "        Runs the main interaction loop. If the user's message includes \"weather\",\n",
    "        we delegate to WeatherAgent; else we call the main assistant agent.\n",
    "        \"\"\"\n",
    "        logger.debug(\"Entering main run loop (outer) for ChatApplication.\")\n",
    "        while True:\n",
    "            cancellation_token = CancellationToken()\n",
    "            conversation_history = []\n",
    "            logger.debug(\"Initialized new conversation history; now starting inner loop.\")\n",
    "\n",
    "            try:\n",
    "                while True:\n",
    "                    user_input = input(\"User: \")\n",
    "                    user_input_lower = user_input.lower()\n",
    "\n",
    "                    if user_input_lower in EXIT_COMMANDS:\n",
    "                        logger.info(\"User issued exit command. Exiting application.\")\n",
    "                        print(\"Exiting the assistant. Goodbye!\")\n",
    "                        return\n",
    "\n",
    "                    if user_input_lower == CANCEL_COMMAND:\n",
    "                        logger.info(\"User issued cancel command.\")\n",
    "                        print(\"Cancelling the current operation.\\n\")\n",
    "                        cancellation_token.cancel()\n",
    "                        continue\n",
    "\n",
    "                    # Log user input\n",
    "                    user_message = TextMessage(content=user_input, source=\"user\")\n",
    "                    conversation_history.append(user_message)\n",
    "                    logger.info(f\"User message: {user_input}\")\n",
    "                    logger.debug(\"Current conversation history length: %d\", len(conversation_history))\n",
    "\n",
    "                    # Decide which agent to route to\n",
    "                    if \"weather\" in user_input_lower:\n",
    "                        logger.debug(\"Routing user query to WeatherAgent.\")\n",
    "                        response = await self.weather_agent.on_messages([user_message], cancellation_token)\n",
    "                    else:\n",
    "                        logger.debug(\"Routing user query to main AssistantAgent.\")\n",
    "                        try:\n",
    "                            response = await self.assistant.on_messages([user_message], cancellation_token)\n",
    "                        except asyncio.CancelledError:\n",
    "                            logger.info(\"Operation was cancelled by user.\")\n",
    "                            print(\"Operation cancelled by user.\\n\")\n",
    "                            continue\n",
    "\n",
    "                    # Extract the text from the agent's response\n",
    "                    if hasattr(response, \"chat_message\") and response.chat_message:\n",
    "                        agent_text = response.chat_message.content\n",
    "                    elif hasattr(response, \"content\"):\n",
    "                        agent_text = response.content\n",
    "                    else:\n",
    "                        agent_text = \"No response\"\n",
    "\n",
    "                    print(\"Assistant:\", agent_text, \"\\n\")\n",
    "                    assistant_message = TextMessage(content=agent_text, source=\"assistant\")\n",
    "                    conversation_history.append(assistant_message)\n",
    "\n",
    "                    logger.info(f\"Assistant message: {agent_text}\")\n",
    "                    logger.debug(\"Current conversation history length: %d\", len(conversation_history))\n",
    "\n",
    "            except openai.error.OpenAIError as e:\n",
    "                self._handle_error(\"OpenAI API error\", e, restart=True)\n",
    "\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                self._handle_error(\"Network error\", e, restart=True)\n",
    "\n",
    "            except Exception as e:\n",
    "                self._handle_error(\"An unexpected error occurred\", e, restart=False)\n",
    "                return  # Exit after an unexpected error\n",
    "\n",
    "            logger.debug(\"Exiting main run loop gracefully.\")\n",
    "            break\n",
    "\n",
    "    def _handle_error(self, message, exception, restart=False):\n",
    "        \"\"\"Handles and logs errors, optionally restarting the loop.\"\"\"\n",
    "        logger.error(f\"{message}: {exception}\", exc_info=True)\n",
    "        print(f\"{message}. {'Restarting...' if restart else 'Exiting...'}\\n\")\n",
    "\n",
    "        if restart:\n",
    "            time.sleep(2)  # Brief pause before restarting\n",
    "        else:\n",
    "            return\n",
    "\n",
    "def load_config(filename=CONFIG_FILE):\n",
    "    \"\"\"Loads configuration from a YAML file.\"\"\"\n",
    "    logger.debug(\"Loading configuration from %s\", filename)\n",
    "    try:\n",
    "        with open(filename, \"r\") as f:\n",
    "            config_data = yaml.safe_load(f)\n",
    "            logger.debug(\"Configuration loaded successfully: %s\", config_data)\n",
    "            return config_data\n",
    "    except FileNotFoundError:\n",
    "        logger.warning(f\"Configuration file '{filename}' not found. Using default settings.\")\n",
    "        return {}\n",
    "    except yaml.YAMLError as e:\n",
    "        logger.error(f\"Configuration file parsing error: {e}\", exc_info=True)\n",
    "        print(\"Configuration file parsing error. Using default settings.\\n\")\n",
    "        return {}\n",
    "\n",
    "async def main():\n",
    "    logger.debug(\"Entering main() function.\")\n",
    "    config = load_config()\n",
    "    app = ChatApplication(config)\n",
    "    await app.run()\n",
    "    logger.debug(\"main() completed.\")\n",
    "\n",
    "# ---- Run (Jupyter or standalone) ----\n",
    "load_dotenv()  # If you have a .env with OPENAI_API_KEY\n",
    "await main()    # For Jupyter Notebook\n",
    "# If you need standalone .py usage, do:\n",
    "# if __name__ == \"__main__\":\n",
    "#     load_dotenv()\n",
    "#     asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa0c64cd-f754-4c30-af82-44b3949b4913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  what is the weather in Virginia Beach, VA?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: The current weather in Virginia Beach, Va:\n",
      "Partly cloudy, 51Â°F (feels like 46Â°F) \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  What is the weather in Bethesda, MD?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: The current weather in Bethesda, Md:\n",
      "Partly cloudy, 48Â°F (feels like 43Â°F) \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  what is the difference between Autogen 1 and Autogen 2?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Autogen 1 and Autogen 2 likely refer to versions of a particular technology or product, possibly related to automated processes or scripts in a software context. Generally, the differences between version 1 and version 2 of any product can include improvements or new features, bug fixes, performance enhancements, and possibly changes in user interface or functionality. To provide a more specific answer, I would need additional context about what \"Autogen\" refers to, as it could apply to various fields or products. \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  What is the weather for Knoxville, TN?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: I'm not sure which city/state you want weather for. Please specify the location clearly. \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  What is the weather for Knoxville?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: I'm not sure which city/state you want weather for. Please specify the location clearly. \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the assistant. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import asyncio\n",
    "import logging\n",
    "import openai\n",
    "import requests\n",
    "import yaml\n",
    "import re\n",
    "from requests.utils import quote\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "#Import the raw client\n",
    "from openai import OpenAI # Import the synchronous OpenAI client\n",
    "\n",
    "# Uncomment these lines if you want *raw* HTTP-level debug output:\n",
    "\"\"\"\n",
    "import http.client as http_client\n",
    "http_client.HTTPConnection.debuglevel = 1\n",
    "logging.getLogger(\"http.client\").setLevel(logging.DEBUG)\n",
    "logging.getLogger(\"http.client\").propagate = True\n",
    "\"\"\"\n",
    "\n",
    "# ---- Constants ----\n",
    "EXIT_COMMANDS = {\"exit\", \"quit\", \"!exit\"}\n",
    "CANCEL_COMMAND = \"!cancel\"\n",
    "DEFAULT_MODEL = \"gpt-4o\"\n",
    "DEFAULT_SYSTEM_MESSAGE = \"You are a helpful assistant.\"\n",
    "CONFIG_FILE = \"config.yaml\"\n",
    "LOG_FILE = \"log.txt\"\n",
    "\n",
    "# ---- Configure Very Verbose Logging ----\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)  # Set to DEBUG for very verbose output\n",
    "\n",
    "# Remove any existing handlers (useful if re-running in Jupyter)\n",
    "for handler in logger.handlers[:]:\n",
    "    logger.removeHandler(handler)\n",
    "\n",
    "file_handler = logging.FileHandler(LOG_FILE)\n",
    "formatter = logging.Formatter(\n",
    "    '%(asctime)s - %(levelname)s - %(module)s - %(funcName)s:%(lineno)d - %(message)s'\n",
    ")\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "logger.debug(\"Logger initialized at DEBUG level. Very verbose mode is enabled.\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Verbose client for the main assistant calls (GPT). Logs raw request/response.\n",
    "# ---------------------------------------------------------------------------\n",
    "class VerboseOpenAIChatCompletionClient(OpenAIChatCompletionClient):\n",
    "    \"\"\"\n",
    "    An extension of OpenAIChatCompletionClient that logs detailed request/response data\n",
    "    at INFO level, matching your prior logging style.\n",
    "    \"\"\"\n",
    "    async def _send_request(self, messages, **kwargs):\n",
    "        url = \"https://api.openai.com/v1/chat/completions\"\n",
    "        logger.info(f\"HTTP Request: POST {url} 'HTTP/1.1 200 OK'\")\n",
    "        response = await super()._send_request(messages, **kwargs)\n",
    "\n",
    "        import json\n",
    "        log_payload = {\n",
    "            \"type\": \"LLMCall\",\n",
    "            \"messages\": messages,\n",
    "            \"response\": response\n",
    "        }\n",
    "        logger.info(json.dumps(log_payload))\n",
    "        logger.debug(\"Received response from OpenAI (debug): %s\", response)\n",
    "        return response\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# WeatherAgent for queries containing \"weather\"\n",
    "# Now uses Fahrenheit data (&u) and parses temp_F, FeelsLikeF.\n",
    "# ---------------------------------------------------------------------------\n",
    "class WeatherAgent(AssistantAgent):\n",
    "    \"\"\"\n",
    "    A specialized agent that queries wttr.in for weather data in Fahrenheit (USCS).\n",
    "    \"\"\"\n",
    "    def __init__(self, name, system_message, model_client):\n",
    "        super().__init__(name=name, system_message=system_message, model_client=model_client)\n",
    "        self.parser_client = model_client # Initialize parser_client with the verbose model_client\n",
    "        self.openai_client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"]) # Create sync openai client\n",
    "\n",
    "    async def on_messages(self, messages, cancellation_token=None):\n",
    "        user_message = messages[-1].content\n",
    "        logger.debug(f\"[WeatherAgent] Received message: {user_message}\")\n",
    "\n",
    "        city = self._extract_city(user_message)\n",
    "        if not city:\n",
    "            city = await self._extract_city_with_llm(user_message)\n",
    "            if not city:\n",
    "                response_text = (\n",
    "                    \"I'm not sure which city/state you want weather for. \"\n",
    "                    \"Please specify the location clearly.\"\n",
    "                )\n",
    "                return TextMessage(content=response_text, source=\"assistant\")\n",
    "\n",
    "        weather_info = self._fetch_weather(city)\n",
    "        if weather_info:\n",
    "            response_text = f\"The current weather in {city}:\\n{weather_info}\"\n",
    "        else:\n",
    "            response_text = f\"Sorry, I couldn't fetch weather data for {city}.\"\n",
    "\n",
    "        logger.debug(f\"[WeatherAgent] Responding: {response_text}\")\n",
    "        return TextMessage(content=response_text, source=\"assistant\")\n",
    "\n",
    "    def _extract_city(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Improved approach to extract the city and state from user text.\n",
    "        Handles more variations in input.\n",
    "        \"\"\"\n",
    "        match = re.search(r\"weather in\\s+([A-Za-z\\s]+(?:,\\s*[A-Za-z]{2,})?)\", text.lower())\n",
    "        if match:\n",
    "            city_name = match.group(1).strip()\n",
    "            # Remove any remaining non-alphanumeric characters except spaces and commas\n",
    "            city_name = re.sub(r\"[^\\w\\s,]\", \"\", city_name)\n",
    "            # Convert multiple spaces to single spaces\n",
    "            city_name = re.sub(r\"\\s+\", \" \", city_name)\n",
    "            city_name = city_name.strip().title()  # Title case\n",
    "            return city_name\n",
    "        return None\n",
    "\n",
    "    async def _extract_city_with_llm(self, user_text: str) -> str:\n",
    "        \"\"\"\n",
    "        Uses GPT to extract the city and state/country, if present.\n",
    "        If GPT can't find a city, returns None.\n",
    "        \"\"\"\n",
    "        system_prompt = (\n",
    "            \"You are a location extraction assistant. Your task is to identify the city and state (or country) from user queries about the weather.\\n\"\n",
    "            \"Return ONLY the city and state/country, separated by a comma and a space. For example: 'Orlando, FL' or 'Tokyo, Japan'.\\n\"\n",
    "            \"If the query does not contain a location, or if you are unsure, return 'NONE'.\\n\"\n",
    "            \"Here are some examples:\\n\"\n",
    "            \"User: What is the weather in Orlando, FL?\\n\"\n",
    "            \"Assistant: Orlando, FL\\n\"\n",
    "            \"User: What is the weather in Washington, DC?\\n\"\n",
    "            \"Assistant: Washington, DC\\n\"\n",
    "            \"User: What is the weather in Virginia Beach, VA?\\n\"\n",
    "            \"Assistant: Virginia Beach, VA\\n\"\n",
    "            \"User: What is the weather in Tokyo, Japan?\\n\"\n",
    "            \"Assistant: Tokyo, Japan\\n\"\n",
    "            \"User: Tell me a joke\\n\"\n",
    "            \"Assistant: NONE\\n\"\n",
    "        )\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_text},\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "\n",
    "            # Perform the OpenAI API call here (synchronously as acompletion isn't directly available)\n",
    "            completion = self.openai_client.chat.completions.create(\n",
    "                model=self.parser_client.model, # Use the same model as the verbose client\n",
    "                messages=messages,\n",
    "                temperature=0.0,\n",
    "                max_tokens=30,\n",
    "                top_p=1.0\n",
    "            )\n",
    "\n",
    "            raw_location = completion.choices[0].message.content.strip()\n",
    "            logger.debug(f\"[WeatherAgent] LLM raw location extraction: '{raw_location}'\")\n",
    "\n",
    "            if raw_location.upper() == \"NONE\":\n",
    "                logger.debug(\"[WeatherAgent] LLM returned 'NONE'.\")\n",
    "                return None\n",
    "\n",
    "            # Split the string by comma and space\n",
    "            parts = [part.strip() for part in raw_location.split(\", \")]  # Split by comma and space\n",
    "\n",
    "            if len(parts) == 2:\n",
    "                city, state = parts\n",
    "                cleaned_city = f\"{city}, {state}\"  # Reassemble with comma and space\n",
    "                logger.debug(f\"[WeatherAgent] Extracted city and state: '{cleaned_city}'\")\n",
    "                return cleaned_city\n",
    "            elif len(parts) == 1:\n",
    "                city = parts[0]\n",
    "                cleaned_city = city\n",
    "                logger.debug(f\"[WeatherAgent] Extracted city only: '{cleaned_city}'\")\n",
    "                return cleaned_city\n",
    "            else:\n",
    "                logger.warning(f\"[WeatherAgent] Unexpected LLM output format: '{raw_location}'\")  # Log unexpected output\n",
    "                return None\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error calling GPT for location extraction: {e}\", exc_info=True)\n",
    "            return None\n",
    "\n",
    "    def _fetch_weather(self, city: str) -> str:\n",
    "        \"\"\"\n",
    "        Calls wttr.in with city name (URL-encoded) requesting Fahrenheit data.\n",
    "        Prioritizes full state name for Florida.\n",
    "        If that fails for a city, state abbreviation, tries the full state name.\n",
    "        Returns a string like \"Overcast, 60Â°F (feels like 58Â°F)\"\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Prioritize full state name for Florida\n",
    "            if \"Orlando, Fl\" in city or \"Miami, Fl\" in city:\n",
    "                city_parts = city.split(\", \")\n",
    "                if len(city_parts) == 2:\n",
    "                    city_name, state_abbreviation = city_parts\n",
    "                    full_state_name = self._get_full_state_name(state_abbreviation)\n",
    "                    if full_state_name:\n",
    "                        full_city = f\"{city_name}, {full_state_name}\"\n",
    "                        city = full_city  # Use the full city for the initial request\n",
    "\n",
    "            city_encoded = quote(city)\n",
    "            # Use &u for Fahrenheit\n",
    "            url = f\"https://wttr.in/{city_encoded}?format=j1&u\"\n",
    "            logger.debug(f\"[WeatherAgent] Calling wttr.in URL: {url}\")\n",
    "\n",
    "            resp = requests.get(url, timeout=10)\n",
    "            resp.raise_for_status()\n",
    "            data = resp.json()\n",
    "            logger.debug(f\"[WeatherAgent] wttr.in response data: {data}\")  # Log the data\n",
    "\n",
    "            current = data.get(\"current_condition\", [{}])[0]\n",
    "            desc = current.get(\"weatherDesc\", [{}])[0].get(\"value\", \"Unknown\")\n",
    "            temp_f = current.get(\"temp_F\", \"?\")\n",
    "            feels_like_f = current.get(\"FeelsLikeF\", \"?\")\n",
    "            return f\"{desc}, {temp_f}Â°F (feels like {feels_like_f}Â°F)\"\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fetching weather for '{city}': {e}\", exc_info=True)\n",
    "\n",
    "            # If the city contains a state abbreviation, try the full state name\n",
    "            if \", \" in city:\n",
    "                city_parts = city.split(\", \")\n",
    "                if len(city_parts) == 2:\n",
    "                    city_name, state_abbreviation = city_parts\n",
    "                    full_state_name = self._get_full_state_name(state_abbreviation)\n",
    "                    if full_state_name:\n",
    "                        try:\n",
    "                            full_city = f\"{city_name}, {full_state_name}\"\n",
    "                            city_encoded = quote(full_city)\n",
    "                            url = f\"https://wttr.in/{city_encoded}?format=j1&u\"\n",
    "                            logger.debug(f\"[WeatherAgent] Retrying with full state name: {url}\")\n",
    "\n",
    "                            resp = requests.get(url, timeout=10)\n",
    "                            resp.raise_for_status()\n",
    "                            data = resp.json()\n",
    "                            logger.debug(f\"[WeatherAgent] wttr.in retry response data: {data}\") #Log retry data\n",
    "\n",
    "                            current = data.get(\"current_condition\", [{}])[0]\n",
    "                            desc = current.get(\"weatherDesc\", [{}])[0].get(\"value\", \"Unknown\")\n",
    "                            temp_f = current.get(\"temp_F\", \"?\")\n",
    "                            feels_like_f = current.get(\"FeelsLikeF\", \"?\")\n",
    "                            return f\"{desc}, {temp_f}Â°F (feels like {feels_like_f}Â°F)\"\n",
    "                        except Exception as e:\n",
    "                            logger.error(f\"Error fetching weather for '{full_city}': {e}\", exc_info=True)\n",
    "                            return None\n",
    "            return None\n",
    "\n",
    "    def _get_full_state_name(self, state_abbreviation: str) -> str:\n",
    "        \"\"\"\n",
    "        A simple helper function to convert state abbreviations to full names.\n",
    "        \"\"\"\n",
    "        state_map = {\n",
    "            \"AL\": \"Alabama\",\n",
    "            \"AK\": \"Alaska\",\n",
    "            \"AZ\": \"Arizona\",\n",
    "            \"AR\": \"Arkansas\",\n",
    "            \"CA\": \"California\",\n",
    "            \"CO\": \"Colorado\",\n",
    "            \"CT\": \"Connecticut\",\n",
    "            \"DE\": \"Delaware\",\n",
    "            \"FL\": \"Florida\",\n",
    "            \"GA\": \"Georgia\",\n",
    "            \"HI\": \"Hawaii\",\n",
    "            \"ID\": \"Idaho\",\n",
    "            \"IL\": \"Illinois\",\n",
    "            \"IN\": \"Indiana\",\n",
    "            \"IA\": \"Iowa\",\n",
    "            \"KS\": \"Kansas\",\n",
    "            \"KY\": \"Kentucky\",\n",
    "            \"LA\": \"Louisiana\",\n",
    "            \"ME\": \"Maine\",\n",
    "            \"MD\": \"Maryland\",\n",
    "            \"MA\": \"Massachusetts\",\n",
    "            \"MI\": \"Michigan\",\n",
    "            \"MN\": \"Minnesota\",\n",
    "            \"MS\": \"Mississippi\",\n",
    "            \"MO\": \"Missouri\",\n",
    "            \"MT\": \"Montana\",\n",
    "            \"NE\": \"Nebraska\",\n",
    "            \"NV\": \"Nevada\",\n",
    "            \"NH\": \"New Hampshire\",\n",
    "            \"NJ\": \"New Jersey\",\n",
    "            \"NM\": \"New Mexico\",\n",
    "            \"NY\": \"New York\",\n",
    "            \"NC\": \"North Carolina\",\n",
    "            \"ND\": \"North Dakota\",\n",
    "            \"OH\": \"Ohio\",\n",
    "            \"OK\": \"Oklahoma\",\n",
    "            \"OR\": \"Oregon\",\n",
    "            \"PA\": \"Pennsylvania\",\n",
    "            \"RI\": \"Rhode Island\",\n",
    "            \"SC\": \"South Carolina\",\n",
    "            \"SD\": \"South Dakota\",\n",
    "            \"TN\": \"Tennessee\",\n",
    "            \"TX\": \"Texas\",\n",
    "            \"UT\": \"Utah\",\n",
    "            \"VT\": \"Vermont\",\n",
    "            \"VA\": \"Virginia\",\n",
    "            \"WA\": \"Washington\",\n",
    "            \"WV\": \"West Virginia\",\n",
    "            \"WI\": \"Wisconsin\",\n",
    "            \"WY\": \"Wyoming\",\n",
    "            \"DC\": \"District of Columbia\",\n",
    "        }\n",
    "        return state_map.get(state_abbreviation.upper())\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Main ChatApplication\n",
    "# ---------------------------------------------------------------------------\n",
    "class ChatApplication:\n",
    "    \"\"\"\n",
    "    An interactive chat application with:\n",
    "      1) A main assistant agent (GPT-based)\n",
    "      2) A weather agent (wttr.in, Fahrenheit)\n",
    "    Logs are very verbose; any 'weather' queries route to WeatherAgent.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        logger.debug(\"Initializing ChatApplication with config: %s\", config)\n",
    "        self.config = config\n",
    "        self.openai_api_key = self._load_api_key()\n",
    "\n",
    "        # Create a verbose model client for GPT-based calls\n",
    "        self.model_client = self._create_model_client()\n",
    "\n",
    "        # The main \"assistant\" for general queries\n",
    "        self.assistant = AssistantAgent(\n",
    "            name=\"assistant\",\n",
    "            system_message=self.config.get(\"system_message\", DEFAULT_SYSTEM_MESSAGE),\n",
    "            model_client=self.model_client,\n",
    "        )\n",
    "\n",
    "        # A specialized \"weather_agent\" for weather queries\n",
    "        self.weather_agent = WeatherAgent(\n",
    "            name=\"weather_agent\",\n",
    "            system_message=\"You are a specialized weather agent.\",\n",
    "            model_client=self.model_client\n",
    "        )\n",
    "\n",
    "    def _load_api_key(self):\n",
    "        \"\"\"Loads the OpenAI API key from environment variables.\"\"\"\n",
    "        logger.debug(\"Attempting to load OPENAI_API_KEY from environment variables.\")\n",
    "        openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not openai_api_key:\n",
    "            logger.error(\"OPENAI_API_KEY not found in environment variables.\")\n",
    "            raise ValueError(\"OPENAI_API_KEY not found. Check your .env file or env settings.\")\n",
    "        logger.debug(\"Successfully loaded OPENAI_API_KEY.\")\n",
    "        return openai_api_key\n",
    "\n",
    "    def _create_model_client(self):\n",
    "        \"\"\"Creates the OpenAI client based on the configuration.\"\"\"\n",
    "        model = self.config.get(\"model\", DEFAULT_MODEL)\n",
    "        logger.debug(\"Creating VerboseOpenAIChatCompletionClient with model: %s\", model)\n",
    "        return VerboseOpenAIChatCompletionClient(model=model, api_key=self.openai_api_key)\n",
    "\n",
    "    async def run(self):\n",
    "        \"\"\"\n",
    "        Runs the main interaction loop. If the user's message includes \"weather\",\n",
    "        we delegate to WeatherAgent; else we call the main assistant agent.\n",
    "        \"\"\"\n",
    "        logger.debug(\"Entering main run loop (outer) for ChatApplication.\")\n",
    "        while True:\n",
    "            cancellation_token = CancellationToken()\n",
    "            conversation_history = []\n",
    "            logger.debug(\"Initialized new conversation history; now starting inner loop.\")\n",
    "\n",
    "            try:\n",
    "                while True:\n",
    "                    user_input = input(\"User: \")\n",
    "                    user_input_lower = user_input.lower()\n",
    "\n",
    "                    if user_input_lower in EXIT_COMMANDS:\n",
    "                        logger.info(\"User issued exit command. Exiting application.\")\n",
    "                        print(\"Exiting the assistant. Goodbye!\")\n",
    "                        return\n",
    "\n",
    "                    if user_input_lower == CANCEL_COMMAND:\n",
    "                        logger.info(\"User issued cancel command.\")\n",
    "                        print(\"Cancelling the current operation.\\n\")\n",
    "                        cancellation_token.cancel()\n",
    "                        continue\n",
    "\n",
    "                    # Log user input\n",
    "                    user_message = TextMessage(content=user_input, source=\"user\")\n",
    "                    conversation_history.append(user_message)\n",
    "                    logger.info(f\"User message: {user_input}\")\n",
    "                    logger.debug(\"Current conversation history length: %d\", len(conversation_history))\n",
    "\n",
    "                    # Decide which agent to route to\n",
    "                    if \"weather\" in user_input_lower:\n",
    "                        logger.debug(\"Routing user query to WeatherAgent.\")\n",
    "                        response = await self.weather_agent.on_messages([user_message], cancellation_token)\n",
    "                    else:\n",
    "                        logger.debug(\"Routing user query to main AssistantAgent.\")\n",
    "                        try:\n",
    "                            response = await self.assistant.on_messages([user_message], cancellation_token)\n",
    "                        except asyncio.CancelledError:\n",
    "                            logger.info(\"Operation was cancelled by user.\")\n",
    "                            print(\"Operation cancelled by user.\\n\")\n",
    "                            continue\n",
    "\n",
    "                    # Extract the text from the agent's response\n",
    "                    if hasattr(response, \"chat_message\") and response.chat_message:\n",
    "                        agent_text = response.chat_message.content\n",
    "                    elif hasattr(response, \"content\"):\n",
    "                        agent_text = response.content\n",
    "                    else:\n",
    "                        agent_text = \"No response\"\n",
    "\n",
    "                    print(\"Assistant:\", agent_text, \"\\n\")\n",
    "                    assistant_message = TextMessage(content=agent_text, source=\"assistant\")\n",
    "                    conversation_history.append(assistant_message)\n",
    "\n",
    "                    logger.info(f\"Assistant message: {agent_text}\")\n",
    "                    logger.debug(\"Current conversation history length: %d\", len(conversation_history))\n",
    "\n",
    "            except openai.error.OpenAIError as e:\n",
    "                self._handle_error(\"OpenAI API error\", e, restart=True)\n",
    "\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                self._handle_error(\"Network error\", e, restart=True)\n",
    "\n",
    "            except Exception as e:\n",
    "                self._handle_error(\"An unexpected error occurred\", e, restart=False)\n",
    "                return  # Exit after an unexpected error\n",
    "\n",
    "            logger.debug(\"Exiting main run loop gracefully.\")\n",
    "            break\n",
    "\n",
    "    def _handle_error(self, message, exception, restart=False):\n",
    "        \"\"\"Handles and logs errors, optionally restarting the loop.\"\"\"\n",
    "        logger.error(f\"{message}: {exception}\", exc_info=True)\n",
    "        print(f\"{message}. {'Restarting...' if restart else 'Exiting...'}\\n\")\n",
    "\n",
    "        if restart:\n",
    "            time.sleep(2)  # Brief pause before restarting\n",
    "        else:\n",
    "            return\n",
    "\n",
    "def load_config(filename=CONFIG_FILE):\n",
    "    \"\"\"Loads configuration from a YAML file.\"\"\"\n",
    "    logger.debug(\"Loading configuration from %s\", filename)\n",
    "    try:\n",
    "        with open(filename, \"r\") as f:\n",
    "            config_data = yaml.safe_load(f)\n",
    "            logger.debug(\"Configuration loaded successfully: %s\", config_data)\n",
    "            return config_data\n",
    "    except FileNotFoundError:\n",
    "        logger.warning(f\"Configuration file '{filename}' not found. Using default settings.\")\n",
    "        return {}\n",
    "    except yaml.YAMLError as e:\n",
    "        logger.error(f\"Configuration file parsing error: {e}\", exc_info=True)\n",
    "        print(\"Configuration file parsing error. Using default settings.\\n\")\n",
    "        return {}\n",
    "\n",
    "async def main():\n",
    "    logger.debug(\"Entering main() function.\")\n",
    "    config = load_config()\n",
    "    app = ChatApplication(config)\n",
    "    await app.run()\n",
    "    logger.debug(\"main() completed.\")\n",
    "\n",
    "# ---- Run (Jupyter or standalone) ----\n",
    "load_dotenv()  # If you have a .env with OPENAI_API_KEY\n",
    "await main()    # For Jupyter Notebook\n",
    "# If you need standalone .py usage, do:\n",
    "# if __name__ == \"__main__\":\n",
    "#     load_dotenv()\n",
    "#     asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44e50c6c-ac30-4dd3-85d3-c7d55a294026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  what is the weather in Knoxville, TN?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: The current weather in Knoxville, Tn:\n",
      "The current weather in Knoxville, Tn:\n",
      "Condition: Sunny\n",
      "Temperature: 48Â°F (Feels like 48Â°F)\n",
      "Humidity: 53%\n",
      "Wind: 2 mph from SSW\n",
      "Visibility: 9 miles\n",
      "Pressure: 30 inHg \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  what is Autogen from Microsoft used for?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Autogen from Microsoft is an open-source library designed to facilitate the orchestration of Large Language Model (LLM) applications. It provides easy-to-use tools for creating applications that involve multiple LLM agents and tools that need to work cooperatively to perform complex tasks. By leveraging Autogen, developers can efficiently manage and coordinate the interactions between various AI components, making it easier to build sophisticated applications that require advanced natural language understanding and generation capabilities. \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  What is the weather for Bethesda, MD?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: The current weather in Bethesda, MD:\n",
      "The current weather in Bethesda, MD:\n",
      "Condition: Partly cloudy\n",
      "Temperature: 48Â°F (Feels like 43Â°F)\n",
      "Humidity: 39%\n",
      "Wind: 12 mph from NW\n",
      "Visibility: 9 miles\n",
      "Pressure: 30 inHg \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the assistant. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import asyncio\n",
    "import logging\n",
    "import openai\n",
    "import requests\n",
    "import yaml\n",
    "import re\n",
    "from requests.utils import quote\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "#Import the raw client\n",
    "from openai import OpenAI # Import the synchronous OpenAI client\n",
    "\n",
    "# Uncomment these lines if you want *raw* HTTP-level debug output:\n",
    "\"\"\"\n",
    "import http.client as http_client\n",
    "http_client.HTTPConnection.debuglevel = 1\n",
    "logging.getLogger(\"http.client\").setLevel(logging.DEBUG)\n",
    "logging.getLogger(\"http.client\").propagate = True\n",
    "\"\"\"\n",
    "\n",
    "# ---- Constants ----\n",
    "EXIT_COMMANDS = {\"exit\", \"quit\", \"!exit\"}\n",
    "CANCEL_COMMAND = \"!cancel\"\n",
    "DEFAULT_MODEL = \"gpt-4o\"\n",
    "DEFAULT_SYSTEM_MESSAGE = \"You are a helpful assistant.\"\n",
    "CONFIG_FILE = \"config.yaml\"\n",
    "LOG_FILE = \"log.txt\"\n",
    "\n",
    "# ---- Configure Very Verbose Logging ----\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)  # Set to DEBUG for very verbose output\n",
    "\n",
    "# Remove any existing handlers (useful if re-running in Jupyter)\n",
    "for handler in logger.handlers[:]:\n",
    "    logger.removeHandler(handler)\n",
    "\n",
    "file_handler = logging.FileHandler(LOG_FILE)\n",
    "formatter = logging.Formatter(\n",
    "    '%(asctime)s - %(levelname)s - %(module)s - %(funcName)s:%(lineno)d - %(message)s'\n",
    ")\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "logger.debug(\"Logger initialized at DEBUG level. Very verbose mode is enabled.\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Verbose client for the main assistant calls (GPT). Logs raw request/response.\n",
    "# ---------------------------------------------------------------------------\n",
    "class VerboseOpenAIChatCompletionClient(OpenAIChatCompletionClient):\n",
    "    \"\"\"\n",
    "    An extension of OpenAIChatCompletionClient that logs detailed request/response data\n",
    "    at INFO level, matching your prior logging style.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, api_key):\n",
    "        super().__init__(model=model, api_key=api_key)\n",
    "        self.model = model # Store the model\n",
    "\n",
    "    async def _send_request(self, messages, **kwargs):\n",
    "        url = \"https://api.openai.com/v1/chat/completions\"\n",
    "        logger.info(f\"HTTP Request: POST {url} 'HTTP/1.1 200 OK'\")\n",
    "        response = await super()._send_request(messages, **kwargs)\n",
    "\n",
    "        import json\n",
    "        log_payload = {\n",
    "            \"type\": \"LLMCall\",\n",
    "            \"messages\": messages,\n",
    "            \"response\": response\n",
    "        }\n",
    "        logger.info(json.dumps(log_payload))\n",
    "        logger.debug(\"Received response from OpenAI (debug): %s\", response)\n",
    "        return response\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# WeatherAgent for queries containing \"weather\"\n",
    "# Now uses Fahrenheit data (&u) and parses temp_F, FeelsLikeF.\n",
    "# ---------------------------------------------------------------------------\n",
    "class WeatherAgent(AssistantAgent):\n",
    "    \"\"\"\n",
    "    A specialized agent that queries wttr.in for weather data in Fahrenheit (USCS).\n",
    "    \"\"\"\n",
    "    def __init__(self, name, system_message, model_client):\n",
    "        super().__init__(name=name, system_message=system_message, model_client=model_client)\n",
    "        self.parser_client = model_client # Initialize parser_client with the verbose model_client\n",
    "        self.openai_client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"]) # Create sync openai client\n",
    "\n",
    "    async def on_messages(self, messages, cancellation_token=None):\n",
    "        user_message = messages[-1].content\n",
    "        logger.debug(f\"[WeatherAgent] Received message: {user_message}\")\n",
    "\n",
    "        city = self._extract_city(user_message)\n",
    "        if not city:\n",
    "            city = await self._extract_city_with_llm(user_message)\n",
    "            if not city:\n",
    "                response_text = (\n",
    "                    \"I'm not sure which city/state you want weather for. \"\n",
    "                    \"Please specify the location clearly.\"\n",
    "                )\n",
    "                return TextMessage(content=response_text, source=\"assistant\")\n",
    "\n",
    "        weather_info = self._fetch_weather(city)\n",
    "        if weather_info:\n",
    "            response_text = f\"The current weather in {city}:\\n{weather_info}\"\n",
    "        else:\n",
    "            response_text = f\"Sorry, I couldn't fetch weather data for {city}.\"\n",
    "\n",
    "        logger.debug(f\"[WeatherAgent] Responding: {response_text}\")\n",
    "        return TextMessage(content=response_text, source=\"assistant\")\n",
    "\n",
    "    def _extract_city(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Improved approach to extract the city and state from user text.\n",
    "        Handles more variations in input.\n",
    "        \"\"\"\n",
    "        match = re.search(r\"weather in\\s+([A-Za-z\\s]+(?:,\\s*[A-Za-z]{2,})?)\", text.lower())\n",
    "        if match:\n",
    "            city_name = match.group(1).strip()\n",
    "            # Remove any remaining non-alphanumeric characters except spaces and commas\n",
    "            city_name = re.sub(r\"[^\\w\\s,]\", \"\", city_name)\n",
    "            # Convert multiple spaces to single spaces\n",
    "            city_name = re.sub(r\"\\s+\", \" \", city_name)\n",
    "            city_name = city_name.strip().title()  # Title case\n",
    "            return city_name\n",
    "        return None\n",
    "\n",
    "    async def _extract_city_with_llm(self, user_text: str) -> str:\n",
    "        \"\"\"\n",
    "        Uses GPT to extract the city and state/country, if present.\n",
    "        If GPT can't find a city, returns None.\n",
    "        \"\"\"\n",
    "        system_prompt = (\n",
    "            \"You are a location extraction assistant. Your task is to identify the city and state (or country) from user queries about the weather.\\n\"\n",
    "            \"Return ONLY the city and state/country, separated by a comma and a space. For example: 'Orlando, FL' or 'Tokyo, Japan'.\\n\"\n",
    "            \"If the query does not contain a location, or if you are unsure, return 'NONE'.\\n\"\n",
    "            \"Here are some examples:\\n\"\n",
    "            \"User: What is the weather in Orlando, FL?\\n\"\n",
    "            \"Assistant: Orlando, FL\\n\"\n",
    "            \"User: What is the weather in Washington, DC?\\n\"\n",
    "            \"Assistant: Washington, DC\\n\"\n",
    "            \"User: What is the weather in Virginia Beach, VA?\\n\"\n",
    "            \"Assistant: Virginia Beach, VA\\n\"\n",
    "            \"User: What is the weather in Tokyo, Japan?\\n\"\n",
    "            \"Assistant: Tokyo, Japan\\n\"\n",
    "            \"User: Tell me a joke\\n\"\n",
    "            \"Assistant: NONE\\n\"\n",
    "        )\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_text},\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "\n",
    "            # Perform the OpenAI API call here (synchronously as acompletion isn't directly available)\n",
    "            completion = self.openai_client.chat.completions.create(\n",
    "                model=self.parser_client.model, # Use the same model as the verbose client\n",
    "                messages=messages,\n",
    "                temperature=0.0,\n",
    "                max_tokens=30,\n",
    "                top_p=1.0\n",
    "            )\n",
    "\n",
    "            raw_location = completion.choices[0].message.content.strip()\n",
    "            logger.debug(f\"[WeatherAgent] LLM raw location extraction: '{raw_location}'\")\n",
    "\n",
    "            if raw_location.upper() == \"NONE\":\n",
    "                logger.debug(\"[WeatherAgent] LLM returned 'NONE'.\")\n",
    "                return None\n",
    "\n",
    "            # Split the string by comma and space\n",
    "            parts = [part.strip() for part in raw_location.split(\", \")]  # Split by comma and space\n",
    "\n",
    "            if len(parts) == 2:\n",
    "                city, state = parts\n",
    "                cleaned_city = f\"{city}, {state}\"  # Reassemble with comma and space\n",
    "                logger.debug(f\"[WeatherAgent] Extracted city and state: '{cleaned_city}'\")\n",
    "                return cleaned_city\n",
    "            elif len(parts) == 1:\n",
    "                city = parts[0]\n",
    "                cleaned_city = city\n",
    "                logger.debug(f\"[WeatherAgent] Extracted city only: '{cleaned_city}'\")\n",
    "                return cleaned_city\n",
    "            else:\n",
    "                logger.warning(f\"[WeatherAgent] Unexpected LLM output format: '{raw_location}'\")  # Log unexpected output\n",
    "                return None\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error calling GPT for location extraction: {e}\", exc_info=True)\n",
    "            return None\n",
    "\n",
    "    def _fetch_weather(self, city: str) -> str:\n",
    "        \"\"\"\n",
    "        Calls wttr.in with city name (URL-encoded) requesting Fahrenheit data.\n",
    "        Prioritizes full state name for Florida.\n",
    "        If that fails for a city, state abbreviation, tries the full state name.\n",
    "        Returns a string like \"Overcast, 60Â°F (feels like 58Â°F)\"\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Prioritize full state name for Florida\n",
    "            if \"Orlando, Fl\" in city or \"Miami, Fl\" in city:\n",
    "                city_parts = city.split(\", \")\n",
    "                if len(city_parts) == 2:\n",
    "                    city_name, state_abbreviation = city_parts\n",
    "                    full_state_name = self._get_full_state_name(state_abbreviation)\n",
    "                    if full_state_name:\n",
    "                        full_city = f\"{city_name}, {full_state_name}\"\n",
    "                        city = full_city  # Use the full city for the initial request\n",
    "\n",
    "            city_encoded = quote(city)\n",
    "            # Use &u for Fahrenheit\n",
    "            url = f\"https://wttr.in/{city_encoded}?format=j1&u\"\n",
    "            logger.debug(f\"[WeatherAgent] Calling wttr.in URL: {url}\")\n",
    "\n",
    "            resp = requests.get(url, timeout=10)\n",
    "            resp.raise_for_status()\n",
    "            data = resp.json()\n",
    "            logger.debug(f\"[WeatherAgent] wttr.in response data: {data}\")  # Log the data\n",
    "\n",
    "            current = data.get(\"current_condition\", [{}])[0]\n",
    "            desc = current.get(\"weatherDesc\", [{}])[0].get(\"value\", \"Unknown\")\n",
    "            temp_f = current.get(\"temp_F\", \"?\")\n",
    "            feels_like_f = current.get(\"FeelsLikeF\", \"?\")\n",
    "            humidity = current.get(\"humidity\", \"?\")\n",
    "            wind_speed = current.get(\"windspeedMiles\", \"?\")\n",
    "            wind_direction = current.get(\"winddir16Point\", \"?\")\n",
    "            visibility = current.get(\"visibilityMiles\", \"?\")\n",
    "            pressure = current.get(\"pressureInches\", \"?\")\n",
    "\n",
    "            # Construct a more informative response\n",
    "            response = (\n",
    "                f\"The current weather in {city}:\\n\"\n",
    "                f\"Condition: {desc}\\n\"\n",
    "                f\"Temperature: {temp_f}Â°F (Feels like {feels_like_f}Â°F)\\n\"\n",
    "                f\"Humidity: {humidity}%\\n\"\n",
    "                f\"Wind: {wind_speed} mph from {wind_direction}\\n\"\n",
    "                f\"Visibility: {visibility} miles\\n\"\n",
    "                f\"Pressure: {pressure} inHg\"\n",
    "            )\n",
    "\n",
    "            return response\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fetching weather for '{city}': {e}\", exc_info=True)\n",
    "\n",
    "            # If the city contains a state abbreviation, try the full state name\n",
    "            if \", \" in city:\n",
    "                city_parts = city.split(\", \")\n",
    "                if len(city_parts) == 2:\n",
    "                    city_name, state_abbreviation = city_parts\n",
    "                    full_state_name = self._get_full_state_name(state_abbreviation)\n",
    "                    if full_state_name:\n",
    "                        try:\n",
    "                            full_city = f\"{city_name}, {full_state_name}\"\n",
    "                            city_encoded = quote(full_city)\n",
    "                            url = f\"https://wttr.in/{city_encoded}?format=j1&u\"\n",
    "                            logger.debug(f\"[WeatherAgent] Retrying with full state name: {url}\")\n",
    "\n",
    "                            resp = requests.get(url, timeout=10)\n",
    "                            resp.raise_for_status()\n",
    "                            data = resp.json()\n",
    "                            logger.debug(f\"[WeatherAgent] wttr.in retry response data: {data}\") #Log retry data\n",
    "\n",
    "                            current = data.get(\"current_condition\", [{}])[0]\n",
    "                            desc = current.get(\"weatherDesc\", [{}])[0].get(\"value\", \"Unknown\")\n",
    "                            temp_f = current.get(\"temp_F\", \"?\")\n",
    "                            feels_like_f = current.get(\"FeelsLikeF\", \"?\")\n",
    "                            humidity = current.get(\"humidity\", \"?\")\n",
    "                            wind_speed = current.get(\"windspeedMiles\", \"?\")\n",
    "                            wind_direction = current.get(\"winddir16Point\", \"?\")\n",
    "                            visibility = current.get(\"visibilityMiles\", \"?\")\n",
    "                            pressure = current.get(\"pressureInches\", \"?\")\n",
    "\n",
    "                            # Construct a more informative response\n",
    "                            response = (\n",
    "                                f\"The current weather in {full_city}:\\n\"\n",
    "                                f\"Condition: {desc}\\n\"\n",
    "                                f\"Temperature: {temp_f}Â°F (Feels like {feels_like_f}Â°F)\\n\"\n",
    "                                f\"Humidity: {humidity}%\\n\"\n",
    "                                f\"Wind: {wind_speed} mph from {wind_direction}\\n\"\n",
    "                                f\"Visibility: {visibility} miles\\n\"\n",
    "                                f\"Pressure: {pressure} inHg\"\n",
    "                            )\n",
    "\n",
    "                            return response\n",
    "\n",
    "                        except Exception as e:\n",
    "                            logger.error(f\"Error fetching weather for '{full_city}': {e}\", exc_info=True)\n",
    "                            return None\n",
    "            return None\n",
    "\n",
    "    def _get_full_state_name(self, state_abbreviation: str) -> str:\n",
    "        \"\"\"\n",
    "        A simple helper function to convert state abbreviations to full names.\n",
    "        \"\"\"\n",
    "        state_map = {\n",
    "            \"AL\": \"Alabama\",\n",
    "            \"AK\": \"Alaska\",\n",
    "            \"AZ\": \"Arizona\",\n",
    "            \"AR\": \"Arkansas\",\n",
    "            \"CA\": \"California\",\n",
    "            \"CO\": \"Colorado\",\n",
    "            \"CT\": \"Connecticut\",\n",
    "            \"DE\": \"Delaware\",\n",
    "            \"FL\": \"Florida\",\n",
    "            \"GA\": \"Georgia\",\n",
    "            \"HI\": \"Hawaii\",\n",
    "            \"ID\": \"Idaho\",\n",
    "            \"IL\": \"Illinois\",\n",
    "            \"IN\": \"Indiana\",\n",
    "            \"IA\": \"Iowa\",\n",
    "            \"KS\": \"Kansas\",\n",
    "            \"KY\": \"Kentucky\",\n",
    "            \"LA\": \"Louisiana\",\n",
    "            \"ME\": \"Maine\",\n",
    "            \"MD\": \"Maryland\",\n",
    "            \"MA\": \"Massachusetts\",\n",
    "            \"MI\": \"Michigan\",\n",
    "            \"MN\": \"Minnesota\",\n",
    "            \"MS\": \"Mississippi\",\n",
    "            \"MO\": \"Missouri\",\n",
    "            \"MT\": \"Montana\",\n",
    "            \"NE\": \"Nebraska\",\n",
    "            \"NV\": \"Nevada\",\n",
    "            \"NH\": \"New Hampshire\",\n",
    "            \"NJ\": \"New Jersey\",\n",
    "            \"NM\": \"New Mexico\",\n",
    "            \"NY\": \"New York\",\n",
    "            \"NC\": \"North Carolina\",\n",
    "            \"ND\": \"North Dakota\",\n",
    "            \"OH\": \"Ohio\",\n",
    "            \"OK\": \"Oklahoma\",\n",
    "            \"OR\": \"Oregon\",\n",
    "            \"PA\": \"Pennsylvania\",\n",
    "            \"RI\": \"Rhode Island\",\n",
    "            \"SC\": \"South Carolina\",\n",
    "            \"SD\": \"South Dakota\",\n",
    "            \"TN\": \"Tennessee\",\n",
    "            \"TX\": \"Texas\",\n",
    "            \"UT\": \"Utah\",\n",
    "            \"VT\": \"Vermont\",\n",
    "            \"VA\": \"Virginia\",\n",
    "            \"WA\": \"Washington\",\n",
    "            \"WV\": \"West Virginia\",\n",
    "            \"WI\": \"Wisconsin\",\n",
    "            \"WY\": \"Wyoming\",\n",
    "            \"DC\": \"District of Columbia\",\n",
    "        }\n",
    "        return state_map.get(state_abbreviation.upper())\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Main ChatApplication\n",
    "# ---------------------------------------------------------------------------\n",
    "class ChatApplication:\n",
    "    \"\"\"\n",
    "    An interactive chat application with:\n",
    "      1) A main assistant agent (GPT-based)\n",
    "      2) A weather agent (wttr.in, Fahrenheit)\n",
    "    Logs are very verbose; any 'weather' queries route to WeatherAgent.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        logger.debug(\"Initializing ChatApplication with config: %s\", config)\n",
    "        self.config = config\n",
    "        self.openai_api_key = self._load_api_key()\n",
    "\n",
    "        # Create a verbose model client for GPT-based calls\n",
    "        self.model_client = self._create_model_client()\n",
    "\n",
    "        # The main \"assistant\" for general queries\n",
    "        self.assistant = AssistantAgent(\n",
    "            name=\"assistant\",\n",
    "            system_message=self.config.get(\"system_message\", DEFAULT_SYSTEM_MESSAGE),\n",
    "            model_client=self.model_client,\n",
    "        )\n",
    "\n",
    "        # A specialized \"weather_agent\" for weather queries\n",
    "        self.weather_agent = WeatherAgent(\n",
    "            name=\"weather_agent\",\n",
    "            system_message=\"You are a specialized weather agent.\",\n",
    "            model_client=self.model_client\n",
    "        )\n",
    "\n",
    "    def _load_api_key(self):\n",
    "        \"\"\"Loads the OpenAI API key from environment variables.\"\"\"\n",
    "        logger.debug(\"Attempting to load OPENAI_API_KEY from environment variables.\")\n",
    "        openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not openai_api_key:\n",
    "            logger.error(\"OPENAI_API_KEY not found in environment variables.\")\n",
    "            raise ValueError(\"OPENAI_API_KEY not found. Check your .env file or env settings.\")\n",
    "        logger.debug(\"Successfully loaded OPENAI_API_KEY.\")\n",
    "        return openai_api_key\n",
    "\n",
    "    def _create_model_client(self):\n",
    "        \"\"\"Creates the OpenAI client based on the configuration.\"\"\"\n",
    "        model = self.config.get(\"model\", DEFAULT_MODEL)\n",
    "        logger.debug(\"Creating VerboseOpenAIChatCompletionClient with model: %s\", model)\n",
    "        return VerboseOpenAIChatCompletionClient(model=model, api_key=self.openai_api_key)\n",
    "\n",
    "    async def run(self):\n",
    "        \"\"\"\n",
    "        Runs the main interaction loop. If the user's message includes \"weather\",\n",
    "        we delegate to WeatherAgent; else we call the main assistant agent.\n",
    "        \"\"\"\n",
    "        logger.debug(\"Entering main run loop (outer) for ChatApplication.\")\n",
    "        while True:\n",
    "            cancellation_token = CancellationToken()\n",
    "            conversation_history = []\n",
    "            logger.debug(\"Initialized new conversation history; now starting inner loop.\")\n",
    "\n",
    "            try:\n",
    "                while True:\n",
    "                    user_input = input(\"User: \")\n",
    "                    user_input_lower = user_input.lower()\n",
    "\n",
    "                    if user_input_lower in EXIT_COMMANDS:\n",
    "                        logger.info(\"User issued exit command. Exiting application.\")\n",
    "                        print(\"Exiting the assistant. Goodbye!\")\n",
    "                        return\n",
    "\n",
    "                    if user_input_lower == CANCEL_COMMAND:\n",
    "                        logger.info(\"User issued cancel command.\")\n",
    "                        print(\"Cancelling the current operation.\\n\")\n",
    "                        cancellation_token.cancel()\n",
    "                        continue\n",
    "\n",
    "                    # Log user input\n",
    "                    user_message = TextMessage(content=user_input, source=\"user\")\n",
    "                    conversation_history.append(user_message)\n",
    "                    logger.info(f\"User message: {user_input}\")\n",
    "                    logger.debug(\"Current conversation history length: %d\", len(conversation_history))\n",
    "\n",
    "                    # Decide which agent to route to\n",
    "                    if \"weather\" in user_input_lower:\n",
    "                        logger.debug(\"Routing user query to WeatherAgent.\")\n",
    "                        response = await self.weather_agent.on_messages([user_message], cancellation_token)\n",
    "                    else:\n",
    "                        logger.debug(\"Routing user query to main AssistantAgent.\")\n",
    "                        try:\n",
    "                            response = await self.assistant.on_messages([user_message], cancellation_token)\n",
    "                        except asyncio.CancelledError:\n",
    "                            logger.info(\"Operation was cancelled by user.\")\n",
    "                            print(\"Operation cancelled by user.\\n\")\n",
    "                            continue\n",
    "\n",
    "                    # Extract the text from the agent's response\n",
    "                    if hasattr(response, \"chat_message\") and response.chat_message:\n",
    "                        agent_text = response.chat_message.content\n",
    "                    elif hasattr(response, \"content\"):\n",
    "                        agent_text = response.content\n",
    "                    else:\n",
    "                        agent_text = \"No response\"\n",
    "\n",
    "                    print(\"Assistant:\", agent_text, \"\\n\")\n",
    "                    assistant_message = TextMessage(content=agent_text, source=\"assistant\")\n",
    "                    conversation_history.append(assistant_message)\n",
    "\n",
    "                    logger.info(f\"Assistant message: {agent_text}\")\n",
    "                    logger.debug(\"Current conversation history length: %d\", len(conversation_history))\n",
    "\n",
    "            except openai.error.OpenAIError as e:\n",
    "                self._handle_error(\"OpenAI API error\", e, restart=True)\n",
    "\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                self._handle_error(\"Network error\", e, restart=True)\n",
    "\n",
    "            except Exception as e:\n",
    "                self._handle_error(\"An unexpected error occurred\", e, restart=False)\n",
    "                return  # Exit after an unexpected error\n",
    "\n",
    "            logger.debug(\"Exiting main run loop gracefully.\")\n",
    "            break\n",
    "\n",
    "    def _handle_error(self, message, exception, restart=False):\n",
    "        \"\"\"Handles and logs errors, optionally restarting the loop.\"\"\"\n",
    "        logger.error(f\"{message}: {exception}\", exc_info=True)\n",
    "        print(f\"{message}. {'Restarting...' if restart else 'Exiting...'}\\n\")\n",
    "\n",
    "        if restart:\n",
    "            time.sleep(2)  # Brief pause before restarting\n",
    "        else:\n",
    "            return\n",
    "\n",
    "def load_config(filename=CONFIG_FILE):\n",
    "    \"\"\"Loads configuration from a YAML file.\"\"\"\n",
    "    logger.debug(\"Loading configuration from %s\", filename)\n",
    "    try:\n",
    "        with open(filename, \"r\") as f:\n",
    "            config_data = yaml.safe_load(f)\n",
    "            logger.debug(\"Configuration loaded successfully: %s\", config_data)\n",
    "            return config_data\n",
    "    except FileNotFoundError:\n",
    "        logger.warning(f\"Configuration file '{filename}' not found. Using default settings.\")\n",
    "        return {}\n",
    "    except yaml.YAMLError as e:\n",
    "        logger.error(f\"Configuration file parsing error: {e}\", exc_info=True)\n",
    "        print(\"Configuration file parsing error. Using default settings.\\n\")\n",
    "        return {}\n",
    "\n",
    "async def main():\n",
    "    try:\n",
    "        logger.debug(\"Entering main() function.\")\n",
    "        config = load_config()\n",
    "        app = ChatApplication(config)\n",
    "        await app.run()\n",
    "        logger.debug(\"main() completed.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unhandled error occurred in main: {e}\", exc_info=True)\n",
    "\n",
    "# ---- Run (Jupyter or standalone) ----\n",
    "load_dotenv()  # If you have a .env with OPENAI_API_KEY\n",
    "try:\n",
    "    await main()    # For Jupyter Notebook\n",
    "except Exception as e:\n",
    "    logger.error(f\"Unhandled exception in Jupyter environment: {e}\", exc_info=True)\n",
    "\n",
    "# If you need standalone .py usage, do:\n",
    "# if __name__ == \"__main__\":\n",
    "#     load_dotenv()\n",
    "#     try:\n",
    "#         asyncio.run(main())\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"Unhandled exception in standalone mode: {e}\", exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d32ea014-db69-4088-ab24-3e1f73edda4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  what is the weather in Bethesda, MD?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: The current weather in Bethesda, Md:\n",
      "The current weather in Bethesda, Md:\n",
      "Condition: Partly cloudy\n",
      "Temperature: 48Â°F (Feels like 43Â°F)\n",
      "Humidity: 39%\n",
      "Wind: 12 mph from NW\n",
      "Visibility: 9 miles\n",
      "Pressure: 30 inHg\n",
      "UV Index: 2\n",
      "Cloud Cover: 75%\n",
      "Precipitation: 0.0 inches\n",
      "\n",
      "Forecast:\n",
      "  2025-02-28:\n",
      "    Condition: Clear \n",
      "    Avg Temp: 45Â°F\n",
      "    Max Temp: 55Â°F\n",
      "    Min Temp: 36Â°F\n",
      "    Chance of Rain: 0%\n",
      "  2025-03-01:\n",
      "    Condition: Clear \n",
      "    Avg Temp: 42Â°F\n",
      "    Max Temp: 53Â°F\n",
      "    Min Temp: 28Â°F\n",
      "    Chance of Rain: 0%\n",
      "  2025-03-02:\n",
      "    Condition: Clear \n",
      "    Avg Temp: 28Â°F\n",
      "    Max Temp: 37Â°F\n",
      "    Min Temp: 19Â°F\n",
      "    Chance of Rain: 0%\n",
      " \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  what should I wear for next week in Bethesda, MD?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: To give you the best advice on what to wear next week in Bethesda, MD, it's important to check the local weather forecast just before the week begins. Hereâ€™s a general guideline based on typical seasonal weather:\n",
      "\n",
      "- **Late Fall/Winter (November to February):** Prepare for cold temperatures. Wear layers such as sweaters, a warm coat, scarves, gloves, and a hat. You might also need boots if snow is expected.\n",
      "\n",
      "- **Spring (March to May):** Expect variable weather, ranging from chilly to mild. Light jackets, sweaters, and rain gear (like a waterproof jacket or umbrella) are good to have.\n",
      "\n",
      "- **Summer (June to August):** This is usually hot and humid, so wear light, breathable fabrics. T-shirts, shorts, dresses, and sunscreen are recommended.\n",
      "\n",
      "- **Early Fall (September to October):** Weather can be mild to warm. Layers like light jackets or cardigans, along with comfortable shoes, are ideal.\n",
      "\n",
      "For an accurate recommendation, it's best to consult a local weather app or website for the most up-to-date forecast. \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the assistant. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import asyncio\n",
    "import logging\n",
    "import openai\n",
    "import requests\n",
    "import yaml\n",
    "import re\n",
    "from requests.utils import quote\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "#Import the raw client\n",
    "from openai import OpenAI # Import the synchronous OpenAI client\n",
    "\n",
    "# Uncomment these lines if you want *raw* HTTP-level debug output:\n",
    "\"\"\"\n",
    "import http.client as http_client\n",
    "http_client.HTTPConnection.debuglevel = 1\n",
    "logging.getLogger(\"http.client\").setLevel(logging.DEBUG)\n",
    "logging.getLogger(\"http.client\").propagate = True\n",
    "\"\"\"\n",
    "\n",
    "# ---- Constants ----\n",
    "EXIT_COMMANDS = {\"exit\", \"quit\", \"!exit\"}\n",
    "CANCEL_COMMAND = \"!cancel\"\n",
    "DEFAULT_MODEL = \"gpt-4o\"\n",
    "DEFAULT_SYSTEM_MESSAGE = \"You are a helpful assistant.\"\n",
    "CONFIG_FILE = \"config.yaml\"\n",
    "LOG_FILE = \"log.txt\"\n",
    "\n",
    "# ---- Configure Very Verbose Logging ----\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)  # Set to DEBUG for very verbose output\n",
    "\n",
    "# Remove any existing handlers (useful if re-running in Jupyter)\n",
    "for handler in logger.handlers[:]:\n",
    "    logger.removeHandler(handler)\n",
    "\n",
    "file_handler = logging.FileHandler(LOG_FILE)\n",
    "formatter = logging.Formatter(\n",
    "    '%(asctime)s - %(levelname)s - %(module)s - %(funcName)s:%(lineno)d - %(message)s'\n",
    ")\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "logger.debug(\"Logger initialized at DEBUG level. Very verbose mode is enabled.\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Verbose client for the main assistant calls (GPT). Logs raw request/response.\n",
    "# ---------------------------------------------------------------------------\n",
    "class VerboseOpenAIChatCompletionClient(OpenAIChatCompletionClient):\n",
    "    \"\"\"\n",
    "    An extension of OpenAIChatCompletionClient that logs detailed request/response data\n",
    "    at INFO level, matching your prior logging style.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, api_key):\n",
    "        super().__init__(model=model, api_key=api_key)\n",
    "        self.model = model # Store the model\n",
    "\n",
    "    async def _send_request(self, messages, **kwargs):\n",
    "        url = \"https://api.openai.com/v1/chat/completions\"\n",
    "        logger.info(f\"HTTP Request: POST {url} 'HTTP/1.1 200 OK'\")\n",
    "        response = await super()._send_request(messages, **kwargs)\n",
    "\n",
    "        import json\n",
    "        log_payload = {\n",
    "            \"type\": \"LLMCall\",\n",
    "            \"messages\": messages,\n",
    "            \"response\": response\n",
    "        }\n",
    "        logger.info(json.dumps(log_payload))\n",
    "        logger.debug(\"Received response from OpenAI (debug): %s\", response)\n",
    "        return response\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# WeatherAgent for queries containing \"weather\"\n",
    "# Now uses Fahrenheit data (&u) and parses temp_F, FeelsLikeF.\n",
    "# ---------------------------------------------------------------------------\n",
    "class WeatherAgent(AssistantAgent):\n",
    "    \"\"\"\n",
    "    A specialized agent that queries wttr.in for weather data in Fahrenheit (USCS).\n",
    "    \"\"\"\n",
    "    def __init__(self, name, system_message, model_client):\n",
    "        super().__init__(name=name, system_message=system_message, model_client=model_client)\n",
    "        self.parser_client = model_client # Initialize parser_client with the verbose model_client\n",
    "        self.openai_client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"]) # Create sync openai client\n",
    "\n",
    "    async def on_messages(self, messages, cancellation_token=None):\n",
    "        user_message = messages[-1].content\n",
    "        logger.debug(f\"[WeatherAgent] Received message: {user_message}\")\n",
    "\n",
    "        city = self._extract_city(user_message)\n",
    "        if not city:\n",
    "            city = await self._extract_city_with_llm(user_message)\n",
    "            if not city:\n",
    "                response_text = (\n",
    "                    \"I'm not sure which city/state you want weather for. \"\n",
    "                    \"Please specify the location clearly.\"\n",
    "                )\n",
    "                return TextMessage(content=response_text, source=\"assistant\")\n",
    "\n",
    "        weather_info = self._fetch_weather(city)\n",
    "        if weather_info:\n",
    "            response_text = f\"The current weather in {city}:\\n{weather_info}\"\n",
    "        else:\n",
    "            response_text = f\"Sorry, I couldn't fetch weather data for {city}.\"\n",
    "\n",
    "        logger.debug(f\"[WeatherAgent] Responding: {response_text}\")\n",
    "        return TextMessage(content=response_text, source=\"assistant\")\n",
    "\n",
    "    def _extract_city(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Improved approach to extract the city and state from user text.\n",
    "        Handles more variations in input.\n",
    "        \"\"\"\n",
    "        match = re.search(r\"weather in\\s+([A-Za-z\\s]+(?:,\\s*[A-Za-z]{2,})?)\", text.lower())\n",
    "        if match:\n",
    "            city_name = match.group(1).strip()\n",
    "            # Remove any remaining non-alphanumeric characters except spaces and commas\n",
    "            city_name = re.sub(r\"[^\\w\\s,]\", \"\", city_name)\n",
    "            # Convert multiple spaces to single spaces\n",
    "            city_name = re.sub(r\"\\s+\", \" \", city_name)\n",
    "            city_name = city_name.strip().title()  # Title case\n",
    "            return city_name\n",
    "        return None\n",
    "\n",
    "    async def _extract_city_with_llm(self, user_text: str) -> str:\n",
    "        \"\"\"\n",
    "        Uses GPT to extract the city and state/country, if present.\n",
    "        If GPT can't find a city, returns None.\n",
    "        \"\"\"\n",
    "        system_prompt = (\n",
    "            \"You are a location extraction assistant. Your task is to identify the city and state (or country) from user queries about the weather.\\n\"\n",
    "            \"Return ONLY the city and state/country, separated by a comma and a space. For example: 'Orlando, FL' or 'Tokyo, Japan'.\\n\"\n",
    "            \"If the query does not contain a location, or if you are unsure, return 'NONE'.\\n\"\n",
    "            \"Here are some examples:\\n\"\n",
    "            \"User: What is the weather in Orlando, FL?\\n\"\n",
    "            \"Assistant: Orlando, FL\\n\"\n",
    "            \"User: What is the weather in Washington, DC?\\n\"\n",
    "            \"Assistant: Washington, DC\\n\"\n",
    "            \"User: What is the weather in Virginia Beach, VA?\\n\"\n",
    "            \"Assistant: Virginia Beach, VA\\n\"\n",
    "            \"User: What is the weather in Tokyo, Japan?\\n\"\n",
    "            \"Assistant: Tokyo, Japan\\n\"\n",
    "            \"User: Tell me a joke\\n\"\n",
    "            \"Assistant: NONE\\n\"\n",
    "        )\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_text},\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "\n",
    "            # Perform the OpenAI API call here (synchronously as acompletion isn't directly available)\n",
    "            completion = self.openai_client.chat.completions.create(\n",
    "                model=self.parser_client.model, # Use the same model as the verbose client\n",
    "                messages=messages,\n",
    "                temperature=0.0,\n",
    "                max_tokens=30,\n",
    "                top_p=1.0\n",
    "            )\n",
    "\n",
    "            raw_location = completion.choices[0].message.content.strip()\n",
    "            logger.debug(f\"[WeatherAgent] LLM raw location extraction: '{raw_location}'\")\n",
    "\n",
    "            if raw_location.upper() == \"NONE\":\n",
    "                logger.debug(\"[WeatherAgent] LLM returned 'NONE'.\")\n",
    "                return None\n",
    "\n",
    "            # Split the string by comma and space\n",
    "            parts = [part.strip() for part in raw_location.split(\", \")]  # Split by comma and space\n",
    "\n",
    "            if len(parts) == 2:\n",
    "                city, state = parts\n",
    "                cleaned_city = f\"{city}, {state}\"  # Reassemble with comma and space\n",
    "                logger.debug(f\"[WeatherAgent] Extracted city and state: '{cleaned_city}'\")\n",
    "                return cleaned_city\n",
    "            elif len(parts) == 1:\n",
    "                city = parts[0]\n",
    "                cleaned_city = city\n",
    "                logger.debug(f\"[WeatherAgent] Extracted city only: '{cleaned_city}'\")\n",
    "                return cleaned_city\n",
    "            else:\n",
    "                logger.warning(f\"[WeatherAgent] Unexpected LLM output format: '{raw_location}'\")  # Log unexpected output\n",
    "                return None\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error calling GPT for location extraction: {e}\", exc_info=True)\n",
    "            return None\n",
    "\n",
    "    def _fetch_weather(self, city: str) -> str:\n",
    "        \"\"\"\n",
    "        Calls wttr.in with city name (URL-encoded) requesting Fahrenheit data.\n",
    "        Prioritizes full state name for Florida.\n",
    "        If that fails for a city, state abbreviation, tries the full state name.\n",
    "        Returns a string like \"Overcast, 60Â°F (feels like 58Â°F)\"\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Prioritize full state name for Florida\n",
    "            if \"Orlando, Fl\" in city or \"Miami, Fl\" in city:\n",
    "                city_parts = city.split(\", \")\n",
    "                if len(city_parts) == 2:\n",
    "                    city_name, state_abbreviation = city_parts\n",
    "                    full_state_name = self._get_full_state_name(state_abbreviation)\n",
    "                    if full_state_name:\n",
    "                        full_city = f\"{city_name}, {full_state_name}\"\n",
    "                        city = full_city  # Use the full city for the initial request\n",
    "\n",
    "            city_encoded = quote(city)\n",
    "            # Use &u for Fahrenheit\n",
    "            url = f\"https://wttr.in/{city_encoded}?format=j1&u\"\n",
    "            logger.debug(f\"[WeatherAgent] Calling wttr.in URL: {url}\")\n",
    "\n",
    "            resp = requests.get(url, timeout=10)\n",
    "            resp.raise_for_status()\n",
    "            data = resp.json()\n",
    "            logger.debug(f\"[WeatherAgent] wttr.in response data: {data}\")  # Log the data\n",
    "\n",
    "            current = data.get(\"current_condition\", [{}])[0]\n",
    "            desc = current.get(\"weatherDesc\", [{}])[0].get(\"value\", \"Unknown\")\n",
    "            temp_f = current.get(\"temp_F\", \"?\")\n",
    "            feels_like_f = current.get(\"FeelsLikeF\", \"?\")\n",
    "            humidity = current.get(\"humidity\", \"?\")\n",
    "            wind_speed = current.get(\"windspeedMiles\", \"?\")\n",
    "            wind_direction = current.get(\"winddir16Point\", \"?\")\n",
    "            visibility = current.get(\"visibilityMiles\", \"?\")\n",
    "            pressure = current.get(\"pressureInches\", \"?\")\n",
    "            uv_index = current.get(\"uvIndex\", \"?\")\n",
    "            cloud_cover = current.get(\"cloudcover\", \"?\")\n",
    "            precip_inches = current.get(\"precipInches\", \"?\")\n",
    "\n",
    "            response = (\n",
    "                f\"The current weather in {city}:\\n\"\n",
    "                f\"Condition: {desc}\\n\"\n",
    "                f\"Temperature: {temp_f}Â°F (Feels like {feels_like_f}Â°F)\\n\"\n",
    "                f\"Humidity: {humidity}%\\n\"\n",
    "                f\"Wind: {wind_speed} mph from {wind_direction}\\n\"\n",
    "                f\"Visibility: {visibility} miles\\n\"\n",
    "                f\"Pressure: {pressure} inHg\\n\"\n",
    "                f\"UV Index: {uv_index}\\n\"\n",
    "                f\"Cloud Cover: {cloud_cover}%\\n\"\n",
    "                f\"Precipitation: {precip_inches} inches\\n\\n\"\n",
    "            )\n",
    "\n",
    "            # Daily Forecast (3 days from wttr.in's j1 format)\n",
    "            weather_forecast = data.get(\"weather\", [])\n",
    "            if weather_forecast:\n",
    "                response += \"Forecast:\\n\"\n",
    "                for day in weather_forecast:\n",
    "                    date = day.get(\"date\", \"?\")\n",
    "                    avgtemp_f = day.get(\"avgtempF\", \"?\")\n",
    "                    maxtemp_f = day.get(\"maxtempF\", \"?\")\n",
    "                    mintemp_f = day.get(\"mintempF\", \"?\")\n",
    "                    # Find max chance of rain for the day\n",
    "                    max_chance_of_rain = 0\n",
    "                    for hour in day.get(\"hourly\", []):\n",
    "                        chance_of_rain = int(hour.get(\"chanceofrain\", 0))\n",
    "                        max_chance_of_rain = max(max_chance_of_rain, chance_of_rain)\n",
    "                    description = day.get(\"hourly\", [{}])[0].get(\"weatherDesc\", [{}])[0].get(\"value\", \"?\")\n",
    "\n",
    "                    response += (\n",
    "                        f\"  {date}:\\n\"\n",
    "                        f\"    Condition: {description}\\n\"\n",
    "                        f\"    Avg Temp: {avgtemp_f}Â°F\\n\"\n",
    "                        f\"    Max Temp: {maxtemp_f}Â°F\\n\"\n",
    "                        f\"    Min Temp: {mintemp_f}Â°F\\n\"\n",
    "                        f\"    Chance of Rain: {max_chance_of_rain}%\\n\"\n",
    "                    )\n",
    "\n",
    "            return response\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fetching weather for '{city}': {e}\", exc_info=True)\n",
    "\n",
    "            # If the city contains a state abbreviation, try the full state name\n",
    "            if \", \" in city:\n",
    "                city_parts = city.split(\", \")\n",
    "                if len(city_parts) == 2:\n",
    "                    city_name, state_abbreviation = city_parts\n",
    "                    full_state_name = self._get_full_state_name(state_abbreviation)\n",
    "                    if full_state_name:\n",
    "                        try:\n",
    "                            full_city = f\"{city_name}, {full_state_name}\"\n",
    "                            city_encoded = quote(full_city)\n",
    "                            url = f\"https://wttr.in/{city_encoded}?format=j1&u\"\n",
    "                            logger.debug(f\"[WeatherAgent] Retrying with full state name: {url}\")\n",
    "\n",
    "                            resp = requests.get(url, timeout=10)\n",
    "                            resp.raise_for_status()\n",
    "                            data = resp.json()\n",
    "                            logger.debug(f\"[WeatherAgent] wttr.in retry response data: {data}\") #Log retry data\n",
    "\n",
    "                            current = data.get(\"current_condition\", [{}])[0]\n",
    "                            desc = current.get(\"weatherDesc\", [{}])[0].get(\"value\", \"Unknown\")\n",
    "                            temp_f = current.get(\"temp_F\", \"?\")\n",
    "                            feels_like_f = current.get(\"FeelsLikeF\", \"?\")\n",
    "                            humidity = current.get(\"humidity\", \"?\")\n",
    "                            wind_speed = current.get(\"windspeedMiles\", \"?\")\n",
    "                            wind_direction = current.get(\"winddir16Point\", \"?\")\n",
    "                            visibility = current.get(\"visibilityMiles\", \"?\")\n",
    "                            pressure = current.get(\"pressureInches\", \"?\")\n",
    "                            uv_index = current.get(\"uvIndex\", \"?\")\n",
    "                            cloud_cover = current.get(\"cloudcover\", \"?\")\n",
    "                            precip_inches = current.get(\"precipInches\", \"?\")\n",
    "\n",
    "                            response = (\n",
    "                                f\"The current weather in {full_city}:\\n\"\n",
    "                                f\"Condition: {desc}\\n\"\n",
    "                                f\"Temperature: {temp_f}Â°F (Feels like {feels_like_f}Â°F)\\n\"\n",
    "                                f\"Humidity: {humidity}%\\n\"\n",
    "                                f\"Wind: {wind_speed} mph from {wind_direction}\\n\"\n",
    "                                f\"Visibility: {visibility} miles\\n\"\n",
    "                                f\"Pressure: {pressure} inHg\\n\"\n",
    "                                f\"UV Index: {uv_index}\\n\"\n",
    "                                f\"Cloud Cover: {cloud_cover}%\\n\"\n",
    "                                f\"Precipitation: {precip_inches} inches\\n\\n\"\n",
    "                            )\n",
    "\n",
    "                            # Daily Forecast (3 days from wttr.in's j1 format)\n",
    "                            weather_forecast = data.get(\"weather\", [])\n",
    "                            if weather_forecast:\n",
    "                                response += \"Forecast:\\n\"\n",
    "                                for day in weather_forecast:\n",
    "                                    date = day.get(\"date\", \"?\")\n",
    "                                    avgtemp_f = day.get(\"avgtempF\", \"?\")\n",
    "                                    maxtemp_f = day.get(\"maxtempF\", \"?\")\n",
    "                                    mintemp_f = day.get(\"mintempF\", \"?\")\n",
    "                                    # Find max chance of rain for the day\n",
    "                                    max_chance_of_rain = 0\n",
    "                                    for hour in day.get(\"hourly\", []):\n",
    "                                        chance_of_rain = int(hour.get(\"chanceofrain\", 0))\n",
    "                                        max_chance_of_rain = max(max_chance_of_rain, chance_of_rain)\n",
    "                                    description = day.get(\"hourly\", [{}])[0].get(\"weatherDesc\", [{}])[0].get(\"value\", \"?\")\n",
    "\n",
    "                                    response += (\n",
    "                                        f\"  {date}:\\n\"\n",
    "                                        f\"    Condition: {description}\\n\"\n",
    "                                        f\"    Avg Temp: {avgtemp_f}Â°F\\n\"\n",
    "                                        f\"    Max Temp: {maxtemp_f}Â°F\\n\"\n",
    "                                        f\"    Min Temp: {mintemp_f}Â°F\\n\"\n",
    "                                        f\"    Chance of Rain: {max_chance_of_rain}%\\n\"\n",
    "                                    )\n",
    "\n",
    "                            return response\n",
    "\n",
    "                        except Exception as e:\n",
    "                            logger.error(f\"Error fetching weather for '{full_city}': {e}\", exc_info=True)\n",
    "                            return None\n",
    "            return None\n",
    "\n",
    "    def _get_full_state_name(self, state_abbreviation: str) -> str:\n",
    "        \"\"\"\n",
    "        A simple helper function to convert state abbreviations to full names.\n",
    "        \"\"\"\n",
    "        state_map = {\n",
    "            \"AL\": \"Alabama\",\n",
    "            \"AK\": \"Alaska\",\n",
    "            \"AZ\": \"Arizona\",\n",
    "            \"AR\": \"Arkansas\",\n",
    "            \"CA\": \"California\",\n",
    "            \"CO\": \"Colorado\",\n",
    "            \"CT\": \"Connecticut\",\n",
    "            \"DE\": \"Delaware\",\n",
    "            \"FL\": \"Florida\",\n",
    "            \"GA\": \"Georgia\",\n",
    "            \"HI\": \"Hawaii\",\n",
    "            \"ID\": \"Idaho\",\n",
    "            \"IL\": \"Illinois\",\n",
    "            \"IN\": \"Indiana\",\n",
    "            \"IA\": \"Iowa\",\n",
    "            \"KS\": \"Kansas\",\n",
    "            \"KY\": \"Kentucky\",\n",
    "            \"LA\": \"Louisiana\",\n",
    "            \"ME\": \"Maine\",\n",
    "            \"MD\": \"Maryland\",\n",
    "            \"MA\": \"Massachusetts\",\n",
    "            \"MI\": \"Michigan\",\n",
    "            \"MN\": \"Minnesota\",\n",
    "            \"MS\": \"Mississippi\",\n",
    "            \"MO\": \"Missouri\",\n",
    "            \"MT\": \"Montana\",\n",
    "            \"NE\": \"Nebraska\",\n",
    "            \"NV\": \"Nevada\",\n",
    "            \"NH\": \"New Hampshire\",\n",
    "            \"NJ\": \"New Jersey\",\n",
    "            \"NM\": \"New Mexico\",\n",
    "            \"NY\": \"New York\",\n",
    "            \"NC\": \"North Carolina\",\n",
    "            \"ND\": \"North Dakota\",\n",
    "            \"OH\": \"Ohio\",\n",
    "            \"OK\": \"Oklahoma\",\n",
    "            \"OR\": \"Oregon\",\n",
    "            \"PA\": \"Pennsylvania\",\n",
    "            \"RI\": \"Rhode Island\",\n",
    "            \"SC\": \"South Carolina\",\n",
    "            \"SD\": \"South Dakota\",\n",
    "            \"TN\": \"Tennessee\",\n",
    "            \"TX\": \"Texas\",\n",
    "            \"UT\": \"Utah\",\n",
    "            \"VT\": \"Vermont\",\n",
    "            \"VA\": \"Virginia\",\n",
    "            \"WA\": \"Washington\",\n",
    "            \"WV\": \"West Virginia\",\n",
    "            \"WI\": \"Wisconsin\",\n",
    "            \"WY\": \"Wyoming\",\n",
    "            \"DC\": \"District of Columbia\",\n",
    "        }\n",
    "        return state_map.get(state_abbreviation.upper())\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Main ChatApplication\n",
    "# ---------------------------------------------------------------------------\n",
    "class ChatApplication:\n",
    "    \"\"\"\n",
    "    An interactive chat application with:\n",
    "      1) A main assistant agent (GPT-based)\n",
    "      2) A weather agent (wttr.in, Fahrenheit)\n",
    "    Logs are very verbose; any 'weather' queries route to WeatherAgent.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        logger.debug(\"Initializing ChatApplication with config: %s\", config)\n",
    "        self.config = config\n",
    "        self.openai_api_key = self._load_api_key()\n",
    "\n",
    "        # Create a verbose model client for GPT-based calls\n",
    "        self.model_client = self._create_model_client()\n",
    "\n",
    "        # The main \"assistant\" for general queries\n",
    "        self.assistant = AssistantAgent(\n",
    "            name=\"assistant\",\n",
    "            system_message=self.config.get(\"system_message\", DEFAULT_SYSTEM_MESSAGE),\n",
    "            model_client=self.model_client,\n",
    "        )\n",
    "\n",
    "        # A specialized \"weather_agent\" for weather queries\n",
    "        self.weather_agent = WeatherAgent(\n",
    "            name=\"weather_agent\",\n",
    "            system_message=\"You are a specialized weather agent.\",\n",
    "            model_client=self.model_client\n",
    "        )\n",
    "\n",
    "    def _load_api_key(self):\n",
    "        \"\"\"Loads the OpenAI API key from environment variables.\"\"\"\n",
    "        logger.debug(\"Attempting to load OPENAI_API_KEY from environment variables.\")\n",
    "        openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not openai_api_key:\n",
    "            logger.error(\"OPENAI_API_KEY not found in environment variables.\")\n",
    "            raise ValueError(\"OPENAI_API_KEY not found. Check your .env file or env settings.\")\n",
    "        logger.debug(\"Successfully loaded OPENAI_API_KEY.\")\n",
    "        return openai_api_key\n",
    "\n",
    "    def _create_model_client(self):\n",
    "        \"\"\"Creates the OpenAI client based on the configuration.\"\"\"\n",
    "        model = self.config.get(\"model\", DEFAULT_MODEL)\n",
    "        logger.debug(\"Creating VerboseOpenAIChatCompletionClient with model: %s\", model)\n",
    "        return VerboseOpenAIChatCompletionClient(model=model, api_key=self.openai_api_key)\n",
    "\n",
    "    async def run(self):\n",
    "        \"\"\"\n",
    "        Runs the main interaction loop. If the user's message includes \"weather\",\n",
    "        we delegate to WeatherAgent; else we call the main assistant agent.\n",
    "        \"\"\"\n",
    "        logger.debug(\"Entering main run loop (outer) for ChatApplication.\")\n",
    "        while True:\n",
    "            cancellation_token = CancellationToken()\n",
    "            conversation_history = []\n",
    "            logger.debug(\"Initialized new conversation history; now starting inner loop.\")\n",
    "\n",
    "            try:\n",
    "                while True:\n",
    "                    user_input = input(\"User: \")\n",
    "                    user_input_lower = user_input.lower()\n",
    "\n",
    "                    if user_input_lower in EXIT_COMMANDS:\n",
    "                        logger.info(\"User issued exit command. Exiting application.\")\n",
    "                        print(\"Exiting the assistant. Goodbye!\")\n",
    "                        return\n",
    "\n",
    "                    if user_input_lower == CANCEL_COMMAND:\n",
    "                        logger.info(\"User issued cancel command.\")\n",
    "                        print(\"Cancelling the current operation.\\n\")\n",
    "                        cancellation_token.cancel()\n",
    "                        continue\n",
    "\n",
    "                    # Log user input\n",
    "                    user_message = TextMessage(content=user_input, source=\"user\")\n",
    "                    conversation_history.append(user_message)\n",
    "                    logger.info(f\"User message: {user_input}\")\n",
    "                    logger.debug(\"Current conversation history length: %d\", len(conversation_history))\n",
    "\n",
    "                    # Decide which agent to route to\n",
    "                    if \"weather\" in user_input_lower:\n",
    "                        logger.debug(\"Routing user query to WeatherAgent.\")\n",
    "                        response = await self.weather_agent.on_messages([user_message], cancellation_token)\n",
    "                    else:\n",
    "                        logger.debug(\"Routing user query to main AssistantAgent.\")\n",
    "                        try:\n",
    "                            response = await self.assistant.on_messages([user_message], cancellation_token)\n",
    "                        except asyncio.CancelledError:\n",
    "                            logger.info(\"Operation was cancelled by user.\")\n",
    "                            print(\"Operation cancelled by user.\\n\")\n",
    "                            continue\n",
    "\n",
    "                    # Extract the text from the agent's response\n",
    "                    if hasattr(response, \"chat_message\") and response.chat_message:\n",
    "                        agent_text = response.chat_message.content\n",
    "                    elif hasattr(response, \"content\"):\n",
    "                        agent_text = response.content\n",
    "                    else:\n",
    "                        agent_text = \"No response\"\n",
    "\n",
    "                    print(\"Assistant:\", agent_text, \"\\n\")\n",
    "                    assistant_message = TextMessage(content=agent_text, source=\"assistant\")\n",
    "                    conversation_history.append(assistant_message)\n",
    "\n",
    "                    logger.info(f\"Assistant message: {agent_text}\")\n",
    "                    logger.debug(\"Current conversation history length: %d\", len(conversation_history))\n",
    "\n",
    "            except openai.error.OpenAIError as e:\n",
    "                self._handle_error(\"OpenAI API error\", e, restart=True)\n",
    "\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                self._handle_error(\"Network error\", e, restart=True)\n",
    "\n",
    "            except Exception as e:\n",
    "                self._handle_error(\"An unexpected error occurred\", e, restart=False)\n",
    "                return  # Exit after an unexpected error\n",
    "\n",
    "            logger.debug(\"Exiting main run loop gracefully.\")\n",
    "            break\n",
    "\n",
    "    def _handle_error(self, message, exception, restart=False):\n",
    "        \"\"\"Handles and logs errors, optionally restarting the loop.\"\"\"\n",
    "        logger.error(f\"{message}: {exception}\", exc_info=True)\n",
    "        print(f\"{message}. {'Restarting...' if restart else 'Exiting...'}\\n\")\n",
    "\n",
    "        if restart:\n",
    "            time.sleep(2)  # Brief pause before restarting\n",
    "        else:\n",
    "            return\n",
    "\n",
    "def load_config(filename=CONFIG_FILE):\n",
    "    \"\"\"Loads configuration from a YAML file.\"\"\"\n",
    "    logger.debug(\"Loading configuration from %s\", filename) #Corrected\n",
    "    try:\n",
    "        with open(filename, \"r\") as f:\n",
    "            config_data = yaml.safe_load(f)\n",
    "            logger.debug(\"Configuration loaded successfully: %s\", config_data)\n",
    "            return config_data\n",
    "    except FileNotFoundError:\n",
    "        logger.warning(f\"Configuration file '{filename}' not found. Using default settings.\")\n",
    "        return {}\n",
    "    except yaml.YAMLError as e:\n",
    "        logger.error(f\"Configuration file parsing error: {e}\", exc_info=True)\n",
    "        print(\"Configuration file parsing error. Using default settings.\\n\")\n",
    "        return {}\n",
    "\n",
    "async def main():\n",
    "    try:\n",
    "        logger.debug(\"Entering main() function.\")\n",
    "        config = load_config()\n",
    "        app = ChatApplication(config)\n",
    "        await app.run()\n",
    "        logger.debug(\"main() completed.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unhandled error occurred in main: {e}\", exc_info=True)\n",
    "\n",
    "# ---- Run (Jupyter or standalone) ----\n",
    "load_dotenv()  # If you have a .env with OPENAI_API_KEY\n",
    "try:\n",
    "    await main()    # For Jupyter Notebook\n",
    "except Exception as e:\n",
    "    logger.error(f\"Unhandled exception in Jupyter environment: {e}\", exc_info=True)\n",
    "\n",
    "# If you need standalone .py usage, do:\n",
    "# if __name__ == \"__main__\":\n",
    "#     load_dotenv()\n",
    "#     try:\n",
    "#         asyncio.run(main())\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"Unhandled exception in standalone mode: {e}\", exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1845a81e-976a-412a-ba9b-3b8b5acba48e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26938b74-ce4a-45e9-b36c-454384963902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LangGraph Graph Pattern ===\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```mermaid\n",
       "\n",
       "graph LR\n",
       "%%{init: {'flowchart': {'curve': 'linear'}}}%%\n",
       "    A[User Input] --> B(Extract Intent);\n",
       "    B -- \"route_to=weather_agent_logic\" --> C{Weather Agent};\n",
       "    B -- \"route_to=clothing_agent_logic\" --> D{Clothing Agent};\n",
       "    B -- \"route_to=general_assistant_logic\" --> E{General Assistant};\n",
       "    C --> F(Update History);\n",
       "    D --> F;\n",
       "    E --> F;\n",
       "    F --> G(Send Response);\n",
       "    G --> A;\n",
       "    style A fill:#b3e2cd,stroke:#333,stroke-width:2px\n",
       "    style B fill:#fbb4ae,stroke:#333,stroke-width:2px\n",
       "    style C fill:#ccebc5,stroke:#333,stroke-width:2px\n",
       "    style D fill:#decbe4,stroke:#333,stroke-width:2px\n",
       "    style E fill:#fed9a6,stroke:#333,stroke-width:2px\n",
       "    style F fill:#ffffcc,stroke:#333,stroke-width:2px\n",
       "    style G fill:#e5d8bd,stroke:#333,stroke-width:2px\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import TypedDict, List, Dict, Any\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from IPython.display import Image, display, Markdown  # Import Markdown\n",
    "import asyncio\n",
    "import re\n",
    "\n",
    "# The `State` class definition\n",
    "class State(TypedDict):\n",
    "    user_input: str\n",
    "    conversation_history: List[Dict[str, str]]  # List of messages as {\"role\": \"user|assistant\", \"content\": \"...\"}\n",
    "    last_agent: str  # 'assistant', 'weather_agent', 'what_to_wear_agent'\n",
    "    city: str  # Extracted city for weather-related queries\n",
    "    response: str\n",
    "    route_to: str # the agent it routes to\n",
    "    weather_agent_output : str # the results from the weather agent call\n",
    "    assistant_output : str # the results from main assistant call\n",
    "    what_to_wear_agent_output : str # the results from the what to wear agent call\n",
    "\n",
    "# Dummy agent logic methods to keep the graph declaration in one cell\n",
    "\n",
    "def extract_user_intent(state: State):\n",
    "    \"\"\"\n",
    "    This node extracts the intent from user_input\n",
    "    and returns the agent to use\n",
    "    \"\"\"\n",
    "    user_input_lower = state[\"user_input\"].lower()\n",
    "    if \"weather\" in user_input_lower:\n",
    "        route = \"weather_agent_logic\"\n",
    "    elif \"wear\" in user_input_lower:\n",
    "        route = \"clothing_agent_logic\"\n",
    "    else:\n",
    "        route = \"general_assistant_logic\"\n",
    "\n",
    "    logger.debug(f\"Routing to: {route}\")\n",
    "    return {\"route_to\": route}\n",
    "\n",
    "async def weather_agent_logic(state: State):\n",
    "    \"\"\"\n",
    "    Node that calls the weather agent\n",
    "    \"\"\"\n",
    "    #This will error because the \"weather_agent\" isn't implemented\n",
    "    #Placeholder code\n",
    "    results = \"Weather_Agent called\"\n",
    "\n",
    "    logger.debug(f\"Weather agent responded: {results}\")\n",
    "    return {\"weather_agent_output\": results}\n",
    "\n",
    "async def clothing_agent_logic(state: State):\n",
    "    \"\"\"\n",
    "    Node that calls the clothing agent\n",
    "    \"\"\"\n",
    "    #This will error because the \"what_to_wear_agent\" isn't implemented\n",
    "    #Placeholder code\n",
    "    results = \"What_to_wear_Agent called\"\n",
    "\n",
    "    logger.debug(f\"Clothing agent responded: {results}\")\n",
    "    return {\"what_to_wear_agent_output\": results}\n",
    "\n",
    "async def general_assistant_logic(state: State):\n",
    "    \"\"\"\n",
    "    Node that calls the main assistant agent.\n",
    "    \"\"\"\n",
    "    #This will error because the \"assistant\" isn't implemented\n",
    "    #Placeholder Code\n",
    "    results = \"Assistant agent called\"\n",
    "\n",
    "    logger.debug(f\"Main assistant agent responded: {results}\")\n",
    "    return {\"assistant_output\": results}\n",
    "\n",
    "def send_response(state: State):\n",
    "    \"\"\"\n",
    "    Node that prints the last bot response\n",
    "    \"\"\"\n",
    "    #This will error because there is not response value\n",
    "    responseValue = \"\"\n",
    "\n",
    "    if(state[\"route_to\"] == \"weather_agent_logic\"):\n",
    "        responseValue = state[\"weather_agent_output\"]\n",
    "    elif(state[\"route_to\"] == \"clothing_agent_logic\"):\n",
    "        responseValue = state[\"what_to_wear_agent_output\"]\n",
    "    else:\n",
    "        responseValue = state[\"assistant_output\"]\n",
    "    \n",
    "    print(\"Assistant:\", responseValue, \"\\n\")\n",
    "    return {\"response\": responseValue}\n",
    "\n",
    "def update_history(state: State):\n",
    "    \"\"\"\n",
    "    This node appends the user and assistant turn to conversation history.\n",
    "    \"\"\"\n",
    "    updated_history = state[\"conversation_history\"] + [\n",
    "        {\"role\": \"user\", \"content\": state[\"user_input\"]},\n",
    "        {\"role\": \"assistant\", \"content\": state[\"response\"]},\n",
    "    ]\n",
    "    return {\"conversation_history\": updated_history}\n",
    "\n",
    "def should_route_to_weather(state: State):\n",
    "    \"\"\"\n",
    "    conditional edge to route to weather agent\n",
    "    \"\"\"\n",
    "    if state[\"route_to\"] == \"weather_agent_logic\":\n",
    "        return \"weather_agent_logic\"\n",
    "    else:\n",
    "        return \"extract_intent\"\n",
    "\n",
    "def should_route_to_wear(state: State):\n",
    "    \"\"\"\n",
    "    conditional edge to route to wear agent\n",
    "    \"\"\"\n",
    "    if state[\"route_to\"] == \"clothing_agent_logic\":\n",
    "        return \"clothing_agent_logic\"\n",
    "    else:\n",
    "        return \"extract_intent\"\n",
    "        \n",
    "def should_route_to_assistant(state: State):\n",
    "    \"\"\"\n",
    "    conditional edge to route to main assistant agent\n",
    "    \"\"\"\n",
    "    if state[\"route_to\"] == \"general_assistant_logic\":\n",
    "        return \"general_assistant_logic\"\n",
    "    else:\n",
    "        return \"extract_intent\" #Revisits to get to new agent if applicable\n",
    "\n",
    "# 2) Build the graph\n",
    "builder_graph = StateGraph(State)\n",
    "\n",
    "# 3) Add nodes\n",
    "builder_graph.add_node(\"extract_intent\", extract_user_intent)\n",
    "builder_graph.add_node(\"weather_agent_logic\", weather_agent_logic)\n",
    "builder_graph.add_node(\"clothing_agent_logic\", clothing_agent_logic)\n",
    "builder_graph.add_node(\"general_assistant_logic\", general_assistant_logic)\n",
    "builder_graph.add_node(\"send_response\", send_response)\n",
    "builder_graph.add_node(\"update_history\", update_history)\n",
    "\n",
    "# 4) Add edges and conditional edges\n",
    "\n",
    "builder_graph.set_entry_point(\"extract_intent\") #first node\n",
    "\n",
    "builder_graph.add_conditional_edges(\n",
    "    \"extract_intent\",\n",
    "    should_route_to_weather,\n",
    "    {\n",
    "        \"weather_agent_logic\": \"weather_agent_logic\",\n",
    "        \"extract_intent\": \"extract_intent\" #On a no route to weather should loop back\n",
    "    }\n",
    ")\n",
    "\n",
    "builder_graph.add_conditional_edges(\n",
    "    \"extract_intent\",\n",
    "    should_route_to_wear,\n",
    "    {\n",
    "        \"clothing_agent_logic\": \"clothing_agent_logic\",\n",
    "        \"extract_intent\": \"extract_intent\" #On a no route to wear, should loop back\n",
    "    }\n",
    ")\n",
    "\n",
    "builder_graph.add_conditional_edges(\n",
    "    \"extract_intent\",\n",
    "    should_route_to_assistant,\n",
    "    {\n",
    "        \"general_assistant_logic\": \"general_assistant_logic\",\n",
    "        \"extract_intent\": \"extract_intent\" #On a no route to wear, should loop back\n",
    "    }\n",
    ")\n",
    "\n",
    "builder_graph.add_edge(\"weather_agent_logic\", \"update_history\")\n",
    "builder_graph.add_edge(\"clothing_agent_logic\", \"update_history\")\n",
    "builder_graph.add_edge(\"general_assistant_logic\", \"update_history\")\n",
    "builder_graph.add_edge(\"update_history\", \"send_response\")\n",
    "builder_graph.add_edge(\"send_response\", \"extract_intent\")\n",
    "\n",
    "# 5) Compile\n",
    "graph_graph = builder_graph.compile()\n",
    "print(\"\\n=== LangGraph Graph Pattern ===\")\n",
    "\n",
    "from IPython.display import Markdown\n",
    "\n",
    "mermaid_syntax = \"\"\"\n",
    "graph LR\n",
    "%%{init: {'flowchart': {'curve': 'linear'}}}%%\n",
    "    A[User Input] --> B(Extract Intent);\n",
    "    B -- \"route_to=weather_agent_logic\" --> C{Weather Agent};\n",
    "    B -- \"route_to=clothing_agent_logic\" --> D{Clothing Agent};\n",
    "    B -- \"route_to=general_assistant_logic\" --> E{General Assistant};\n",
    "    C --> F(Update History);\n",
    "    D --> F;\n",
    "    E --> F;\n",
    "    F --> G(Send Response);\n",
    "    G --> A;\n",
    "    style A fill:#b3e2cd,stroke:#333,stroke-width:2px\n",
    "    style B fill:#fbb4ae,stroke:#333,stroke-width:2px\n",
    "    style C fill:#ccebc5,stroke:#333,stroke-width:2px\n",
    "    style D fill:#decbe4,stroke:#333,stroke-width:2px\n",
    "    style E fill:#fed9a6,stroke:#333,stroke-width:2px\n",
    "    style F fill:#ffffcc,stroke:#333,stroke-width:2px\n",
    "    style G fill:#e5d8bd,stroke:#333,stroke-width:2px\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(f\"```mermaid\\n{mermaid_syntax}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f15e98b-d3fd-4528-b012-a595165a7a0b",
   "metadata": {},
   "source": [
    "# added a Clothing Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6e8a4fc-af75-492f-a41e-c6a311f33c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  what is the climate for Bethesda, MD?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Bethesda, MD, has a humid subtropical climate. It experiences four distinct seasons:\n",
      "\n",
      "- **Spring:** Mild and pleasant, with temperatures gradually warming.\n",
      "- **Summer:** Hot and humid, with temperatures often reaching the 80s and 90s Â°F (around 27-37 Â°C).\n",
      "- **Fall:** Cool and crisp, with temperatures gradually decreasing and beautiful fall foliage.\n",
      "- **Winter:** Cold, with occasional snowfall. Temperatures can range from the 20s to 40s Â°F (-6 to 4 Â°C).\n",
      "\n",
      "Rain is fairly evenly distributed throughout the year. \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  what is the temperature for Bethesda, MD?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: The temperature in Bethesda, MD, can vary significantly depending on the time of year:\n",
      "\n",
      "- **Winter (December-February):** Average lows range from the mid-20s to 30s Â°F (-4 to 3 Â°C), while highs are often in the 40s Â°F (4-9 Â°C).\n",
      "- **Spring (March-May):** Temperatures gradually warm, with averages ranging from 40s to 70s Â°F (4-24 Â°C).\n",
      "- **Summer (June-August):** Hot season, with average highs in the 80s to low 90s Â°F (27-34 Â°C) and lows in the 60s to 70s Â°F (16-24 Â°C).\n",
      "- **Fall (September-November):** Temperatures cool down, with averages ranging from 50s to 70s Â°F (10-24 Â°C).\n",
      "\n",
      "For the current temperature, you might need to check a local weather service or weather app. \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the assistant. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import asyncio\n",
    "import logging\n",
    "import openai\n",
    "import requests\n",
    "import yaml\n",
    "import re\n",
    "from requests.utils import quote\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "# Import the raw client\n",
    "from openai import OpenAI\n",
    "from openai import AuthenticationError, RateLimitError, APIConnectionError, APIStatusError\n",
    "\n",
    "# Uncomment these lines if you want *raw* HTTP-level debug output:\n",
    "\"\"\"\n",
    "import http.client as http_client\n",
    "http_client.HTTPConnection.debuglevel = 1\n",
    "logging.getLogger(\"http.client\").setLevel(logging.DEBUG)\n",
    "logging.getLogger(\"http.client\").propagate = True\n",
    "\"\"\"\n",
    "\n",
    "# ---- Constants ----\n",
    "EXIT_COMMANDS = {\"exit\", \"quit\", \"!exit\"}\n",
    "CANCEL_COMMAND = \"!cancel\"\n",
    "DEFAULT_MODEL = \"gpt-4o\"\n",
    "DEFAULT_SYSTEM_MESSAGE = \"You are a helpful assistant.\"\n",
    "CONFIG_FILE = \"config.yaml\"\n",
    "LOG_FILE = \"log.txt\"\n",
    "\n",
    "# ---- Configure Very Verbose Logging ----\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)  # Set to DEBUG for very verbose output\n",
    "\n",
    "# Remove any existing handlers (useful if re-running in Jupyter)\n",
    "for handler in logger.handlers[:]:\n",
    "    logger.removeHandler(handler)\n",
    "\n",
    "file_handler = logging.FileHandler(LOG_FILE)\n",
    "formatter = logging.Formatter(\n",
    "    '%(asctime)s - %(levelname)s - %(module)s - %(funcName)s:%(lineno)d - %(message)s'\n",
    ")\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "logger.debug(\"Logger initialized at DEBUG level. Very verbose mode is enabled.\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Verbose client for the main assistant calls (GPT). Logs raw request/response.\n",
    "# ---------------------------------------------------------------------------\n",
    "class VerboseOpenAIChatCompletionClient(OpenAIChatCompletionClient):\n",
    "    \"\"\"\n",
    "    An extension of OpenAIChatCompletionClient that logs detailed request/response data\n",
    "    at INFO level, matching your prior logging style.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, api_key):\n",
    "        super().__init__(model=model, api_key=api_key)\n",
    "        self.model = model  # Store the model\n",
    "\n",
    "    async def _send_request(self, messages, **kwargs):\n",
    "        url = \"https://api.openai.com/v1/chat/completions\"\n",
    "        logger.info(f\"HTTP Request: POST {url} 'HTTP/1.1 200 OK'\")\n",
    "        response = await super()._send_request(messages, **kwargs)\n",
    "\n",
    "        import json\n",
    "\n",
    "        log_payload = {\"type\": \"LLMCall\", \"messages\": messages, \"response\": response}\n",
    "        logger.info(json.dumps(log_payload))\n",
    "        logger.debug(\"Received response from OpenAI (debug): %s\", response)\n",
    "        return response\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# WeatherAgent for queries containing \"weather\"\n",
    "# Now uses Fahrenheit data (&u) and parses temp_F, FeelsLikeF.\n",
    "# ---------------------------------------------------------------------------\n",
    "class WeatherAgent(AssistantAgent):\n",
    "    \"\"\"\n",
    "    A specialized agent that queries wttr.in for weather data in Fahrenheit (USCS).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name, system_message, model_client):\n",
    "        super().__init__(name=name, system_message=system_message, model_client=model_client)\n",
    "        self.parser_client = model_client  # Initialize parser_client with the verbose model_client\n",
    "        self.openai_client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])  # Create sync openai client\n",
    "\n",
    "    async def on_messages(self, messages, cancellation_token=None):\n",
    "        user_message = messages[-1].content\n",
    "        logger.debug(f\"[WeatherAgent] Received message: {user_message}\")\n",
    "\n",
    "        city = self._extract_city(user_message)\n",
    "        if not city:\n",
    "            city = await self._extract_city_with_llm(user_message)\n",
    "            if not city:\n",
    "                response_text = \"I'm not sure which city/state you want weather for. \" \"Please specify the location clearly.\"\n",
    "                return TextMessage(content=response_text, source=\"assistant\")\n",
    "\n",
    "        weather_info = self._fetch_weather(city)\n",
    "        if weather_info:\n",
    "            response_text = f\"The current weather in {city}:\\n{weather_info}\"\n",
    "        else:\n",
    "            response_text = f\"Sorry, I couldn't fetch weather data for {city}.\"\n",
    "\n",
    "        logger.debug(f\"[WeatherAgent] Responding: {response_text}\")\n",
    "        return TextMessage(content=response_text, source=\"assistant\")\n",
    "\n",
    "    def _extract_city(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Improved approach to extract the city and state from user text.\n",
    "        Handles more variations in input.\n",
    "        \"\"\"\n",
    "        match = re.search(r\"weather in\\s+([A-Za-z\\s]+(?:,\\s*[A-Za-z]{2,})?)\", text.lower())\n",
    "        if match:\n",
    "            city_name = match.group(1).strip()\n",
    "            # Remove any remaining non-alphanumeric characters except spaces and commas\n",
    "            city_name = re.sub(r\"[^\\w\\s,]\", \"\", city_name)\n",
    "            # Convert multiple spaces to single spaces\n",
    "            city_name = re.sub(r\"\\s+\", \" \", city_name)\n",
    "            city_name = city_name.strip().title()  # Title case\n",
    "            return city_name\n",
    "        return None\n",
    "\n",
    "    async def _extract_city_with_llm(self, user_text: str) -> str:\n",
    "        \"\"\"\n",
    "        Uses GPT to extract the city and state/country, if present.\n",
    "        If GPT can't find a city, returns None.\n",
    "        \"\"\"\n",
    "        system_prompt = (\n",
    "            \"You are a location extraction assistant. Your task is to identify the city and state (or country) from user queries about the weather.\\n\"\n",
    "            \"Return ONLY the city and state/country, separated by a comma and a space. For example: 'Orlando, FL' or 'Tokyo, Japan'.\\n\"\n",
    "            \"If the query does not contain a location, or if you are unsure, return 'NONE'.\\n\"\n",
    "            \"Here are some examples:\\n\"\n",
    "            \"User: What is the weather in Orlando, FL?\\n\"\n",
    "            \"Assistant: Orlando, FL\\n\"\n",
    "            \"User: What is the weather in Washington, DC?\\n\"\n",
    "            \"Assistant: Washington, DC\\n\"\n",
    "            \"User: What is the weather in Virginia Beach, VA?\\n\"\n",
    "            \"Assistant: Virginia Beach, VA\\n\"\n",
    "            \"User: What is the weather in Tokyo, Japan\\n\"\n",
    "            \"Assistant: Tokyo, Japan\\n\"\n",
    "            \"User: Tell me a joke\\n\"\n",
    "            \"Assistant: NONE\\n\"\n",
    "        )\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_text},\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "\n",
    "            # Perform the OpenAI API call here (synchronously as acompletion isn't directly available)\n",
    "            completion = self.openai_client.chat.completions.create(\n",
    "                model=self.parser_client.model,  # Use the same model as the verbose client\n",
    "                messages=messages,\n",
    "                temperature=0.0,\n",
    "                max_tokens=30,\n",
    "                top_p=1.0,\n",
    "            )\n",
    "\n",
    "            raw_location = completion.choices[0].message.content.strip()\n",
    "            logger.debug(f\"[WeatherAgent] LLM raw location extraction: '{raw_location}'\")\n",
    "\n",
    "            if raw_location.upper() == \"NONE\":\n",
    "                logger.debug(\"[WeatherAgent] LLM returned 'NONE'.\")\n",
    "                return None\n",
    "\n",
    "            # Split the string by comma and space\n",
    "            parts = [part.strip() for part in raw_location.split(\", \")]  # Split by comma and space\n",
    "\n",
    "            if len(parts) == 2:\n",
    "                city, state = parts\n",
    "                cleaned_city = f\"{city}, {state}\"  # Reassemble with comma and space\n",
    "                logger.debug(f\"[WeatherAgent] Extracted city and state: '{cleaned_city}'\")\n",
    "                return cleaned_city\n",
    "            elif len(parts) == 1:\n",
    "                city = parts[0]\n",
    "                cleaned_city = city\n",
    "                logger.debug(f\"[WeatherAgent] Extracted city only: '{cleaned_city}'\")\n",
    "                return cleaned_city\n",
    "            else:\n",
    "                logger.warning(f\"[WeatherAgent] Unexpected LLM output format: '{raw_location}'\")  # Log unexpected output\n",
    "                return None\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error calling GPT for location extraction: {e}\", exc_info=True)\n",
    "            return None\n",
    "\n",
    "    def _fetch_weather(self, city: str) -> str:\n",
    "        \"\"\"\n",
    "        Calls wttr.in with city name (URL-encoded) requesting Fahrenheit data.\n",
    "        Prioritizes full state name for Florida.\n",
    "        If that fails for a city, state abbreviation, tries the full state name.\n",
    "        Returns a string like \"Overcast, 60Â°F (feels like 58Â°F)\"\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Prioritize full state name for Florida\n",
    "            if \"Orlando, Fl\" in city or \"Miami, Fl\" in city:\n",
    "                city_parts = city.split(\", \")\n",
    "                if len(city_parts) == 2:\n",
    "                    city_name, state_abbreviation = city_parts\n",
    "                    full_state_name = self._get_full_state_name(state_abbreviation)\n",
    "                    if full_state_name:\n",
    "                        full_city = f\"{city_name}, {full_state_name}\"\n",
    "                        city = full_city  # Use the full city for the initial request\n",
    "\n",
    "            city_encoded = quote(city)\n",
    "            # Use &u for Fahrenheit\n",
    "            url = f\"https://wttr.in/{city_encoded}?format=j1&u\"\n",
    "            logger.debug(f\"[WeatherAgent] Calling wttr.in URL: {url}\")\n",
    "\n",
    "            resp = requests.get(url, timeout=10)\n",
    "            resp.raise_for_status()\n",
    "            data = resp.json()\n",
    "            logger.debug(f\"[WeatherAgent] wttr.in response data: {data}\")  # Log the data\n",
    "\n",
    "            current = data.get(\"current_condition\", [{}])[0]\n",
    "            desc = current.get(\"weatherDesc\", [{}])[0].get(\"value\", \"Unknown\")\n",
    "            temp_f = current.get(\"temp_F\", \"?\")\n",
    "            feels_like_f = current.get(\"FeelsLikeF\", \"?\")\n",
    "            humidity = current.get(\"humidity\", \"?\")\n",
    "            wind_speed = current.get(\"windspeedMiles\", \"?\")\n",
    "            wind_direction = current.get(\"winddir16Point\", \"?\")\n",
    "            visibility = current.get(\"visibilityMiles\", \"?\")\n",
    "            pressure = current.get(\"pressureInches\", \"?\")\n",
    "            uv_index = current.get(\"uvIndex\", \"?\")\n",
    "            cloud_cover = current.get(\"cloudcover\", \"?\")\n",
    "            precip_inches = current.get(\"precipInches\", \"?\")\n",
    "\n",
    "            response = (\n",
    "                f\"The current weather in {city}:\\n\"\n",
    "                f\"Condition: {desc}\\n\"\n",
    "                f\"Temperature: {temp_f}Â°F (Feels like {feels_like_f}Â°F)\\n\"\n",
    "                f\"Humidity: {humidity}%\\n\"\n",
    "                f\"Wind: {wind_speed} mph from {wind_direction}\\n\"\n",
    "                f\"Visibility: {visibility} miles\\n\"\n",
    "                f\"Pressure: {pressure} inHg\\n\"\n",
    "                f\"UV Index: {uv_index}\\n\"\n",
    "                f\"Cloud Cover: {cloud_cover}%\\n\"\n",
    "                f\"Precipitation: {precip_inches} inches\\n\\n\"\n",
    "            )\n",
    "\n",
    "            # Daily Forecast (3 days from wttr.in's j1 format)\n",
    "            weather_forecast = data.get(\"weather\", [])\n",
    "            if weather_forecast:\n",
    "                response += \"Forecast:\\n\"\n",
    "                for day in weather_forecast:\n",
    "                    date = day.get(\"date\", \"?\")\n",
    "                    avgtemp_f = day.get(\"avgtempF\", \"?\")\n",
    "                    maxtemp_f = day.get(\"maxtempF\", \"?\")\n",
    "                    mintemp_f = day.get(\"mintempF\", \"?\")\n",
    "                    # Find max chance of rain for the day\n",
    "                    max_chance_of_rain = 0\n",
    "                    for hour in day.get(\"hourly\", []):\n",
    "                        chance_of_rain = int(hour.get(\"chanceofrain\", 0))\n",
    "                        max_chance_of_rain = max(max_chance_of_rain, chance_of_rain)\n",
    "                    description = day.get(\"hourly\", [{}])[0].get(\"weatherDesc\", [{}])[0].get(\"value\", \"?\")\n",
    "\n",
    "                    response += (\n",
    "                        f\"  {date}:\\n\"\n",
    "                        f\"    Condition: {description}\\n\"\n",
    "                        f\"    Avg Temp: {avgtemp_f}Â°F\\n\"\n",
    "                        f\"    Max Temp: {maxtemp_f}Â°F\\n\"\n",
    "                        f\"    Min Temp: {mintemp_f}Â°F\\n\"\n",
    "                        f\"    Chance of Rain: {max_chance_of_rain}%\\n\"\n",
    "                    )\n",
    "\n",
    "            return response\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fetching weather for '{city}': {e}\", exc_info=True)\n",
    "\n",
    "            # If the city contains a state abbreviation, try the full state name\n",
    "            if \", \" in city:\n",
    "                city_parts = city.split(\", \")\n",
    "                if len(city_parts) == 2:\n",
    "                    city_name, state_abbreviation = city_parts\n",
    "                    full_state_name = self._get_full_state_name(state_abbreviation)\n",
    "                    if full_state_name:\n",
    "                        try:\n",
    "                            full_city = f\"{city_name}, {full_state_name}\"\n",
    "                            city_encoded = quote(full_city)\n",
    "                            url = f\"https://wttr.in/{city_encoded}?format=j1&u\"\n",
    "                            logger.debug(f\"[WeatherAgent] Retrying with full state name: {url}\")\n",
    "\n",
    "                            resp = requests.get(url, timeout=10)\n",
    "                            resp.raise_for_status()\n",
    "                            data = resp.json()\n",
    "                            logger.debug(f\"[WeatherAgent] wttr.in retry response data: {data}\")  # Log retry data\n",
    "\n",
    "                            current = data.get(\"current_condition\", [{}])[0]\n",
    "                            desc = current.get(\"weatherDesc\", [{}])[0].get(\"value\", \"Unknown\")\n",
    "                            temp_f = current.get(\"temp_F\", \"?\")\n",
    "                            feels_like_f = current.get(\"FeelsLikeF\", \"?\")\n",
    "                            humidity = current.get(\"humidity\", \"?\")\n",
    "                            wind_speed = current.get(\"windspeedMiles\", \"?\")\n",
    "                            wind_direction = current.get(\"winddir16Point\", \"?\")\n",
    "                            visibility = current.get(\"visibilityMiles\", \"?\")\n",
    "                            pressure = current.get(\"pressureInches\", \"?\")\n",
    "                            uv_index = current.get(\"uvIndex\", \"?\")\n",
    "                            cloud_cover = current.get(\"cloudcover\", \"?\")\n",
    "                            precip_inches = current.get(\"precipInches\", \"?\")\n",
    "\n",
    "                            response = (\n",
    "                                f\"The current weather in {full_city}:\\n\"\n",
    "                                f\"Condition: {desc}\\n\"\n",
    "                                f\"Temperature: {temp_f}Â°F (Feels like {feels_like_f}Â°F)\\n\"\n",
    "                                f\"Humidity: {humidity}%\\n\"\n",
    "                                f\"Wind: {wind_speed} mph from {wind_direction}\\n\"\n",
    "                                f\"Visibility: {visibility} miles\\n\"\n",
    "                                f\"Pressure: {pressure} inHg\\n\"\n",
    "                                f\"UV Index: {uv_index}\\n\"\n",
    "                                f\"Cloud Cover: {cloud_cover}%\\n\"\n",
    "                                f\"Precipitation: {precip_inches} inches\\n\\n\"\n",
    "                            )\n",
    "\n",
    "                            # Daily Forecast (3 days from wttr.in's j1 format)\n",
    "                            weather_forecast = data.get(\"weather\", [])\n",
    "                            if weather_forecast:\n",
    "                                response += \"Forecast:\\n\"\n",
    "                                for day in weather_forecast:\n",
    "                                    date = day.get(\"date\", \"?\")\n",
    "                                    avgtemp_f = day.get(\"avgtempF\", \"?\")\n",
    "                                    maxtemp_f = day.get(\"maxtempF\", \"?\")\n",
    "                                    mintemp_f = day.get(\"mintempF\", \"?\")\n",
    "                                    # Find max chance of rain for the day\n",
    "                                    max_chance_of_rain = 0\n",
    "                                    for hour in day.get(\"hourly\", []):\n",
    "                                        chance_of_rain = int(hour.get(\"chanceofrain\", 0))\n",
    "                                        max_chance_of_rain = max(max_chance_of_rain, chance_of_rain)\n",
    "                                    description = day.get(\"hourly\", [{}])[0].get(\"weatherDesc\", [{}])[0].get(\"value\", \"?\")\n",
    "\n",
    "                                    response += (\n",
    "                                        f\"  {date}:\\n\"\n",
    "                                        f\"    Condition: {description}\\n\"\n",
    "                                        f\"    Avg Temp: {avgtemp_f}Â°F\\n\"\n",
    "                                        f\"    Max Temp: {maxtemp_f}Â°F\\n\"\n",
    "                                        f\"    Min Temp: {mintemp_f}Â°F\\n\"\n",
    "                                        f\"    Chance of Rain: {max_chance_of_rain}%\\n\"\n",
    "                                    )\n",
    "\n",
    "                            return response\n",
    "\n",
    "                        except Exception as e:\n",
    "                            logger.error(f\"Error fetching weather for '{full_city}': {e}\", exc_info=True)\n",
    "                            return None\n",
    "            return None\n",
    "\n",
    "    def _get_full_state_name(self, state_abbreviation: str) -> str:\n",
    "        \"\"\"\n",
    "        A simple helper function to convert state abbreviations to full names.\n",
    "        \"\"\"\n",
    "        state_map = {\n",
    "            \"AL\": \"Alabama\",\n",
    "            \"AK\": \"Alaska\",\n",
    "            \"AZ\": \"Arizona\",\n",
    "            \"AR\": \"Arkansas\",\n",
    "            \"CA\": \"California\",\n",
    "            \"CO\": \"Colorado\",\n",
    "            \"CT\": \"Connecticut\",\n",
    "            \"DE\": \"Delaware\",\n",
    "            \"FL\": \"Florida\",\n",
    "            \"GA\": \"Georgia\",\n",
    "            \"HI\": \"Hawaii\",\n",
    "            \"ID\": \"Idaho\",\n",
    "            \"IL\": \"Illinois\",\n",
    "            \"IN\": \"Indiana\",\n",
    "            \"IA\": \"Iowa\",\n",
    "            \"KS\": \"Kansas\",\n",
    "            \"KY\": \"Kentucky\",\n",
    "            \"LA\": \"Louisiana\",\n",
    "            \"ME\": \"Maine\",\n",
    "            \"MD\": \"Maryland\",\n",
    "            \"MA\": \"Massachusetts\",\n",
    "            \"MI\": \"Michigan\",\n",
    "            \"MN\": \"Minnesota\",\n",
    "            \"MS\": \"Mississippi\",\n",
    "            \"MO\": \"Missouri\",\n",
    "            \"MT\": \"Montana\",\n",
    "            \"NE\": \"Nebraska\",\n",
    "            \"NV\": \"Nevada\",\n",
    "            \"NH\": \"New Hampshire\",\n",
    "            \"NJ\": \"New Jersey\",\n",
    "            \"NM\": \"New Mexico\",\n",
    "            \"NY\": \"New York\",\n",
    "            \"NC\": \"North Carolina\",\n",
    "            \"ND\": \"North Dakota\",\n",
    "            \"OH\": \"Ohio\",\n",
    "            \"OK\": \"Oklahoma\",\n",
    "            \"OR\": \"Oregon\",\n",
    "            \"PA\": \"Pennsylvania\",\n",
    "            \"RI\": \"Rhode Island\",\n",
    "            \"SC\": \"South Carolina\",\n",
    "            \"SD\": \"South Dakota\",\n",
    "            \"TN\": \"Tennessee\",\n",
    "            \"TX\": \"Texas\",\n",
    "            \"UT\": \"Utah\",\n",
    "            \"VT\": \"Vermont\",\n",
    "            \"VA\": \"Virginia\",\n",
    "            \"WA\": \"Washington\",\n",
    "            \"WV\": \"West Virginia\",\n",
    "            \"WI\": \"Wisconsin\",\n",
    "            \"WY\": \"Wyoming\",\n",
    "            \"DC\": \"District of Columbia\",\n",
    "        }\n",
    "        return state_map.get(state_abbreviation.upper())\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# WhatToWearAgent for clothing recommendations\n",
    "# ---------------------------------------------------------------------------\n",
    "class WhatToWearAgent(AssistantAgent):\n",
    "    \"\"\"\n",
    "    A specialized agent that recommends clothing based on weather data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name, system_message, model_client):\n",
    "        super().__init__(name=name, system_message=system_message, model_client=model_client)\n",
    "        self.parser_client = model_client  # Initialize parser_client with the verbose model_client\n",
    "        self.openai_client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "        self.model_client = model_client  # VERY IMPORTANT:  Assign model_client to self.\n",
    "\n",
    "    async def on_messages(self, messages, cancellation_token=None):\n",
    "        user_message = messages[-1].content\n",
    "        logger.debug(f\"[WhatToWearAgent] Received message: {user_message}\")\n",
    "\n",
    "        # Extract location from the user message (similar to WeatherAgent)\n",
    "        city = await self._extract_city_with_llm(user_message)\n",
    "        if not city:\n",
    "            response_text = (\n",
    "                \"I'm not sure which city/state you want clothing advice for. \"\n",
    "                \"Please specify the location clearly.\"\n",
    "            )\n",
    "            return TextMessage(content=response_text, source=\"assistant\")\n",
    "\n",
    "        # Fetch weather data (using WeatherAgent's method or a similar one)\n",
    "        weather_data = await self._get_weather_data(city)  # Implement this method\n",
    "\n",
    "        if weather_data:\n",
    "            # Generate clothing recommendation based on weather data\n",
    "            clothing_recommendation = self._generate_clothing_recommendation(weather_data)\n",
    "            response_text = f\"For {city}, based on the weather: {clothing_recommendation}\"\n",
    "        else:\n",
    "            response_text = f\"Sorry, I couldn't fetch weather data for {city} to provide clothing advice.\"\n",
    "\n",
    "        logger.debug(f\"[WhatToWearAgent] Responding: {response_text}\")\n",
    "        return TextMessage(content=response_text, source=\"assistant\")\n",
    "\n",
    "    async def _extract_city_with_llm(self, user_text: str) -> str:\n",
    "        \"\"\"\n",
    "        Extracts the city and state/country from the user's text.\n",
    "        Uses LLM to improve extraction.\n",
    "        \"\"\"\n",
    "        # Reuse the WeatherAgent's city extraction logic (copy or refactor)\n",
    "        system_prompt = (\n",
    "            \"You are a location extraction assistant. Your task is to identify the city and state (or country) from user queries about the weather.\\n\"\n",
    "            \"Return ONLY the city and state/country, separated by a comma and a space. For example: 'Orlando, FL' or 'Tokyo, Japan'.\\n\"\n",
    "            \"If the query does not contain a location, or if you are unsure, return 'NONE'.\\n\"\n",
    "            \"Here are some examples:\\n\"\n",
    "            \"User: What is the weather in Orlando, FL?\\n\"\n",
    "            \"Assistant: Orlando, FL\\n\"\n",
    "            \"User: What is the weather in Washington, DC?\\n\"\n",
    "            \"Assistant: Washington, DC\\n\"\n",
    "            \"User: What is the weather in Virginia Beach, VA?\\n\"\n",
    "            \"Assistant: Virginia Beach, VA\\n\"\n",
    "            \"User: What is the weather in Tokyo, Japan\\n\"\n",
    "            \"Assistant: Tokyo, Japan\\n\"\n",
    "            \"User: Tell me a joke\\n\"\n",
    "            \"Assistant: NONE\\n\"\n",
    "        )\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_text},\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "\n",
    "            # Perform the OpenAI API call here (synchronously as acompletion isn't directly available)\n",
    "            completion = self.openai_client.chat.completions.create(\n",
    "                model=self.parser_client.model,  # Use the same model as the verbose client\n",
    "                messages=messages,\n",
    "                temperature=0.0,\n",
    "                max_tokens=30,\n",
    "                top_p=1.0,\n",
    "            )\n",
    "\n",
    "            raw_location = completion.choices[0].message.content.strip()\n",
    "            logger.debug(f\"[WeatherAgent] LLM raw location extraction: '{raw_location}'\")\n",
    "\n",
    "            if raw_location.upper() == \"NONE\":\n",
    "                logger.debug(\"[WeatherAgent] LLM returned 'NONE'.\")\n",
    "                return None\n",
    "\n",
    "            # Split the string by comma and space\n",
    "            parts = [part.strip() for part in raw_location.split(\", \")]  # Split by comma and space\n",
    "\n",
    "            if len(parts) == 2:\n",
    "                city, state = parts\n",
    "                cleaned_city = f\"{city}, {state}\"  # Reassemble with comma and space\n",
    "                logger.debug(f\"[WeatherAgent] Extracted city and state: '{cleaned_city}'\")\n",
    "                return cleaned_city\n",
    "            elif len(parts) == 1:\n",
    "                city = parts[0]\n",
    "                cleaned_city = city\n",
    "                logger.debug(f\"[WeatherAgent] Extracted city only: '{cleaned_city}'\")\n",
    "                return cleaned_city\n",
    "            else:\n",
    "                logger.warning(f\"[WeatherAgent] Unexpected LLM output format: '{raw_location}'\")  # Log unexpected output\n",
    "                return None\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error calling GPT for location extraction: {e}\", exc_info=True)\n",
    "            return None\n",
    "\n",
    "    async def _get_weather_data(self, city: str) -> str:  # return type hint of weather data output, from _fetch_weather\n",
    "        \"\"\"\n",
    "        Fetches weather data for the given city.\n",
    "        Reuses the _fetch_weather method from the WeatherAgent.\n",
    "        \"\"\"\n",
    "        # Create a temporary WeatherAgent instance to reuse its method\n",
    "        temp_weather_agent = WeatherAgent(\n",
    "            name=\"temp_weather_agent\",\n",
    "            system_message=\"Temporary agent for fetching weather.\",\n",
    "            model_client=self.model_client,  # Use the stored model_client here\n",
    "        )\n",
    "        return temp_weather_agent._fetch_weather(city)  # return the string output of a successful API call\n",
    "\n",
    "    def _generate_clothing_recommendation(self, weather_data: str) -> str:  # input the string weather data, output a clothing recommendation\n",
    "        \"\"\"\n",
    "        Generates a clothing recommendation based on the weather data.\n",
    "        \"\"\"\n",
    "        # Parse the weather data string (you might want to use a more robust method)\n",
    "        temperature_match = re.search(r\"Temperature: (\\d+)Â°F\", weather_data)  # match the temperature in the string data\n",
    "        if temperature_match:\n",
    "            temperature = int(temperature_match.group(1))  # convert the group to a number\n",
    "        else:\n",
    "            return \"Unable to determine temperature, so dress in layers.\"  # if it fails to read the number\n",
    "\n",
    "        # Precipitation check\n",
    "        rain_match = re.search(r\"Precipitation: ([\\d.]+) inches\", weather_data)\n",
    "        chance_of_rain_match = re.search(r\"Chance of Rain: (\\d+)%\", weather_data)\n",
    "\n",
    "        rain_gear = \"\"\n",
    "        if rain_match and float(rain_match.group(1)) > 0:\n",
    "            rain_gear = \"Bring an umbrella and wear waterproof shoes.\"\n",
    "        elif chance_of_rain_match and int(chance_of_rain_match.group(1)) > 50:\n",
    "            rain_gear = \"There's a chance of rain, so bring an umbrella and wear waterproof shoes.\"\n",
    "\n",
    "        # Simple clothing logic (you can expand this)\n",
    "        if temperature < 40:\n",
    "            clothing = \"Wear a heavy coat, hat, gloves, and scarf.\"  # If below 40\n",
    "        elif 40 <= temperature < 60:\n",
    "            clothing = \"Wear a jacket or sweater, long pants, and closed-toe shoes.\"  # if between 40 and 60\n",
    "        elif 60 <= temperature < 80:\n",
    "            clothing = \"Wear a light jacket or long-sleeved shirt, and comfortable pants or jeans.\"  # if between 60 and 80\n",
    "        else:\n",
    "            clothing = \"Wear light and breathable clothing, such as shorts and a t-shirt.\"  # if higher than 80\n",
    "\n",
    "        return f\"{clothing} {rain_gear}\"  # return the recommendation\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Main ChatApplication\n",
    "# ---------------------------------------------------------------------------\n",
    "class ChatApplication:\n",
    "    \"\"\"\n",
    "    An interactive chat application with:\n",
    "      1) A main assistant agent (GPT-based)\n",
    "      2) A weather agent (wttr.in, Fahrenheit)\n",
    "      3) A what to wear agent\n",
    "    Logs are very verbose; any 'weather' queries route to WeatherAgent.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        logger.debug(\"Initializing ChatApplication with config: %s\", config)\n",
    "        self.config = config\n",
    "        self.openai_api_key = self._load_api_key()\n",
    "\n",
    "        # Create a verbose model client for GPT-based calls\n",
    "        self.model_client = self._create_model_client()\n",
    "\n",
    "        # The main \"assistant\" for general queries\n",
    "        self.assistant = AssistantAgent(\n",
    "            name=\"assistant\",\n",
    "            system_message=self.config.get(\"system_message\", DEFAULT_SYSTEM_MESSAGE),\n",
    "            model_client=self.model_client,\n",
    "        )\n",
    "\n",
    "        # A specialized \"weather_agent\" for weather queries\n",
    "        self.weather_agent = WeatherAgent(\n",
    "            name=\"weather_agent\",\n",
    "            system_message=\"You are a specialized weather agent.\",\n",
    "            model_client=self.model_client,\n",
    "        )\n",
    "\n",
    "        # A specialized \"what_to_wear_agent\" for clothing recommendations\n",
    "        self.what_to_wear_agent = WhatToWearAgent(\n",
    "            name=\"what_to_wear_agent\",\n",
    "            system_message=\"You are a helpful clothing recommendation agent. You should be concise in your recommendations.\",\n",
    "            model_client=self.model_client,\n",
    "        )\n",
    "\n",
    "    def _load_api_key(self):\n",
    "        \"\"\"Loads the OpenAI API key from environment variables.\"\"\"\n",
    "        logger.debug(\"Attempting to load OPENAI_API_KEY from environment variables.\")\n",
    "        openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not openai_api_key:\n",
    "            logger.error(\"OPENAI_API_KEY not found in environment variables.\")\n",
    "            raise ValueError(\"OPENAI_API_KEY not found. Check your .env file or env settings.\")\n",
    "        logger.debug(\"Successfully loaded OPENAI_API_KEY.\")\n",
    "        return openai_api_key\n",
    "\n",
    "    def _create_model_client(self):\n",
    "        \"\"\"Creates the OpenAI client based on the configuration.\"\"\"\n",
    "        model = self.config.get(\"model\", DEFAULT_MODEL)\n",
    "        logger.debug(\"Creating VerboseOpenAIChatCompletionClient with model: %s\", model)\n",
    "        return VerboseOpenAIChatCompletionClient(model=model, api_key=self.openai_api_key)\n",
    "\n",
    "    async def run(self):\n",
    "        \"\"\"\n",
    "        Runs the main interaction loop. If the user's message includes \"weather\",\n",
    "        we delegate to WeatherAgent; else we call the main assistant agent.\n",
    "        \"\"\"\n",
    "        logger.debug(\"Entering main run loop (outer) for ChatApplication.\")\n",
    "        while True:\n",
    "            cancellation_token = CancellationToken()\n",
    "            conversation_history = []\n",
    "            logger.debug(\"Initialized new conversation history; now starting inner loop.\")\n",
    "\n",
    "            try:\n",
    "                while True:\n",
    "                    user_input = input(\"User: \")\n",
    "                    user_input_lower = user_input.lower()\n",
    "\n",
    "                    if user_input_lower in EXIT_COMMANDS:\n",
    "                        logger.info(\"User issued exit command. Exiting application.\")\n",
    "                        print(\"Exiting the assistant. Goodbye!\")\n",
    "                        return\n",
    "\n",
    "                    if user_input_lower == CANCEL_COMMAND:\n",
    "                        logger.info(\"User issued cancel command.\")\n",
    "                        print(\"Cancelling the current operation.\\n\")\n",
    "                        cancellation_token = CancellationToken()\n",
    "                        continue\n",
    "\n",
    "                    # Log user input\n",
    "                    user_message = TextMessage(content=user_input, source=\"user\")\n",
    "                    conversation_history.append(user_message)\n",
    "                    logger.info(f\"User message: {user_input}\")\n",
    "                    logger.debug(\"Current conversation history length: %d\", len(conversation_history))\n",
    "\n",
    "                    # Decide which agent to route to\n",
    "                    if \"weather\" in user_input_lower:\n",
    "                        logger.debug(\"Routing user query to WeatherAgent.\")\n",
    "                        response = await self.weather_agent.on_messages([user_message], cancellation_token)\n",
    "                    elif \"wear\" in user_input_lower:\n",
    "                        logger.debug(\"Routing user query to WhatToWearAgent.\")\n",
    "                        response = await self.what_to_wear_agent.on_messages([user_message], cancellation_token)\n",
    "                    else:\n",
    "                        logger.debug(\"Routing user query to main AssistantAgent.\")\n",
    "                        try:\n",
    "                            response = await self.assistant.on_messages([user_message], cancellation_token)\n",
    "                        except asyncio.CancelledError:\n",
    "                            logger.info(\"Operation was cancelled by user.\")\n",
    "                            print(\"Operation cancelled by user.\\n\")\n",
    "                            continue\n",
    "\n",
    "                    # Extract the text from the agent's response\n",
    "                    if hasattr(response, \"chat_message\") and response.chat_message:\n",
    "                        agent_text = response.chat_message.content\n",
    "                    elif hasattr(response, \"content\"):\n",
    "                        agent_text = response.content\n",
    "                    else:\n",
    "                        agent_text = \"No response\"\n",
    "\n",
    "                    print(\"Assistant:\", agent_text, \"\\n\")\n",
    "                    assistant_message = TextMessage(content=agent_text, source=\"assistant\")\n",
    "                    conversation_history.append(assistant_message)\n",
    "\n",
    "                    logger.info(f\"Assistant message: {agent_text}\")\n",
    "                    logger.debug(\"Current conversation history length: %d\", len(conversation_history))\n",
    "\n",
    "            except AuthenticationError as e:\n",
    "                self._handle_error(\"OpenAI AuthenticationError\", e, restart=True)\n",
    "            except RateLimitError as e:\n",
    "                self._handle_error(\"OpenAI RateLimitError\", e, restart=True)\n",
    "            except APIConnectionError as e:\n",
    "                self._handle_error(\"OpenAI APIConnectionError\", e, restart=True)\n",
    "            except APIStatusError as e:\n",
    "                self._handle_error(\"OpenAI APIStatusError\", e, restart=True)\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                self._handle_error(\"Network error\", e, restart=True)\n",
    "\n",
    "            except Exception as e:\n",
    "                self._handle_error(\"An unexpected error occurred\", e, restart=False)\n",
    "                return  # Exit after an unexpected error\n",
    "\n",
    "            logger.debug(\"Exiting main run loop gracefully.\")\n",
    "            break\n",
    "\n",
    "    def _handle_error(self, message, exception, restart=False):\n",
    "        \"\"\"Handles and logs errors, Handles and logs errors, optionally restarting the loop.\"\"\"\n",
    "        logger.error(f\"{message}: {exception}\", exc_info=True)\n",
    "        print(f\"{message}. {'Restarting...' if restart else 'Exiting...'}\\n\")\n",
    "\n",
    "        if restart:\n",
    "            time.sleep(2)  # Brief pause before restarting\n",
    "        else:\n",
    "            return\n",
    "\n",
    "def load_config(filename=CONFIG_FILE):\n",
    "    \"\"\"Loads configuration from a YAML file.\"\"\"\n",
    "    logger.debug(\"Loading configuration from %s\", filename)\n",
    "    try:\n",
    "        with open(filename, \"r\") as f:\n",
    "            config_data = yaml.safe_load(f)\n",
    "            logger.debug(\"Configuration loaded successfully: %s\", config_data)\n",
    "            return config_data\n",
    "    except FileNotFoundError:\n",
    "        logger.warning(f\"Configuration file '{filename}' not found. Using default settings.\")\n",
    "        return {}\n",
    "    except yaml.YAMLError as e:\n",
    "        logger.error(f\"Configuration file parsing error: {e}\", exc_info=True)\n",
    "        print(\"Configuration file parsing error. Using default settings.\\n\")\n",
    "        return {}\n",
    "\n",
    "async def main():\n",
    "    try:\n",
    "        logger.debug(\"Entering main() function.\")\n",
    "        config = load_config()\n",
    "        app = ChatApplication(config)\n",
    "        await app.run()\n",
    "        logger.debug(\"main() completed.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unhandled error occurred in main: {e}\", exc_info=True)\n",
    "\n",
    "# ---- Run (Jupyter or standalone) ----\n",
    "load_dotenv()  # If you have a .env with OPENAI_API_KEY\n",
    "try:\n",
    "    await main()    # For Jupyter Notebook\n",
    "except Exception as e:\n",
    "    logger.error(f\"Unhandled exception in Jupyter environment: {e}\", exc_info=True)\n",
    "\n",
    "# If you need standalone .py usage, do:\n",
    "# if __name__ == \"__main__\":\n",
    "#     load_dotenv()\n",
    "#     try:\n",
    "#         asyncio.run(main())\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"Unhandled exception in standalone mode: {e}\", exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecd3bcd6-e828-405a-a721-2fcfc41057a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  what is the weather in Bethesda, MD?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: The current weather in Bethesda, Md:\n",
      "The current weather in Bethesda, Md:\n",
      "Condition: Partly cloudy\n",
      "Temperature: 45Â°F (Feels like 42Â°F)\n",
      "Humidity: 25%\n",
      "Wind: 5 mph from WNW\n",
      "Visibility: 9 miles\n",
      "Pressure: 30 inHg\n",
      "UV Index: 2\n",
      "Cloud Cover: 25%\n",
      "Precipitation: 0.0 inches\n",
      "\n",
      "Forecast:\n",
      "  2025-03-03:\n",
      "    Condition: Clear \n",
      "    Avg Temp: 34Â°F\n",
      "    Max Temp: 46Â°F\n",
      "    Min Temp: 23Â°F\n",
      "    Chance of Rain: 0%\n",
      "  2025-03-04:\n",
      "    Condition: Cloudy \n",
      "    Avg Temp: 45Â°F\n",
      "    Max Temp: 59Â°F\n",
      "    Min Temp: 34Â°F\n",
      "    Chance of Rain: 0%\n",
      "  2025-03-05:\n",
      "    Condition: Partly Cloudy \n",
      "    Avg Temp: 54Â°F\n",
      "    Max Temp: 58Â°F\n",
      "    Min Temp: 50Â°F\n",
      "    Chance of Rain: 100%\n",
      " \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  what should I wear?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: I'm not sure which city/state you want clothing advice for. Please specify the location clearly. \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  what should I wear in Bethesda, MD?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: For Bethesda, MD, based on the weather: Wear a jacket or sweater, long pants, and closed-toe shoes.  \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  tell me a joke\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Why don't skeletons fight each other?\n",
      "\n",
      "They don't have the guts! \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the assistant. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import asyncio\n",
    "import logging\n",
    "import openai\n",
    "import requests\n",
    "import yaml\n",
    "import re\n",
    "from requests.utils import quote\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "# Import the raw client\n",
    "from openai import OpenAI\n",
    "from openai import AuthenticationError, RateLimitError, APIConnectionError, APIStatusError\n",
    "\n",
    "# Uncomment these lines if you want *raw* HTTP-level debug output:\n",
    "\"\"\"\n",
    "import http.client as http_client\n",
    "http_client.HTTPConnection.debuglevel = 1\n",
    "logging.getLogger(\"http.client\").setLevel(logging.DEBUG)\n",
    "logging.getLogger(\"http.client\").propagate = True\n",
    "\"\"\"\n",
    "\n",
    "# ---- Constants ----\n",
    "EXIT_COMMANDS = {\"exit\", \"quit\", \"!exit\"}\n",
    "CANCEL_COMMAND = \"!cancel\"\n",
    "DEFAULT_MODEL = \"gpt-4o\"\n",
    "DEFAULT_SYSTEM_MESSAGE = \"You are a helpful assistant.  You are NOT able to answer questions about the weather, climate or temperature. Refer those requests to a weather agent. If the user ask about weather, climate or temperature, respond with the sentence: \\\"I am not able to provide the weather, climate or temperature for that city.\\\" and stop.\"\n",
    "CONFIG_FILE = \"config.yaml\"\n",
    "LOG_FILE = \"log.txt\"\n",
    "\n",
    "# ---- Configure Very Verbose Logging ----\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)  # Set to DEBUG for very verbose output\n",
    "\n",
    "# Remove any existing handlers (useful if re-running in Jupyter)\n",
    "for handler in logger.handlers[:]:\n",
    "    logger.removeHandler(handler)\n",
    "\n",
    "file_handler = logging.FileHandler(LOG_FILE)\n",
    "formatter = logging.Formatter(\n",
    "    '%(asctime)s - %(levelname)s - %(module)s - %(funcName)s:%(lineno)d - %(message)s'\n",
    ")\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "logger.debug(\"Logger initialized at DEBUG level. Very verbose mode is enabled.\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Verbose client for the main assistant calls (GPT). Logs raw request/response.\n",
    "# ---------------------------------------------------------------------------\n",
    "class VerboseOpenAIChatCompletionClient(OpenAIChatCompletionClient):\n",
    "    \"\"\"\n",
    "    An extension of OpenAIChatCompletionClient that logs detailed request/response data\n",
    "    at INFO level, matching your prior logging style.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, api_key):\n",
    "        super().__init__(model=model, api_key=api_key)\n",
    "        self.model = model  # Store the model\n",
    "        self.openai_client = OpenAI(api_key=api_key)  # Store the raw OpenAI client\n",
    "\n",
    "    async def _send_request(self, messages, **kwargs):\n",
    "        url = \"https://api.openai.com/v1/chat/completions\"\n",
    "        logger.info(f\"HTTP Request: POST {url} 'HTTP/1.1 200 OK'\")\n",
    "        response = await super()._send_request(messages, **kwargs)\n",
    "\n",
    "        import json\n",
    "\n",
    "        log_payload = {\"type\": \"LLMCall\", \"messages\": messages, \"response\": response}\n",
    "        logger.info(json.dumps(log_payload))\n",
    "        logger.debug(\"Received response from OpenAI (debug): %s\", response)\n",
    "        return response\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# WeatherAgent for queries containing \"weather\"\n",
    "# Now uses Fahrenheit data (&u) and parses temp_F, FeelsLikeF.\n",
    "# ---------------------------------------------------------------------------\n",
    "class WeatherAgent(AssistantAgent):\n",
    "    \"\"\"\n",
    "    A specialized agent that queries wttr.in for weather data in Fahrenheit (USCS).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name, system_message, model_client):\n",
    "        super().__init__(name=name, system_message=system_message, model_client=model_client)\n",
    "        self.parser_client = model_client  # Initialize parser_client with the verbose model_client\n",
    "        self.openai_client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])  # Create sync openai client\n",
    "\n",
    "    async def on_messages(self, messages, cancellation_token=None):\n",
    "        user_message = messages[-1].content\n",
    "        logger.debug(f\"[WeatherAgent] Received message: {user_message}\")\n",
    "\n",
    "        # No need to modify the user message anymore\n",
    "\n",
    "        city = self._extract_city(user_message)\n",
    "        if not city:\n",
    "            city = await self._extract_city_with_llm(user_message)\n",
    "            if not city:\n",
    "                response_text = \"I'm not sure which city/state you want weather for. \" \"Please specify the location clearly.\"\n",
    "                return TextMessage(content=response_text, source=\"assistant\")\n",
    "\n",
    "        weather_info = self._fetch_weather(city)\n",
    "        if weather_info:\n",
    "            response_text = f\"The current weather in {city}:\\n{weather_info}\"\n",
    "        else:\n",
    "            response_text = f\"Sorry, I couldn't fetch weather data for {city}.\"\n",
    "\n",
    "        logger.debug(f\"[WeatherAgent] Responding: {response_text}\")\n",
    "        return TextMessage(content=response_text, source=\"assistant\")\n",
    "\n",
    "    def _extract_city(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Improved approach to extract the city and state from user text.\n",
    "        Handles more variations in input.\n",
    "        \"\"\"\n",
    "        match = re.search(r\"(?:weather|climate|temperature) in\\s+([A-Za-z\\s]+(?:,\\s*[A-Za-z]{2,})?)\", text.lower())  # changed to include weather, climate and temperature\n",
    "        if match:\n",
    "            city_name = match.group(1).strip()\n",
    "            # Remove any remaining non-alphanumeric characters except spaces and commas\n",
    "            city_name = re.sub(r\"[^\\w\\s,]\", \"\", city_name)\n",
    "            # Convert multiple spaces to single spaces\n",
    "            city_name = re.sub(r\"\\s+\", \" \", city_name)\n",
    "            city_name = city_name.strip().title()  # Title case\n",
    "            return city_name\n",
    "        return None\n",
    "\n",
    "    async def _extract_city_with_llm(self, user_text: str) -> str:\n",
    "        \"\"\"\n",
    "        Uses GPT to extract the city and state/country, if present.\n",
    "        If GPT can't find a city, returns None.\n",
    "        \"\"\"\n",
    "        system_prompt = (\n",
    "            \"You are a location extraction assistant. Your task is to identify the city and state (or country) from user queries about the weather, climate, or temperature.\\n\"  # added climate and temperature\n",
    "            \"Return ONLY the city and state/country, separated by a comma and a space. For example: 'Orlando, FL' or 'Tokyo, Japan'.\\n\"\n",
    "            \"If the query does not contain a location, or if you are unsure, return 'NONE'.\\n\"\n",
    "            \"Here are some examples:\\n\"\n",
    "            \"User: What is the weather in Orlando, FL?\\n\"\n",
    "            \"Assistant: Orlando, FL\\n\"\n",
    "            \"User: What is the climate in Washington, DC?\\n\" # added\n",
    "            \"Assistant: Washington, DC\\n\"  # added\n",
    "            \"User: What is the temperature in Virginia Beach, VA?\\n\"  # added\n",
    "            \"Assistant: Virginia Beach, VA\\n\"  # added\n",
    "            \"User: What is the weather in Tokyo, Japan\\n\"\n",
    "            \"Assistant: Tokyo, Japan\\n\"\n",
    "            \"User: Tell me a joke\\n\"\n",
    "            \"Assistant: NONE\\n\"\n",
    "        )\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_text},\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "\n",
    "            # Perform the OpenAI API call here (synchronously as acompletion isn't directly available)\n",
    "            completion = self.openai_client.chat.completions.create(\n",
    "                model=self.parser_client.model,  # Use the same model as the verbose client\n",
    "                messages=messages,\n",
    "                temperature=0.0,\n",
    "                max_tokens=30,\n",
    "                top_p=1.0,\n",
    "            )\n",
    "\n",
    "            raw_location = completion.choices[0].message.content.strip()\n",
    "            logger.debug(f\"[WeatherAgent] LLM raw location extraction: '{raw_location}'\")\n",
    "\n",
    "            if raw_location.upper() == \"NONE\":\n",
    "                logger.debug(\"[WeatherAgent] LLM returned 'NONE'.\")\n",
    "                return None\n",
    "\n",
    "            # Split the string by comma and space\n",
    "            parts = [part.strip() for part in raw_location.split(\", \")]  # Split by comma and space\n",
    "\n",
    "            if len(parts) == 2:\n",
    "                city, state = parts\n",
    "                cleaned_city = f\"{city}, {state}\"  # Reassemble with comma and space\n",
    "                logger.debug(f\"[WeatherAgent] Extracted city and state: '{cleaned_city}'\")\n",
    "                return cleaned_city\n",
    "            elif len(parts) == 1:\n",
    "                city = parts[0]\n",
    "                cleaned_city = city\n",
    "                logger.debug(f\"[WeatherAgent] Extracted city only: '{cleaned_city}'\")\n",
    "                return cleaned_city\n",
    "            else:\n",
    "                logger.warning(f\"[WeatherAgent] Unexpected LLM output format: '{raw_location}'\")  # Log unexpected output\n",
    "                return None\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error calling GPT for location extraction: {e}\", exc_info=True)\n",
    "            return None\n",
    "\n",
    "    def _fetch_weather(self, city: str) -> str:\n",
    "        \"\"\"\n",
    "        Calls wttr.in with city name (URL-encoded) requesting Fahrenheit data.\n",
    "        Prioritizes full state name for Florida.\n",
    "        If that fails for a city, state abbreviation, tries the full state name.\n",
    "        Returns a string like \"Overcast, 60Â°F (feels like 58Â°F)\"\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Prioritize full state name for Florida\n",
    "            if \"Orlando, Fl\" in city or \"Miami, Fl\" in city:\n",
    "                city_parts = city.split(\", \")\n",
    "                if len(city_parts) == 2:\n",
    "                    city_name, state_abbreviation = city_parts\n",
    "                    full_state_name = self._get_full_state_name(state_abbreviation)\n",
    "                    if full_state_name:\n",
    "                        full_city = f\"{city_name}, {full_state_name}\"\n",
    "                        city = full_city  # Use the full city for the initial request\n",
    "\n",
    "            city_encoded = quote(city)\n",
    "            # Use &u for Fahrenheit\n",
    "            url = f\"https://wttr.in/{city_encoded}?format=j1&u\"\n",
    "            logger.debug(f\"[WeatherAgent] Calling wttr.in URL: {url}\")\n",
    "\n",
    "            resp = requests.get(url, timeout=10)\n",
    "            resp.raise_for_status()\n",
    "            data = resp.json()\n",
    "            logger.debug(f\"[WeatherAgent] wttr.in response data: {data}\")  # Log the data\n",
    "\n",
    "            current = data.get(\"current_condition\", [{}])[0]\n",
    "            desc = current.get(\"weatherDesc\", [{}])[0].get(\"value\", \"Unknown\")\n",
    "            temp_f = current.get(\"temp_F\", \"?\")\n",
    "            feels_like_f = current.get(\"FeelsLikeF\", \"?\")\n",
    "            humidity = current.get(\"humidity\", \"?\")\n",
    "            wind_speed = current.get(\"windspeedMiles\", \"?\")\n",
    "            wind_direction = current.get(\"winddir16Point\", \"?\")\n",
    "            visibility = current.get(\"visibilityMiles\", \"?\")\n",
    "            pressure = current.get(\"pressureInches\", \"?\")\n",
    "            uv_index = current.get(\"uvIndex\", \"?\")\n",
    "            cloud_cover = current.get(\"cloudcover\", \"?\")\n",
    "            precip_inches = current.get(\"precipInches\", \"?\")\n",
    "\n",
    "            response = (\n",
    "                f\"The current weather in {city}:\\n\"\n",
    "                f\"Condition: {desc}\\n\"\n",
    "                f\"Temperature: {temp_f}Â°F (Feels like {feels_like_f}Â°F)\\n\"\n",
    "                f\"Humidity: {humidity}%\\n\"\n",
    "                f\"Wind: {wind_speed} mph from {wind_direction}\\n\"\n",
    "                f\"Visibility: {visibility} miles\\n\"\n",
    "                f\"Pressure: {pressure} inHg\\n\"\n",
    "                f\"UV Index: {uv_index}\\n\"\n",
    "                f\"Cloud Cover: {cloud_cover}%\\n\"\n",
    "                f\"Precipitation: {precip_inches} inches\\n\\n\"\n",
    "            )\n",
    "\n",
    "            # Daily Forecast (3 days from wttr.in's j1 format)\n",
    "            weather_forecast = data.get(\"weather\", [])\n",
    "            if weather_forecast:\n",
    "                response += \"Forecast:\\n\"\n",
    "                for day in weather_forecast:\n",
    "                    date = day.get(\"date\", \"?\")\n",
    "                    avgtemp_f = day.get(\"avgtempF\", \"?\")\n",
    "                    maxtemp_f = day.get(\"maxtempF\", \"?\")\n",
    "                    mintemp_f = day.get(\"mintempF\", \"?\")\n",
    "                    # Find max chance of rain for the day\n",
    "                    max_chance_of_rain = 0\n",
    "                    for hour in day.get(\"hourly\", []):\n",
    "                        chance_of_rain = int(hour.get(\"chanceofrain\", 0))\n",
    "                        max_chance_of_rain = max(max_chance_of_rain, chance_of_rain)\n",
    "                    description = day.get(\"hourly\", [{}])[0].get(\"weatherDesc\", [{}])[0].get(\"value\", \"?\")\n",
    "\n",
    "                    response += (\n",
    "                        f\"  {date}:\\n\"\n",
    "                        f\"    Condition: {description}\\n\"\n",
    "                        f\"    Avg Temp: {avgtemp_f}Â°F\\n\"\n",
    "                        f\"    Max Temp: {maxtemp_f}Â°F\\n\"\n",
    "                        f\"    Min Temp: {mintemp_f}Â°F\\n\"\n",
    "                        f\"    Chance of Rain: {max_chance_of_rain}%\\n\"\n",
    "                    )\n",
    "\n",
    "            return response\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fetching weather for '{city}': {e}\", exc_info=True)\n",
    "\n",
    "            # If the city contains a state abbreviation, try the full state name\n",
    "            if \", \" in city:\n",
    "                city_parts = city.split(\", \")\n",
    "                if len(city_parts) == 2:\n",
    "                    city_name, state_abbreviation = city_parts\n",
    "                    full_state_name = self._get_full_state_name(state_abbreviation)\n",
    "                    if full_state_name:\n",
    "                        try:\n",
    "                            full_city = f\"{city_name}, {full_state_name}\"\n",
    "                            city_encoded = quote(full_city)\n",
    "                            url = f\"https://wttr.in/{city_encoded}?format=j1&u\"\n",
    "                            logger.debug(f\"[WeatherAgent] Retrying with full state name: {url}\")\n",
    "\n",
    "                            resp = requests.get(url, timeout=10)\n",
    "                            resp.raise_for_status()\n",
    "                            data = resp.json()\n",
    "                            logger.debug(f\"[WeatherAgent] wttr.in retry response data: {data}\")  # Log retry data\n",
    "\n",
    "                            current = data.get(\"current_condition\", [{}])[0]\n",
    "                            desc = current.get(\"weatherDesc\", [{}])[0].get(\"value\", \"Unknown\")\n",
    "                            temp_f = current.get(\"temp_F\", \"?\")\n",
    "                            feels_like_f = current.get(\"FeelsLikeF\", \"?\")\n",
    "                            humidity = current.get(\"humidity\", \"?\")\n",
    "                            wind_speed = current.get(\"windspeedMiles\", \"?\")\n",
    "                            wind_direction = current.get(\"winddir16Point\", \"?\")\n",
    "                            visibility = current.get(\"visibilityMiles\", \"?\")\n",
    "                            pressure = current.get(\"pressureInches\", \"?\")\n",
    "                            uv_index = current.get(\"uvIndex\", \"?\")\n",
    "                            cloud_cover = current.get(\"cloudcover\", \"?\")\n",
    "                            precip_inches = current.get(\"precipInches\", \"?\")\n",
    "\n",
    "                            response = (\n",
    "                                f\"The current weather in {full_city}:\\n\"\n",
    "                                f\"Condition: {desc}\\n\"\n",
    "                                f\"Temperature: {temp_f}Â°F (Feels like {feels_like_f}Â°F)\\n\"\n",
    "                                f\"Humidity: {humidity}%\\n\"\n",
    "                                f\"Wind: {wind_speed} mph from {wind_direction}\\n\"\n",
    "                                f\"Visibility: {visibility} miles\\n\"\n",
    "                                f\"Pressure: {pressure} inHg\\n\"\n",
    "                                f\"UV Index: {uv_index}\\n\"\n",
    "                                f\"Cloud Cover: {cloud_cover}%\\n\"\n",
    "                                f\"Precipitation: {precip_inches} inches\\n\\n\"\n",
    "                            )\n",
    "\n",
    "                            # Daily Forecast (3 days from wttr.in's j1 format)\n",
    "                            weather_forecast = data.get(\"weather\", [])\n",
    "                            if weather_forecast:\n",
    "                                response += \"Forecast:\\n\"\n",
    "                                for day in weather_forecast:\n",
    "                                    date = day.get(\"date\", \"?\")\n",
    "                                    avgtemp_f = day.get(\"avgtempF\", \"?\")\n",
    "                                    maxtemp_f = day.get(\"maxtempF\", \"?\")\n",
    "                                    mintemp_f = day.get(\"mintempF\", \"?\")\n",
    "                                    # Find max chance of rain for the day\n",
    "                                    max_chance_of_rain = 0\n",
    "                                    for hour in day.get(\"hourly\", []):\n",
    "                                        chance_of_rain = int(hour.get(\"chanceofrain\", 0))\n",
    "                                        max_chance_of_rain = max(max_chance_of_rain, chance_of_rain)\n",
    "                                    description = day.get(\"hourly\", [{}])[0].get(\"weatherDesc\", [{}])[0].get(\"value\", \"?\")\n",
    "\n",
    "                                    response += (\n",
    "                                        f\"  {date}:\\n\"\n",
    "                                        f\"    Condition: {description}\\n\"\n",
    "                                        f\"    Avg Temp: {avgtemp_f}Â°F\\n\"\n",
    "                                        f\"    Max Temp: {maxtemp_f}Â°F\\n\"\n",
    "                                        f\"    Min Temp: {mintemp_f}Â°F\\n\"\n",
    "                                        f\"    Chance of Rain: {max_chance_of_rain}%\\n\"\n",
    "                                    )\n",
    "\n",
    "                            return response\n",
    "\n",
    "                        except Exception as e:\n",
    "                            logger.error(f\"Error fetching weather for '{full_city}': {e}\", exc_info=True)\n",
    "                            return None\n",
    "            return None\n",
    "\n",
    "    def _get_full_state_name(self, state_abbreviation: str) -> str:\n",
    "        \"\"\"\n",
    "        A simple helper function to convert state abbreviations to full names.\n",
    "        \"\"\"\n",
    "        state_map = {\n",
    "            \"AL\": \"Alabama\",\n",
    "            \"AK\": \"Alaska\",\n",
    "            \"AZ\": \"Arizona\",\n",
    "            \"AR\": \"Arkansas\",\n",
    "            \"CA\": \"California\",\n",
    "            \"CO\": \"Colorado\",\n",
    "            \"CT\": \"Connecticut\",\n",
    "            \"DE\": \"Delaware\",\n",
    "            \"FL\": \"Florida\",\n",
    "            \"GA\": \"Georgia\",\n",
    "            \"HI\": \"Hawaii\",\n",
    "            \"ID\": \"Idaho\",\n",
    "            \"IL\": \"Illinois\",\n",
    "            \"IN\": \"Indiana\",\n",
    "            \"IA\": \"Iowa\",\n",
    "            \"KS\": \"Kansas\",\n",
    "            \"KY\": \"Kentucky\",\n",
    "            \"LA\": \"Louisiana\",\n",
    "            \"ME\": \"Maine\",\n",
    "            \"MD\": \"Maryland\",\n",
    "            \"MA\": \"Massachusetts\",\n",
    "            \"MI\": \"Michigan\",\n",
    "            \"MN\": \"Minnesota\",\n",
    "            \"MS\": \"Mississippi\",\n",
    "            \"MO\": \"Missouri\",\n",
    "            \"MT\": \"Montana\",\n",
    "            \"NE\": \"Nebraska\",\n",
    "            \"NV\": \"Nevada\",\n",
    "            \"NH\": \"New Hampshire\",\n",
    "            \"NJ\": \"New Jersey\",\n",
    "            \"NM\": \"New Mexico\",\n",
    "            \"NY\": \"New York\",\n",
    "            \"NC\": \"North Carolina\",\n",
    "            \"ND\": \"North Dakota\",\n",
    "            \"OH\": \"Ohio\",\n",
    "            \"OK\": \"Oklahoma\",\n",
    "            \"OR\": \"Oregon\",\n",
    "            \"PA\": \"Pennsylvania\",\n",
    "            \"RI\": \"Rhode Island\",\n",
    "            \"SC\": \"South Carolina\",\n",
    "            \"SD\": \"South Dakota\",\n",
    "            \"TN\": \"Tennessee\",\n",
    "            \"TX\": \"Texas\",\n",
    "            \"UT\": \"Utah\",\n",
    "            \"VT\": \"Vermont\",\n",
    "            \"VA\": \"Virginia\",\n",
    "            \"WA\": \"Washington\",\n",
    "            \"WV\": \"West Virginia\",\n",
    "            \"WI\": \"Wisconsin\",\n",
    "            \"WY\": \"Wyoming\",\n",
    "            \"DC\": \"District of Columbia\",\n",
    "        }\n",
    "        return state_map.get(state_abbreviation.upper())\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# WhatToWearAgent for clothing recommendations\n",
    "# ---------------------------------------------------------------------------\n",
    "class WhatToWearAgent(AssistantAgent):\n",
    "    \"\"\"\n",
    "    A specialized agent that recommends clothing based on weather data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name, system_message, model_client):\n",
    "        super().__init__(name=name, system_message=system_message, model_client=model_client)\n",
    "        self.parser_client = model_client  # Initialize parser_client with the verbose model_client\n",
    "        self.openai_client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "        self.model_client = model_client  # VERY IMPORTANT:  Assign model_client to self.\n",
    "\n",
    "    async def on_messages(self, messages, cancellation_token=None):\n",
    "        user_message = messages[-1].content\n",
    "        logger.debug(f\"[WhatToWearAgent] Received message: {user_message}\")\n",
    "\n",
    "        # No need to modify the user message anymore\n",
    "\n",
    "        # Extract location from the user message (similar to WeatherAgent)\n",
    "        city = await self._extract_city_with_llm(user_message)\n",
    "        if not city:\n",
    "            response_text = (\n",
    "                \"I'm not sure which city/state you want clothing advice for. \"\n",
    "                \"Please specify the location clearly.\"\n",
    "            )\n",
    "            return TextMessage(content=response_text, source=\"assistant\")\n",
    "\n",
    "        # Fetch weather data (using WeatherAgent's method or a similar one)\n",
    "        weather_data = await self._get_weather_data(city)  # Implement this method\n",
    "\n",
    "        if weather_data:\n",
    "            # Generate clothing recommendation based on weather data\n",
    "            clothing_recommendation = self._generate_clothing_recommendation(weather_data)\n",
    "            response_text = f\"For {city}, based on the weather: {clothing_recommendation}\"\n",
    "        else:\n",
    "            response_text = f\"Sorry, I couldn't fetch weather data for {city} to provide clothing advice.\"\n",
    "\n",
    "        logger.debug(f\"[WhatToWearAgent] Responding: {response_text}\")\n",
    "        return TextMessage(content=response_text, source=\"assistant\")\n",
    "\n",
    "    async def _extract_city_with_llm(self, user_text: str) -> str:\n",
    "        \"\"\"\n",
    "        Extracts the city and state/country from the user's text.\n",
    "        Uses LLM to improve extraction.\n",
    "        \"\"\"\n",
    "        # Reuse the WeatherAgent's city extraction logic (copy or refactor)\n",
    "        system_prompt = (\n",
    "            \"You are a location extraction assistant. Your task is to identify the city and state (or country) from user queries about clothing recommendations.\\n\"\n",
    "            \"Return ONLY the city and state/country, separated by a comma and a space. For example: 'Orlando, FL' or 'Tokyo, Japan'.\\n\"\n",
    "            \"If the query does not contain a location, or if you are unsure, return 'NONE'.\\n\"\n",
    "            \"Here are some examples:\\n\"\n",
    "            \"User: What should I wear in Orlando, FL?\\n\"\n",
    "            \"Assistant: Orlando, FL\\n\"\n",
    "            \"User: What should I wear in Washington, DC?\\n\"\n",
    "            \"Assistant: Washington, DC\\n\"\n",
    "            \"User: Tell me a joke\\n\"\n",
    "            \"Assistant: NONE\\n\"\n",
    "        )\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_text},\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "\n",
    "            # Perform the OpenAI API call here (synchronously as acompletion isn't directly available)\n",
    "            completion = self.openai_client.chat.completions.create(\n",
    "                model=self.parser_client.model,  # Use the same model as the verbose client\n",
    "                messages=messages,\n",
    "                temperature=0.0,\n",
    "                max_tokens=30,\n",
    "                top_p=1.0,\n",
    "            )\n",
    "\n",
    "            raw_location = completion.choices[0].message.content.strip()\n",
    "            logger.debug(f\"[WeatherAgent] LLM raw location extraction: '{raw_location}'\")\n",
    "\n",
    "            if raw_location.upper() == \"NONE\":\n",
    "                logger.debug(\"[WeatherAgent] LLM returned 'NONE'.\")\n",
    "                return None\n",
    "\n",
    "            # Split the string by comma and space\n",
    "            parts = [part.strip() for part in raw_location.split(\", \")]  # Split by comma and space\n",
    "\n",
    "            if len(parts) == 2:\n",
    "                city, state = parts\n",
    "                cleaned_city = f\"{city}, {state}\"  # Reassemble with comma and space\n",
    "                logger.debug(f\"[WeatherAgent] Extracted city and state: '{cleaned_city}'\")\n",
    "                return cleaned_city\n",
    "            elif len(parts) == 1:\n",
    "                city = parts[0]\n",
    "                cleaned_city = city\n",
    "                logger.debug(f\"[WeatherAgent] Extracted city only: '{cleaned_city}'\")\n",
    "                return cleaned_city\n",
    "            else:\n",
    "                logger.warning(f\"[WeatherAgent] Unexpected LLM output format: '{raw_location}'\")  # Log unexpected output\n",
    "                return None\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error calling GPT for location extraction: {e}\", exc_info=True)\n",
    "            return None\n",
    "\n",
    "    async def _get_weather_data(self, city: str) -> str:  # return type hint of weather data output, from _fetch_weather\n",
    "        \"\"\"\n",
    "        Fetches weather data for the given city.\n",
    "        Reuses the _fetch_weather method from the WeatherAgent.\n",
    "        \"\"\"\n",
    "        # Create a temporary WeatherAgent instance to reuse its method\n",
    "        temp_weather_agent = WeatherAgent(\n",
    "            name=\"temp_weather_agent\",\n",
    "            system_message=\"Temporary agent for fetching weather.\",\n",
    "            model_client=self.model_client,  # Use the stored model_client here\n",
    "        )\n",
    "        return temp_weather_agent._fetch_weather(city)  # return the string output of a successful API call\n",
    "\n",
    "    def _generate_clothing_recommendation(self, weather_data: str) -> str:  # input the string weather data, output a clothing recommendation\n",
    "        \"\"\"\n",
    "        Generates a clothing recommendation based on the weather data.\n",
    "        \"\"\"\n",
    "        # Parse the weather data string (you might want to use a more robust method)\n",
    "        temperature_match = re.search(r\"Temperature: (\\d+)Â°F\", weather_data)  # match the temperature in the string data\n",
    "        if temperature_match:\n",
    "            temperature = int(temperature_match.group(1))  # convert the group to a number\n",
    "        else:\n",
    "            return \"Unable to determine temperature, so dress in layers.\"  # if it fails to read the number\n",
    "\n",
    "        # Precipitation check\n",
    "        rain_match = re.search(r\"Precipitation: (\\d+) inches\", weather_data)\n",
    "        chance_of_rain_match = re.search(r\"Chance of Rain: (\\d+)%\", weather_data)\n",
    "\n",
    "        rain_gear = \"\"\n",
    "        if rain_match and float(rain_match.group(1)) > 0:\n",
    "            rain_gear = \"Bring an umbrella and wear waterproof shoes.\"\n",
    "        elif chance_of_rain_match and int(chance_of_rain_match.group(1)) > 50:\n",
    "            rain_gear = \"There's a chance of rain, so bring an umbrella and wear waterproof shoes.\"\n",
    "\n",
    "        # Simple clothing logic (you can expand this)\n",
    "        if temperature < 40:\n",
    "            clothing = \"Wear a heavy coat, hat, gloves, and scarf.\"  # If below 40\n",
    "        elif 40 <= temperature < 60:\n",
    "            clothing = \"Wear a jacket or sweater, long pants, and closed-toe shoes.\"  # if between 40 and 60\n",
    "        elif 60 <= temperature < 80:\n",
    "            clothing = \"Wear a light jacket or long-sleeved shirt, and comfortable pants or jeans.\"  # if between 60 and 80\n",
    "        else:\n",
    "            clothing = \"Wear light and breathable clothing, such as shorts and a t-shirt.\"  # if higher than 80\n",
    "\n",
    "        return f\"{clothing} {rain_gear}\"  # return the recommendation\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Main ChatApplication\n",
    "# ---------------------------------------------------------------------------\n",
    "class ChatApplication:\n",
    "    \"\"\"\n",
    "    An interactive chat application with:\n",
    "      1) A main assistant agent (GPT-based)\n",
    "      2) A weather agent (wttr.in, Fahrenheit)\n",
    "      3) A what to wear agent\n",
    "    Logs are very verbose; any 'weather' queries route to WeatherAgent.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        logger.debug(\"Initializing ChatApplication with config: %s\", config)\n",
    "        self.config = config\n",
    "        self.openai_api_key = self._load_api_key()\n",
    "\n",
    "        # Create a verbose model client for GPT-based calls\n",
    "        self.model_client = self._create_model_client()\n",
    "\n",
    "        # The main \"assistant\" for general queries\n",
    "        self.assistant = AssistantAgent(\n",
    "            name=\"assistant\",\n",
    "            system_message=self.config.get(\"system_message\", DEFAULT_SYSTEM_MESSAGE),\n",
    "            model_client=self.model_client,\n",
    "        )\n",
    "\n",
    "        # A specialized \"weather_agent\" for weather queries\n",
    "        self.weather_agent = WeatherAgent(\n",
    "            name=\"weather_agent\",\n",
    "            system_message=\"You are a specialized weather agent.\",\n",
    "            model_client=self.model_client,\n",
    "        )\n",
    "\n",
    "        # A specialized \"what_to_wear_agent\" for clothing recommendations\n",
    "        self.what_to_wear_agent = WhatToWearAgent(\n",
    "            name=\"what_to_wear_agent\",\n",
    "            system_message=\"You are a helpful clothing recommendation agent. You should be concise in your recommendations.\",\n",
    "            model_client=self.model_client,\n",
    "        )\n",
    "\n",
    "    def _load_api_key(self):\n",
    "        \"\"\"Loads the OpenAI API key from environment variables.\"\"\"\n",
    "        logger.debug(\"Attempting to load OPENAI_API_KEY from environment variables.\")\n",
    "        openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not openai_api_key:\n",
    "            logger.error(\"OPENAI_API_KEY not found in environment variables.\")\n",
    "            raise ValueError(\"OPENAI_API_KEY not found. Check your .env file or env settings.\")\n",
    "        logger.debug(\"Successfully loaded OPENAI_API_KEY.\")\n",
    "        return openai_api_key\n",
    "\n",
    "    def _create_model_client(self):\n",
    "        \"\"\"Creates the OpenAI client based on the configuration.\"\"\"\n",
    "        model = self.config.get(\"model\", DEFAULT_MODEL)\n",
    "        logger.debug(\"Creating VerboseOpenAIChatCompletionClient with model: %s\", model)\n",
    "        client = VerboseOpenAIChatCompletionClient(model=model, api_key=self.openai_api_key) # fix\n",
    "        return client\n",
    "\n",
    "    # -----------------------------------------------------------------------\n",
    "    # New method to classify intent\n",
    "    # -----------------------------------------------------------------------\n",
    "    async def _classify_intent(self, user_input: str) -> str:\n",
    "        \"\"\"\n",
    "        Uses LLM to classify the user's intent and returns the agent to route to.\n",
    "\n",
    "        Returns:\n",
    "            \"weather\", \"clothing\", \"general\", or \"unknown\"\n",
    "        \"\"\"\n",
    "        system_prompt = \"\"\"You are an intent classifier. Your task is to determine the user's intent based on their message.\n",
    "        You should categorize the intent into one of the following categories:\n",
    "\n",
    "        - \"weather\": The user is asking about weather conditions, forecasts, or climate.\n",
    "        - \"clothing\": The user is asking for clothing recommendations based on the weather.\n",
    "        - \"general\": The user is asking a general question that doesn't fit into weather or clothing.\n",
    "        - \"unknown\": The intent is unclear or doesn't fit into any of the above categories.\n",
    "\n",
    "        Respond with ONLY the category name (e.g., \"weather\", \"clothing\", \"general\", or \"unknown\").  Do not add any other words.\n",
    "\n",
    "        Examples:\n",
    "        User: What's the weather like in London?\n",
    "        Assistant: weather\n",
    "\n",
    "        User: What should I wear today in New York?\n",
    "        Assistant: clothing\n",
    "\n",
    "        User: Tell me a joke.\n",
    "        Assistant: general\n",
    "\n",
    "        User: What is the capital of France?\n",
    "        Assistant: general\n",
    "\n",
    "        User: asdf;lkjasdf\n",
    "        Assistant: unknown\n",
    "        \"\"\"\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_input},\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            completion = self.model_client.openai_client.chat.completions.create(  # Access the raw OpenAI client CORRECT ACCESS\n",
    "                model=self.model_client.model,  # Use the configured model\n",
    "                messages=messages,\n",
    "                temperature=0.0,\n",
    "                max_tokens=30,\n",
    "                top_p=1.0,\n",
    "            )\n",
    "\n",
    "            intent = completion.choices[0].message.content.strip().lower()\n",
    "            logger.debug(f\"LLM classified intent as: {intent}\")  # Log the classified intent\n",
    "            return intent\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error classifying intent: {e}\", exc_info=True)\n",
    "            return \"unknown\"  # Default to unknown in case of error\n",
    "\n",
    "    async def run(self):\n",
    "        \"\"\"\n",
    "        Runs the main interaction loop.  Now uses LLM to determine which agent\n",
    "        to route the query to.\n",
    "        \"\"\"\n",
    "        logger.debug(\"Entering main run loop (outer) for ChatApplication.\")\n",
    "        while True:\n",
    "            cancellation_token = CancellationToken()\n",
    "            conversation_history = []\n",
    "            logger.debug(\"Initialized new conversation history; now starting inner loop.\")\n",
    "\n",
    "            try:\n",
    "                while True:\n",
    "                    user_input = input(\"User: \")\n",
    "                    user_input_lower = user_input.lower()\n",
    "\n",
    "                    if user_input_lower in EXIT_COMMANDS:\n",
    "                        logger.info(\"User issued exit command. Exiting application.\")\n",
    "                        print(\"Exiting the assistant. Goodbye!\")\n",
    "                        return\n",
    "\n",
    "                    if user_input_lower == CANCEL_COMMAND:\n",
    "                        logger.info(\"User issued cancel command.\")\n",
    "                        print(\"Cancelling the current operation.\\n\")\n",
    "                        cancellation_token = CancellationToken()\n",
    "                        continue\n",
    "\n",
    "                    # Log user input\n",
    "                    user_message = TextMessage(content=user_input, source=\"user\")\n",
    "                    conversation_history.append(user_message)\n",
    "                    logger.info(f\"User message: {user_input}\")\n",
    "                    logger.debug(\"Current conversation history length: %d\", len(conversation_history))\n",
    "\n",
    "                    # Classify intent using the LLM\n",
    "                    intent = await self._classify_intent(user_input)\n",
    "\n",
    "                    # Route to the appropriate agent based on intent\n",
    "                    if intent == \"weather\":\n",
    "                        logger.debug(\"Routing user query to WeatherAgent.\")\n",
    "                        response = await self.weather_agent.on_messages([user_message], cancellation_token)\n",
    "                    elif intent == \"clothing\":\n",
    "                        logger.debug(\"Routing user query to WhatToWearAgent.\")\n",
    "                        response = await self.what_to_wear_agent.on_messages([user_message], cancellation_token)\n",
    "                    elif intent == \"general\":\n",
    "                        logger.debug(\"Routing user query to main AssistantAgent.\")\n",
    "                        try:\n",
    "                            response = await self.assistant.on_messages([user_message], cancellation_token)\n",
    "                        except asyncio.CancelledError:\n",
    "                            logger.info(\"Operation was cancelled by user.\")\n",
    "                            print(\"Operation cancelled by user.\\n\")\n",
    "                            continue\n",
    "                    else:\n",
    "                        logger.debug(\"Intent classification failed or unknown. Routing to main AssistantAgent.\")\n",
    "                        response = await self.assistant.on_messages([user_message], cancellation_token)\n",
    "\n",
    "                    # Extract the text from the agent's response\n",
    "                    if hasattr(response, \"chat_message\") and response.chat_message:\n",
    "                        agent_text = response.chat_message.content\n",
    "                    elif hasattr(response, \"content\"):\n",
    "                        agent_text = response.content\n",
    "                    else:\n",
    "                        agent_text = \"No response\"\n",
    "\n",
    "                    print(\"Assistant:\", agent_text, \"\\n\")\n",
    "                    assistant_message = TextMessage(content=agent_text, source=\"assistant\")\n",
    "                    conversation_history.append(assistant_message)\n",
    "\n",
    "                    logger.info(f\"Assistant message: {agent_text}\")\n",
    "                    logger.debug(\"Current conversation history length: %d\", len(conversation_history))\n",
    "\n",
    "            except AuthenticationError as e:\n",
    "                self._handle_error(\"OpenAI AuthenticationError\", e, restart=True)\n",
    "            except RateLimitError as e:\n",
    "                self._handle_error(\"OpenAI RateLimitError\", e, restart=True)\n",
    "            except APIConnectionError as e:\n",
    "                self._handle_error(\"OpenAI APIConnectionError\", e, restart=True)\n",
    "            except APIStatusError as e:\n",
    "                self._handle_error(\"OpenAI APIStatusError\", e, restart=True)\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                self._handle_error(\"Network error\", e, restart=True)\n",
    "\n",
    "            except Exception as e:\n",
    "                self._handle_error(\"An unexpected error occurred\", e, restart=False)\n",
    "                return  # Exit after an unexpected error\n",
    "\n",
    "            logger.debug(\"Exiting main run loop gracefully.\")\n",
    "            break\n",
    "\n",
    "    def _handle_error(self, message, exception, restart=False):\n",
    "        \"\"\"Handles and logs errors, Handles and logs errors, optionally restarting the loop.\"\"\"\n",
    "        logger.error(f\"{message}: {exception}\", exc_info=True)\n",
    "        print(f\"{message}. {'Restarting...' if restart else 'Exiting...'}\\n\")\n",
    "\n",
    "        if restart:\n",
    "            time.sleep(2)  # Brief pause before restarting\n",
    "        else:\n",
    "            return\n",
    "\n",
    "def load_config(filename=CONFIG_FILE):\n",
    "    \"\"\"Loads configuration from a YAML file.\"\"\"\n",
    "    logger.debug(\"Loading configuration from %s\", filename)\n",
    "    try:\n",
    "        with open(filename, \"r\") as f:\n",
    "            config_data = yaml.safe_load(f)\n",
    "            logger.debug(\"Configuration loaded successfully: %s\", config_data)\n",
    "            return config_data\n",
    "    except FileNotFoundError:\n",
    "        logger.warning(f\"Configuration file '{filename}' not found. Using default settings.\")\n",
    "        return {}\n",
    "    except yaml.YAMLError as e:\n",
    "        logger.error(f\"Configuration file parsing error: {e}\", exc_info=True)\n",
    "        print(\"Configuration file parsing error. Using default settings.\\n\")\n",
    "        return {}\n",
    "\n",
    "async def main():\n",
    "    try:\n",
    "        logger.debug(\"Entering main() function.\")\n",
    "        config = load_config()\n",
    "        app = ChatApplication(config)\n",
    "        await app.run()\n",
    "        logger.debug(\"main() completed.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unhandled error occurred in main: {e}\", exc_info=True)\n",
    "\n",
    "# ---- Run (Jupyter or standalone) ----\n",
    "load_dotenv()  # If you have a .env with OPENAI_API_KEY\n",
    "try:\n",
    "    await main()    # For Jupyter Notebook\n",
    "except Exception as e:\n",
    "    logger.error(f\"Unhandled exception in Jupyter environment: {e}\", exc_info=True)\n",
    "\n",
    "# If you need standalone .py usage, do:\n",
    "# if __name__ == \"__main__\":\n",
    "#     load_dotenv()\n",
    "#     try:\n",
    "#         asyncio.run(main())\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"Unhandled exception in standalone mode: {e}\", exc_info=True)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a8aba4-8fc4-4224-b284-bc13e618e14f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
