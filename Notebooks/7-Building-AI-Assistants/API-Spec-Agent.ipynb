{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75f84369-3fa4-4ded-b25a-cf03b8c96cf5",
   "metadata": {},
   "source": [
    "Integrating an agent to dynamically retrieve and display model specifications from various AI providers' API documentation is an excellent approach to ensure up-to-date and comprehensive information. Here's how you can implement this:\n",
    "\n",
    "**1. Define the Agent's Responsibilities:**\n",
    "\n",
    "- **Fetch Model Lists:** Retrieve the current list of available models from each provider's API.\n",
    "\n",
    "- **Gather Model Specifications:** For each model, extract relevant details such as context window size, input/output token limits, supported modalities, and any other pertinent information.\n",
    "\n",
    "- **Update Local Database:** Maintain a local repository of these specifications to facilitate quick access and reduce redundant API calls.\n",
    "\n",
    "**2. Implementing the Agent:**\n",
    "\n",
    "You can create a Python script or module that performs the following tasks:\n",
    "\n",
    "- **API Endpoints:** Identify and utilize the appropriate API endpoints or documentation URLs for each provider. For example:\n",
    "\n",
    "  - **OpenAI:** Use the [Models API](https://platform.openai.com/docs/models) to list available models and their details.\n",
    "\n",
    "  - **Anthropic:** Refer to the [Models List API](https://docs.anthropic.com/en/api/models-list) for information on Claude models.\n",
    "\n",
    "  - **Google:** Access the [Vertex AI Model Garden](https://cloud.google.com/vertex-ai/docs/model-garden/overview) for details on available models.\n",
    "\n",
    "- **Data Extraction:** Parse the JSON responses or HTML content to extract model specifications.\n",
    "\n",
    "- **Database Update:** Store the extracted information in a structured format, such as a JSON or SQLite database, for easy retrieval.\n",
    "\n",
    "**3. Scheduling Regular Updates:**\n",
    "\n",
    "To ensure the information remains current, schedule the agent to run at regular intervals (e.g., daily or weekly) using a task scheduler like `cron` (Linux/macOS) or Task Scheduler (Windows).\n",
    "\n",
    "**4. Integrating with Your Application:**\n",
    "\n",
    "Modify your Streamlit application to query this local database when displaying model information. This approach ensures that users always see the most recent data without incurring the latency of real-time API calls.\n",
    "\n",
    "**5. Handling API Changes:**\n",
    "\n",
    "Implement error handling and logging within the agent to detect and alert you to any changes in the API structures or endpoints, allowing for prompt updates to the agent's code.\n",
    "\n",
    "**6. Providing Fallback Information:**\n",
    "\n",
    "In cases where API access is limited or unavailable, consider maintaining a fallback dataset with basic model information to ensure continuous functionality.\n",
    "\n",
    "By implementing such an agent, you can automate the process of keeping your application's model specifications up-to-date, providing users with accurate and timely information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8007a4d9-f137-4060-8b9e-337db8710a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install requests\n",
    "#!pip install openai\n",
    "#!pip install anthropic\n",
    "#!pip install google-genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e136ecb-8b39-4642-9ab0-96eda802ba6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models list saved to models_list.json with a total count of: 93\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "def get_env_var(var: str):\n",
    "    \"\"\"Retrieve an environment variable; raises error if not found.\"\"\"\n",
    "    value = os.getenv(var)\n",
    "    if value is None:\n",
    "        raise ValueError(f\"{var} not found in environment variables. Ensure it is set in your .env file.\")\n",
    "    return value\n",
    "\n",
    "# Retrieve API keys from environment variables\n",
    "openai_api_key     = get_env_var(\"OPENAI_API_COURSE_KEY\")\n",
    "anthropic_api_key  = get_env_var(\"ANTHROPIC_API_KEY\")\n",
    "google_api_key     = get_env_var(\"GOOGLE_API_KEY\")\n",
    "xai_api_key        = get_env_var(\"XAI_API_KEY\")\n",
    "\n",
    "def get_openai_models(api_key):\n",
    "    url = \"https://api.openai.com/v1/models\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        if response.ok:\n",
    "            # Return only models starting with \"gpt-\"\n",
    "            return [m[\"id\"] for m in response.json().get(\"data\", []) if m[\"id\"].startswith(\"gpt-\")]\n",
    "        else:\n",
    "            print(\"Failed to retrieve OpenAI models:\", response.status_code, response.text)\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(\"Error retrieving OpenAI models:\", e)\n",
    "        return []\n",
    "\n",
    "def get_anthropic_models(api_key):\n",
    "    url = \"https://api.anthropic.com/v1/models\"\n",
    "    headers = {\n",
    "        \"x-api-key\": api_key,\n",
    "        \"anthropic-version\": \"2023-06-01\",  # Ensure this version matches your API documentation\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        if response.ok:\n",
    "            return [m[\"id\"] for m in response.json().get(\"data\", []) if m[\"id\"].startswith(\"claude\")]\n",
    "        else:\n",
    "            print(\"Failed to retrieve Anthropic models:\", response.status_code, response.text)\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(\"Error retrieving Anthropic models:\", e)\n",
    "        return []\n",
    "\n",
    "def get_google_models(api_key):\n",
    "    try:\n",
    "        client = genai.Client(api_key=api_key)\n",
    "        # Return model names (adjust if more details are needed)\n",
    "        return [model.name for model in client.models.list()]\n",
    "    except Exception as e:\n",
    "        print(\"Failed to retrieve Google models:\", e)\n",
    "        return []\n",
    "\n",
    "def get_grok_models(api_key):\n",
    "    url = \"https://api.x.ai/v1/models\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        models_data = response.json().get(\"data\", [])\n",
    "        return [model[\"id\"] for model in models_data if \"id\" in model]\n",
    "    except Exception as e:\n",
    "        print(\"Failed to retrieve Grok models:\", e)\n",
    "        return []\n",
    "\n",
    "# Fetch available models from each provider\n",
    "openai_models    = get_openai_models(openai_api_key)\n",
    "anthropic_models = get_anthropic_models(anthropic_api_key)\n",
    "google_models    = get_google_models(google_api_key)\n",
    "grok_models      = get_grok_models(xai_api_key)\n",
    "\n",
    "# Assuming 'all_models' is your dictionary containing the model data:\n",
    "all_models = {\n",
    "    \"openai\": openai_models,\n",
    "    \"anthropic\": anthropic_models,\n",
    "    \"google\": google_models,\n",
    "    \"grok\": grok_models\n",
    "}\n",
    "\n",
    "def count_total_models(models_dict):\n",
    "    \"\"\"Count the total number of models in the dictionary.\"\"\"\n",
    "    return sum(len(models) for models in models_dict.values())\n",
    "\n",
    "# Count models and add the total to the dictionary\n",
    "total_models = count_total_models(all_models)\n",
    "all_models[\"total_models\"] = total_models\n",
    "\n",
    "# Save the updated dictionary to models_list.json\n",
    "with open('models_list.json', 'w') as f:\n",
    "    json.dump(all_models, f, indent=4)\n",
    "\n",
    "print(\"Models list saved to models_list.json with a total count of:\", total_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afd9446e-a4d7-40bd-b3c2-d6f846c62fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying details for model: gpt-4o-mini-transcribe\n",
      "Model details:\n",
      "{\n",
      "    \"id\": \"gpt-4o-mini-transcribe\",\n",
      "    \"object\": \"model\",\n",
      "    \"created\": 1742068596,\n",
      "    \"owned_by\": \"system\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Get the first model from the OpenAI models list\n",
    "if openai_models:\n",
    "    first_model_id = openai_models[0]\n",
    "    print(\"Querying details for model:\", first_model_id)\n",
    "\n",
    "    # Build the URL for the model details endpoint\n",
    "    model_url = f\"https://api.openai.com/v1/models/{first_model_id}\"\n",
    "    headers = {\"Authorization\": f\"Bearer {openai_api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    # Query the model details\n",
    "    response = requests.get(model_url, headers=headers, timeout=10)\n",
    "    if response.ok:\n",
    "        model_details = response.json()\n",
    "        print(\"Model details:\")\n",
    "        print(json.dumps(model_details, indent=4))\n",
    "    else:\n",
    "        print(f\"Failed to retrieve model details: {response.status_code} {response.text}\")\n",
    "else:\n",
    "    print(\"No OpenAI models found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86f22080-8d5e-4b4b-a88f-994c2880244a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Anthropic Model Details ===\n",
      "{\n",
      "    \"type\": \"model\",\n",
      "    \"id\": \"claude-3-7-sonnet-20250219\",\n",
      "    \"display_name\": \"Claude 3.7 Sonnet\",\n",
      "    \"created_at\": \"2025-02-24T00:00:00Z\"\n",
      "}\n",
      "\n",
      "=== Google Model Details ===\n",
      "{\n",
      "    \"name\": \"models/chat-bison-001\",\n",
      "    \"description\": \"A legacy text-only model optimized for chat conversations\"\n",
      "}\n",
      "\n",
      "=== Grok Model Details ===\n",
      "{\n",
      "    \"id\": \"grok-2-1212\",\n",
      "    \"created\": 1737331200,\n",
      "    \"object\": \"model\",\n",
      "    \"owned_by\": \"xai\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "def get_env_var(var: str):\n",
    "    value = os.getenv(var)\n",
    "    if value is None:\n",
    "        raise ValueError(f\"{var} not found in environment variables. Ensure it is set in your .env file.\")\n",
    "    return value\n",
    "\n",
    "# Retrieve API keys\n",
    "openai_api_key     = get_env_var(\"OPENAI_API_COURSE_KEY\")\n",
    "anthropic_api_key  = get_env_var(\"ANTHROPIC_API_KEY\")\n",
    "google_api_key     = get_env_var(\"GOOGLE_API_KEY\")\n",
    "xai_api_key        = get_env_var(\"XAI_API_KEY\")\n",
    "\n",
    "# For Anthropic: Query details for the first Anthropic model in our list\n",
    "def query_anthropic_model_details(api_key, model_id):\n",
    "    url = f\"https://api.anthropic.com/v1/models/{model_id}\"\n",
    "    headers = {\n",
    "        \"x-api-key\": api_key,\n",
    "        \"anthropic-version\": \"2023-06-01\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        if response.ok:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"Failed to retrieve Anthropic model details: {response.status_code} {response.text}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(\"Error retrieving Anthropic model details:\", e)\n",
    "        return None\n",
    "\n",
    "# For Google: Try to get details using the GenAI client.\n",
    "# Note: The GenAI SDK might only return model names, so detailed metadata may not be available.\n",
    "def query_google_model_details(api_key, model_name):\n",
    "    try:\n",
    "        client = genai.Client(api_key=api_key)\n",
    "        # The GenAI client may not expose a dedicated \"get details\" method.\n",
    "        # Here we simply return the model object from the list that matches the name.\n",
    "        models = client.models.list()\n",
    "        for model in models:\n",
    "            if model.name == model_name:\n",
    "                # Print available attributes; the SDK might not provide much detail.\n",
    "                return {\"name\": model.name, \"description\": getattr(model, \"description\", \"No description provided\")}\n",
    "        print(\"Model not found in Google models list.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(\"Error retrieving Google model details:\", e)\n",
    "        return None\n",
    "\n",
    "# For Grok: Query details for a given Grok model.\n",
    "def query_grok_model_details(api_key, model_id):\n",
    "    url = f\"https://api.x.ai/v1/models/{model_id}\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        if response.ok:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"Failed to retrieve Grok model details: {response.status_code} {response.text}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(\"Error retrieving Grok model details:\", e)\n",
    "        return None\n",
    "\n",
    "# Example lists (normally these come from your listing functions)\n",
    "# For this example, assume we've already retrieved the lists:\n",
    "anthropic_models = [\"claude-3-7-sonnet-20250219\", \"claude-3-5-sonnet-20241022\", \"claude-3-5-haiku-20241022\"]\n",
    "google_models    = [\"models/chat-bison-001\", \"models/text-bison-001\"]  # using the model names as returned\n",
    "grok_models      = [\"grok-2-1212\", \"grok-2-vision-1212\"]\n",
    "\n",
    "# Query details for the first model from each provider\n",
    "print(\"=== Anthropic Model Details ===\")\n",
    "if anthropic_models:\n",
    "    anthro_details = query_anthropic_model_details(anthropic_api_key, anthropic_models[0])\n",
    "    print(json.dumps(anthro_details, indent=4))\n",
    "else:\n",
    "    print(\"No Anthropic models found.\")\n",
    "\n",
    "print(\"\\n=== Google Model Details ===\")\n",
    "if google_models:\n",
    "    google_details = query_google_model_details(google_api_key, google_models[0])\n",
    "    print(json.dumps(google_details, indent=4))\n",
    "else:\n",
    "    print(\"No Google models found.\")\n",
    "\n",
    "print(\"\\n=== Grok Model Details ===\")\n",
    "if grok_models:\n",
    "    grok_details = query_grok_model_details(xai_api_key, grok_models[0])\n",
    "    print(json.dumps(grok_details, indent=4))\n",
    "else:\n",
    "    print(\"No Grok models found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec626d71-531c-4b33-b7bb-9534327bc73a",
   "metadata": {},
   "source": [
    "Based on the responses we received:\n",
    "\n",
    "**Anthropic returns:**\n",
    "- **type:** The kind of object (in this case, a model)\n",
    "- **id:** The unique identifier for the model\n",
    "- **display_name:** A human-friendly name (e.g., \"Claude 3.7 Sonnet\")\n",
    "- **created_at:** A timestamp indicating when the model was created\n",
    "\n",
    "**Google (via the GenAI SDK) returns:**\n",
    "- **name:** The model’s identifier (including a path-like string, e.g., \"models/chat-bison-001\")\n",
    "- **description:** A brief description of the model (e.g., \"A legacy text-only model optimized for chat conversations\")\n",
    "\n",
    "**Grok (xAI) returns:**\n",
    "- **id:** The unique identifier for the model\n",
    "- **created:** A creation timestamp (in Unix time)\n",
    "- **object:** Typically indicating the object type (here, \"model\")\n",
    "- **owned_by:** The owner (e.g., \"xai\")\n",
    "\n",
    "**OpenAI returns:**\n",
    "- **id:** The unique identifier for the model (e.g., \"gpt-4o-mini-transcribe\")\n",
    "- **object:** The object type (typically \"model\")\n",
    "- **created:** The creation timestamp (in Unix time)\n",
    "- **owned_by:** The owner (which can be \"system\" or \"openai\")\n",
    "\n",
    "This consolidated view helps you compare the metadata available from each provider and determine what additional details you might need to supplement through internal configuration or documentation.\n",
    "\n",
    "**What Else Can Be Retrieved Automatically?**\n",
    "\n",
    "The information you can automatically retrieve depends on each provider’s API design. Here are some possibilities:\n",
    "\n",
    "1. **Basic Metadata:**  \n",
    "   Most endpoints return basic metadata like model IDs, creation timestamps, and sometimes a human-friendly name or description.\n",
    "\n",
    "2. **Permissions and Access Controls:**  \n",
    "   Some APIs may include fields indicating who can access or use a particular model (e.g., `\"owned_by\"` or `\"permissions\"` lists).\n",
    "\n",
    "3. **Status Information:**  \n",
    "   In some cases, the API might include information on the model’s current status or whether it’s in preview, beta, or fully released.\n",
    "\n",
    "4. **Versioning:**  \n",
    "   The response might contain version-related details (e.g., in the model ID or a dedicated version field).\n",
    "\n",
    "**What Isn’t Typically Retrieved Automatically?**\n",
    "\n",
    "Many technical details like:\n",
    "  \n",
    "- **Parameter Count or Model Size**\n",
    "- **Maximum Context Window (Input/Output Token Limits)**\n",
    "- **Supported Modalities (e.g., text, image, audio)**\n",
    "- **Latency or Performance Metrics**\n",
    "\n",
    "...are usually not provided in the basic listing endpoints. This extra information is often found in provider documentation or requires separate endpoints or manual configuration.\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "If you need more detailed technical specifications (like context window size or parameter counts), you may need to:\n",
    "  \n",
    "- **Reference the API Documentation:** Supplement the API response with data from official documentation.\n",
    "- **Create an Internal Repository:** Manually compile and maintain these details in your application (or use a scheduled process that parses documentation pages if available).\n",
    "\n",
    "This approach lets you combine automatically retrieved metadata with additional technical details necessary for your application's logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3c7b38-21b9-44c6-ac71-87fea82581b5",
   "metadata": {},
   "source": [
    "Based on OpenAI's official API documentation and the response we received, here's what we can automatically retrieve from the `/v1/models` endpoint for an OpenAI model:\n",
    "\n",
    "- **id:** The unique identifier for the model (e.g., `\"gpt-4o-mini-transcribe\"`).\n",
    "- **object:** The type of the returned object (typically `\"model\"`).\n",
    "- **created:** A Unix timestamp indicating when the model was created.\n",
    "- **owned_by:** Information about who owns the model (this might be `\"system\"` for system-managed models or `\"openai\"` for those managed by OpenAI).\n",
    "\n",
    "### What Else Might Be Available?\n",
    "\n",
    "When analyzing OpenAI's API information on their documentation page, you'll notice that the models endpoint intentionally returns only minimal metadata. Additional technical details like:\n",
    "\n",
    "- **Maximum Context Length (Input/Output Token Limits)**\n",
    "- **Parameter Count or Model Size**\n",
    "- **Supported Modalities (e.g., text, image, audio)**\n",
    "- **Performance Metrics or Latency Data**\n",
    "\n",
    "...are not included in the automatic API response. These details are typically found in the official documentation and not returned via the API itself.\n",
    "\n",
    "### Why Is This the Case?\n",
    "\n",
    "OpenAI’s design for the `/v1/models` endpoint is to provide a list of models and basic metadata. The assumption is that any deeper technical details (e.g., context window or parameter count) will be managed internally or referenced from their documentation. This means that if you need to display or utilize such details in your application, you’ll likely have to supplement the API response with internal configuration (such as your `MODEL_TOKEN_LIMITS` dictionary) or a manual update based on the latest documentation.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Review the Documentation:**  \n",
    "   Check OpenAI's API reference pages (such as [Models API](https://platform.openai.com/docs/api-reference/models)) for any additional details that might be documented but not exposed via the API.\n",
    "\n",
    "2. **Supplement Data:**  \n",
    "   If you need details like context window size or parameter count, consider maintaining an internal reference table (like your existing `MODEL_TOKEN_LIMITS` dictionary) or manually parsing their documentation.\n",
    "\n",
    "3. **Consider Future Endpoints:**  \n",
    "   Occasionally, APIs evolve. Keep an eye on OpenAI's announcements or API changelogs in case they decide to expose more metadata in the future.\n",
    "\n",
    "In summary, the automatically retrievable information from OpenAI's models endpoint is limited to basic metadata, and additional details must be supplemented by manual configuration or referenced from external documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11560ea-f81f-4279-931c-2fc08c40310f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "665943cd-8a28-4da2-bc66-6edade380cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model details:\n",
      "{\n",
      "    \"id\": \"gpt-4o-2024-05-13\",\n",
      "    \"object\": \"model\",\n",
      "    \"created\": 1715368132,\n",
      "    \"owned_by\": \"system\"\n",
      "}\n",
      "\n",
      "Debug/Rate Limiting Headers:\n",
      "{\n",
      "    \"openai-organization\": null,\n",
      "    \"openai-processing-ms\": \"105\",\n",
      "    \"openai-version\": \"2020-10-01\",\n",
      "    \"x-request-id\": \"2ac1c625553f3c3d339759af2ab56f08\",\n",
      "    \"x-ratelimit-limit-requests\": null,\n",
      "    \"x-ratelimit-limit-tokens\": null,\n",
      "    \"x-ratelimit-remaining-requests\": null,\n",
      "    \"x-ratelimit-remaining-tokens\": null,\n",
      "    \"x-ratelimit-reset-requests\": null,\n",
      "    \"x-ratelimit-reset-tokens\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "def get_env_var(var: str):\n",
    "    value = os.getenv(var)\n",
    "    if value is None:\n",
    "        raise ValueError(f\"{var} not found in environment variables.\")\n",
    "    return value\n",
    "\n",
    "openai_api_key = get_env_var(\"OPENAI_API_COURSE_KEY\")\n",
    "\n",
    "# Query details for a specific model\n",
    "model_id = \"gpt-4o-2024-05-13\"\n",
    "model_url = f\"https://api.openai.com/v1/models/{model_id}\"\n",
    "headers = {\"Authorization\": f\"Bearer {openai_api_key}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "response = requests.get(model_url, headers=headers, timeout=10)\n",
    "\n",
    "if response.ok:\n",
    "    model_details = response.json()\n",
    "    print(\"Model details:\")\n",
    "    print(json.dumps(model_details, indent=4))\n",
    "    \n",
    "    # Extract and print relevant headers for debugging and rate limiting\n",
    "    response_headers = response.headers\n",
    "    debug_info = {\n",
    "        \"openai-organization\": response_headers.get(\"openai-organization\"),\n",
    "        \"openai-processing-ms\": response_headers.get(\"openai-processing-ms\"),\n",
    "        \"openai-version\": response_headers.get(\"openai-version\"),\n",
    "        \"x-request-id\": response_headers.get(\"x-request-id\"),\n",
    "        \"x-ratelimit-limit-requests\": response_headers.get(\"x-ratelimit-limit-requests\"),\n",
    "        \"x-ratelimit-limit-tokens\": response_headers.get(\"x-ratelimit-limit-tokens\"),\n",
    "        \"x-ratelimit-remaining-requests\": response_headers.get(\"x-ratelimit-remaining-requests\"),\n",
    "        \"x-ratelimit-remaining-tokens\": response_headers.get(\"x-ratelimit-remaining-tokens\"),\n",
    "        \"x-ratelimit-reset-requests\": response_headers.get(\"x-ratelimit-reset-requests\"),\n",
    "        \"x-ratelimit-reset-tokens\": response_headers.get(\"x-ratelimit-reset-tokens\"),\n",
    "    }\n",
    "    print(\"\\nDebug/Rate Limiting Headers:\")\n",
    "    print(json.dumps(debug_info, indent=4))\n",
    "else:\n",
    "    print(f\"Failed to retrieve model details: {response.status_code} {response.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502466d1-59a7-42b9-bb0d-c660c823f9af",
   "metadata": {},
   "source": [
    "The response for the model `\"gpt-4o-2024-05-13\"` is very similar to the previous one in structure. Here’s what we can glean from it:\n",
    "\n",
    "- **Model Details:**\n",
    "  - **id:** `\"gpt-4o-2024-05-13\"`  \n",
    "    This uniquely identifies the model.\n",
    "  - **object:** `\"model\"`  \n",
    "    Indicates the type of the object returned.\n",
    "  - **created:** `1715368132`  \n",
    "    A Unix timestamp indicating when the model was created.\n",
    "  - **owned_by:** `\"system\"`  \n",
    "    Indicates that this model is managed by the system.\n",
    "\n",
    "- **Debug/Rate Limiting Headers:**\n",
    "  - **openai-processing-ms:** `\"105\"`  \n",
    "    Indicates that the API took 105 milliseconds to process the request.\n",
    "  - **openai-version:** `\"2020-10-01\"`  \n",
    "    Shows the API version used.\n",
    "  - **x-request-id:** `\"2ac1c625553f3c3d339759af2ab56f08\"`  \n",
    "    Provides a unique identifier for this API request, useful for debugging.\n",
    "  - **Rate Limiting Headers:**  \n",
    "    All related headers (like limits and remaining counts) are null, which is expected for this endpoint.\n",
    "\n",
    "### Why This Information Might Be Useful\n",
    "\n",
    "- **Request Identification & Debugging:**  \n",
    "  The `x-request-id` can help you trace and debug issues with API requests, particularly in production or when working with support teams.\n",
    "\n",
    "- **Performance Insights:**  \n",
    "  The `openai-processing-ms` value gives you an idea of the latency for the API call, which can be valuable for performance monitoring.\n",
    "\n",
    "- **API Versioning:**  \n",
    "  Knowing the `openai-version` ensures you are aware of which version of the API you are interacting with, which is crucial for compatibility.\n",
    "\n",
    "### Summary\n",
    "\n",
    "While the model details endpoint provides only minimal metadata, the accompanying HTTP headers give you valuable information for debugging and monitoring purposes. For deeper technical details (like maximum context window or model size), you would typically rely on OpenAI's documentation or internal configurations.\n",
    "\n",
    "If you need to automatically enrich your model information, you might combine these API responses with manually maintained data (like your `MODEL_TOKEN_LIMITS` dictionary) or use separate endpoints if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab3ef1b7-eabd-44fe-b478-8b2afc5cc24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading metadata from models_metadata.json: Expecting property name enclosed in double quotes: line 20 column 5 (char 684)\n",
      "Models list saved to models_list.json with a total count of: 93\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "def get_env_var(var: str):\n",
    "    \"\"\"Retrieve an environment variable; raises error if not found.\"\"\"\n",
    "    value = os.getenv(var)\n",
    "    if value is None:\n",
    "        raise ValueError(f\"{var} not found in environment variables. Ensure it is set in your .env file.\")\n",
    "    return value\n",
    "\n",
    "# Retrieve API keys from environment variables\n",
    "openai_api_key     = get_env_var(\"OPENAI_API_COURSE_KEY\")\n",
    "anthropic_api_key  = get_env_var(\"ANTHROPIC_API_KEY\")\n",
    "google_api_key     = get_env_var(\"GOOGLE_API_KEY\")\n",
    "xai_api_key        = get_env_var(\"XAI_API_KEY\")\n",
    "\n",
    "# Functions to dynamically list models from each provider\n",
    "def get_openai_models(api_key):\n",
    "    url = \"https://api.openai.com/v1/models\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        if response.ok:\n",
    "            return [m[\"id\"] for m in response.json().get(\"data\", []) if m[\"id\"].startswith(\"gpt-\")]\n",
    "        else:\n",
    "            print(\"Failed to retrieve OpenAI models:\", response.status_code, response.text)\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(\"Error retrieving OpenAI models:\", e)\n",
    "        return []\n",
    "\n",
    "def get_anthropic_models(api_key):\n",
    "    url = \"https://api.anthropic.com/v1/models\"\n",
    "    headers = {\n",
    "        \"x-api-key\": api_key,\n",
    "        \"anthropic-version\": \"2023-06-01\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        if response.ok:\n",
    "            return [m[\"id\"] for m in response.json().get(\"data\", []) if m[\"id\"].startswith(\"claude\")]\n",
    "        else:\n",
    "            print(\"Failed to retrieve Anthropic models:\", response.status_code, response.text)\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(\"Error retrieving Anthropic models:\", e)\n",
    "        return []\n",
    "\n",
    "def get_google_models(api_key):\n",
    "    try:\n",
    "        client = genai.Client(api_key=api_key)\n",
    "        return [model.name for model in client.models.list()]\n",
    "    except Exception as e:\n",
    "        print(\"Failed to retrieve Google models:\", e)\n",
    "        return []\n",
    "\n",
    "def get_grok_models(api_key):\n",
    "    url = \"https://api.x.ai/v1/models\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        models_data = response.json().get(\"data\", [])\n",
    "        return [model[\"id\"] for model in models_data if \"id\" in model]\n",
    "    except Exception as e:\n",
    "        print(\"Failed to retrieve Grok models:\", e)\n",
    "        return []\n",
    "\n",
    "# Load dynamic models from all providers\n",
    "openai_models    = get_openai_models(openai_api_key)\n",
    "anthropic_models = get_anthropic_models(anthropic_api_key)\n",
    "google_models    = get_google_models(google_api_key)\n",
    "grok_models      = get_grok_models(xai_api_key)\n",
    "\n",
    "dynamic_models = {\n",
    "    \"openai\": openai_models,\n",
    "    \"anthropic\": anthropic_models,\n",
    "    \"google\": google_models,\n",
    "    \"grok\": grok_models\n",
    "}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Load additional metadata from a JSON file (if available)\n",
    "# -----------------------------------------------------------------------------\n",
    "def load_models_metadata(filename=\"models_metadata.json\"):\n",
    "    if os.path.exists(filename):\n",
    "        try:\n",
    "            with open(filename, \"r\") as f:\n",
    "                return json.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading metadata from {filename}: {e}\")\n",
    "            return {}\n",
    "    else:\n",
    "        print(f\"{filename} not found. No additional metadata will be added.\")\n",
    "        return {}\n",
    "\n",
    "models_metadata = load_models_metadata(\"models_metadata.json\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Enrich dynamic models with metadata (if available)\n",
    "# -----------------------------------------------------------------------------\n",
    "def enrich_models(dynamic_models, metadata):\n",
    "    enriched = {}\n",
    "    for provider, models in dynamic_models.items():\n",
    "        enriched[provider] = []\n",
    "        for model in models:\n",
    "            model_metadata = metadata.get(model, {})  # Get metadata if exists; else empty dict\n",
    "            enriched[provider].append({\n",
    "                \"model_id\": model,\n",
    "                \"metadata\": model_metadata\n",
    "            })\n",
    "    return enriched\n",
    "\n",
    "enriched_models = enrich_models(dynamic_models, models_metadata)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Count total number of models and add to the dictionary\n",
    "# -----------------------------------------------------------------------------\n",
    "def count_total_models(models_dict):\n",
    "    return sum(len(models) for models in models_dict.values())\n",
    "\n",
    "total_models = count_total_models(dynamic_models)\n",
    "enriched_models[\"total_models\"] = total_models\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Save enriched models list to models_list.json\n",
    "# -----------------------------------------------------------------------------\n",
    "with open('models_list.json', 'w') as f:\n",
    "    json.dump(enriched_models, f, indent=4)\n",
    "\n",
    "print(\"Models list saved to models_list.json with a total count of:\", total_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bb11f82-bcfd-4de0-838f-3bef6d3e2b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching page: 403\n",
      "Scraped models metadata saved to models_metadata.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "\n",
    "# URL of the OpenAI models information page (example URL; update as needed)\n",
    "url = \"https://platform.openai.com/docs/api-reference/models\"\n",
    "\n",
    "# Fetch the page\n",
    "response = requests.get(url)\n",
    "if response.status_code != 200:\n",
    "    print(\"Error fetching page:\", response.status_code)\n",
    "    exit()\n",
    "\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Initialize a dictionary to store metadata for each model.\n",
    "# This is a draft approach; you will need to adjust the selectors based on the actual HTML.\n",
    "models_metadata = {}\n",
    "\n",
    "# Suppose that each model is described within a section with a specific CSS class.\n",
    "# (This is a placeholder selector; update according to the actual page.)\n",
    "model_sections = soup.find_all(\"div\", class_=\"model-section\")\n",
    "\n",
    "for section in model_sections:\n",
    "    # Attempt to extract the model ID/name from a heading.\n",
    "    model_id_elem = section.find(\"h2\")\n",
    "    if not model_id_elem:\n",
    "        continue\n",
    "    model_id = model_id_elem.text.strip()\n",
    "    \n",
    "    # Extract a description. For example, assume there's a <p> with class \"description\".\n",
    "    description_elem = section.find(\"p\", class_=\"description\")\n",
    "    description = description_elem.text.strip() if description_elem else \"TBD\"\n",
    "    \n",
    "    # Get the full text of the section to search for token limits\n",
    "    section_text = section.get_text()\n",
    "    \n",
    "    # Use regular expressions to look for token limits; adjust patterns as needed.\n",
    "    max_input_match = re.search(r\"Max Input Tokens:\\s*(\\d+)\", section_text)\n",
    "    max_output_match = re.search(r\"Max Output Tokens:\\s*(\\d+)\", section_text)\n",
    "    context_window_match = re.search(r\"Context Window:\\s*(\\d+)\", section_text)\n",
    "    \n",
    "    max_input_tokens = int(max_input_match.group(1)) if max_input_match else \"TBD\"\n",
    "    max_output_tokens = int(max_output_match.group(1)) if max_output_match else \"TBD\"\n",
    "    context_window = int(context_window_match.group(1)) if context_window_match else \"TBD\"\n",
    "    \n",
    "    models_metadata[model_id] = {\n",
    "        \"max_input_tokens\": max_input_tokens,\n",
    "        \"max_output_tokens\": max_output_tokens,\n",
    "        \"context_window\": context_window,\n",
    "        \"description\": description\n",
    "    }\n",
    "\n",
    "# For demonstration purposes, add a sample entry if no sections were found:\n",
    "if not models_metadata:\n",
    "    models_metadata = {\n",
    "        \"gpt-4\": {\n",
    "            \"max_input_tokens\": 8192,\n",
    "            \"max_output_tokens\": 8192,\n",
    "            \"context_window\": 8192,\n",
    "            \"description\": \"GPT-4: A large multimodal model capable of processing text and images. Input: text, images; Output: text.\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Save the metadata to models_metadata_scraped.json\n",
    "with open(\"models_metadata.json\", \"w\") as f:\n",
    "    json.dump(models_metadata, f, indent=4)\n",
    "\n",
    "print(\"Scraped models metadata saved to models_metadata.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c27a519-c2d1-421e-a525-616dc9402996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.29.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/Cellar/jupyterlab/4.3.5_1/libexec/lib/python3.13/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Downloading trio-0.29.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/opt/certifi/lib/python3.13/site-packages (from selenium) (2025.1.31)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/Cellar/jupyterlab/4.3.5_1/libexec/lib/python3.13/site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in /usr/local/Cellar/jupyterlab/4.3.5_1/libexec/lib/python3.13/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /usr/local/Cellar/jupyterlab/4.3.5_1/libexec/lib/python3.13/site-packages (from trio~=0.17->selenium) (25.1.0)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: idna in /usr/local/Cellar/jupyterlab/4.3.5_1/libexec/lib/python3.13/site-packages (from trio~=0.17->selenium) (3.10)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/Cellar/jupyterlab/4.3.5_1/libexec/lib/python3.13/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3,>=1.26->selenium)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/Cellar/jupyterlab/4.3.5_1/libexec/lib/python3.13/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Downloading selenium-4.29.0-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading trio-0.29.0-py3-none-any.whl (492 kB)\n",
      "Downloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Installing collected packages: sortedcontainers, wsproto, pysocks, outcome, trio, trio-websocket, selenium\n",
      "Successfully installed outcome-1.3.0.post0 pysocks-1.7.1 selenium-4.29.0 sortedcontainers-2.4.0 trio-0.29.0 trio-websocket-0.12.2 wsproto-1.2.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/usr/local/Cellar/jupyterlab/4.3.5_1/libexec/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4759932-988a-42ec-a446-3a41aeac95c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 models on the overview page.\n",
      "Models metadata saved to models_metadata_scraped.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL for the OpenAI models page\n",
    "OVERVIEW_URL = \"https://platform.openai.com/docs/models\"\n",
    "\n",
    "def fetch_dynamic_page(url):\n",
    "    # Configure Selenium to run in headless mode\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    # Set up the webdriver (make sure chromedriver is installed and in PATH)\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "    # Wait for the dynamic content to load (adjust sleep as needed)\n",
    "    time.sleep(5)\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    return html\n",
    "\n",
    "def parse_overview_page(html):\n",
    "    \"\"\"Parse the dynamically loaded overview page to extract model names and their URLs.\"\"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    models = {}\n",
    "    \n",
    "    # Inspect the page source (using your browser's developer tools) to find\n",
    "    # the appropriate selectors. For example, suppose model links are in <a> tags\n",
    "    # with a class \"model-link\":\n",
    "    for a in soup.find_all(\"a\", class_=\"model-link\", href=True):\n",
    "        href = a[\"href\"]\n",
    "        model_id = href.split(\"/\")[-1].strip()  # e.g., \"gpt-4\"\n",
    "        # Construct the full URL for the model page\n",
    "        model_url = \"https://platform.openai.com\" + href\n",
    "        models[model_id] = model_url\n",
    "    return models\n",
    "\n",
    "def parse_model_page(html):\n",
    "    \"\"\"Parse an individual model page to extract metadata and pricing info.\"\"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    metadata = {\n",
    "        \"max_input_tokens\": \"TBD\",\n",
    "        \"max_output_tokens\": \"TBD\",\n",
    "        \"context_window\": \"TBD\",\n",
    "        \"description\": \"TBD\",\n",
    "        \"pricing\": \"TBD\"\n",
    "    }\n",
    "    \n",
    "    # These selectors are examples. You will need to inspect the page and adjust:\n",
    "    desc_elem = soup.find(\"div\", class_=\"model-description\")\n",
    "    if desc_elem:\n",
    "        metadata[\"description\"] = desc_elem.get_text(separator=\" \", strip=True)\n",
    "    \n",
    "    full_text = soup.get_text(separator=\" \", strip=True)\n",
    "    # Use regex to find token limits and pricing if available\n",
    "    input_match = re.search(r\"Max Input Tokens:\\s*(\\d+)\", full_text)\n",
    "    output_match = re.search(r\"Max Output Tokens:\\s*(\\d+)\", full_text)\n",
    "    context_match = re.search(r\"Context Window:\\s*(\\d+)\", full_text)\n",
    "    pricing_match = re.search(r\"Pricing:\\s*([\\$\\d\\.]+)\", full_text)\n",
    "    \n",
    "    if input_match:\n",
    "        metadata[\"max_input_tokens\"] = int(input_match.group(1))\n",
    "    if output_match:\n",
    "        metadata[\"max_output_tokens\"] = int(output_match.group(1))\n",
    "    if context_match:\n",
    "        metadata[\"context_window\"] = int(context_match.group(1))\n",
    "    if pricing_match:\n",
    "        metadata[\"pricing\"] = pricing_match.group(1)\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "def scrape_all_models():\n",
    "    \"\"\"Scrape the OpenAI models overview page, then scrape each model page for metadata.\"\"\"\n",
    "    overview_html = fetch_dynamic_page(OVERVIEW_URL)\n",
    "    if not overview_html:\n",
    "        return {}\n",
    "    \n",
    "    models = parse_overview_page(overview_html)\n",
    "    print(f\"Found {len(models)} models on the overview page.\")\n",
    "    \n",
    "    models_metadata = {}\n",
    "    \n",
    "    for model_id, model_url in models.items():\n",
    "        print(f\"Scraping metadata for {model_id} from {model_url}\")\n",
    "        model_html = fetch_dynamic_page(model_url)\n",
    "        if model_html:\n",
    "            metadata = parse_model_page(model_html)\n",
    "        else:\n",
    "            metadata = {\n",
    "                \"max_input_tokens\": \"TBD\",\n",
    "                \"max_output_tokens\": \"TBD\",\n",
    "                \"context_window\": \"TBD\",\n",
    "                \"description\": \"TBD\",\n",
    "                \"pricing\": \"TBD\"\n",
    "            }\n",
    "        models_metadata[model_id] = metadata\n",
    "    \n",
    "    return models_metadata\n",
    "\n",
    "def save_metadata(metadata, filename=\"models_metadata_scraped.json\"):\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "    print(f\"Models metadata saved to {filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    metadata = scrape_all_models()\n",
    "    save_metadata(metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f94332bf-c369-4cd6-a9d8-ee9affc735e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout waiting for dynamic content: Message: \n",
      "Stacktrace:\n",
      "0   chromedriver                        0x0000000103315818 chromedriver + 6105112\n",
      "1   chromedriver                        0x000000010330d41a chromedriver + 6071322\n",
      "2   chromedriver                        0x0000000102da8600 chromedriver + 415232\n",
      "3   chromedriver                        0x0000000102dfa2c0 chromedriver + 750272\n",
      "4   chromedriver                        0x0000000102dfa511 chromedriver + 750865\n",
      "5   chromedriver                        0x0000000102e4a9c4 chromedriver + 1079748\n",
      "6   chromedriver                        0x0000000102e2063d chromedriver + 906813\n",
      "7   chromedriver                        0x0000000102e47c3d chromedriver + 1068093\n",
      "8   chromedriver                        0x0000000102e203e3 chromedriver + 906211\n",
      "9   chromedriver                        0x0000000102dec29a chromedriver + 692890\n",
      "10  chromedriver                        0x0000000102ded3f1 chromedriver + 697329\n",
      "11  chromedriver                        0x00000001032d4d10 chromedriver + 5840144\n",
      "12  chromedriver                        0x00000001032d8be4 chromedriver + 5856228\n",
      "13  chromedriver                        0x00000001032af946 chromedriver + 5687622\n",
      "14  chromedriver                        0x00000001032d95db chromedriver + 5858779\n",
      "15  chromedriver                        0x000000010329e034 chromedriver + 5615668\n",
      "16  chromedriver                        0x00000001032fb378 chromedriver + 5997432\n",
      "17  chromedriver                        0x00000001032fb53f chromedriver + 5997887\n",
      "18  chromedriver                        0x000000010330cff8 chromedriver + 6070264\n",
      "19  libsystem_pthread.dylib             0x00007ff80270d253 _pthread_start + 99\n",
      "20  libsystem_pthread.dylib             0x00007ff802708bef thread_start + 15\n",
      "\n",
      "Found 0 models on the overview page.\n",
      "Models metadata saved to models_metadata_scraped.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the OpenAI models overview page\n",
    "OVERVIEW_URL = \"https://platform.openai.com/docs/models\"\n",
    "\n",
    "def setup_driver():\n",
    "    \"\"\"Set up Selenium Chrome driver in headless mode.\"\"\"\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    # You may add further options if needed\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    return driver\n",
    "\n",
    "def fetch_dynamic_page(url, driver, wait_time=10):\n",
    "    \"\"\"Fetch a dynamically rendered page using Selenium and wait for model links.\"\"\"\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        # Wait for at least one <a> tag containing '/docs/models/' in href\n",
    "        WebDriverWait(driver, wait_time).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"a[href*='/docs/models/']\"))\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"Timeout waiting for dynamic content:\", e)\n",
    "    # Give an extra second for safety\n",
    "    time.sleep(1)\n",
    "    return driver.page_source\n",
    "\n",
    "def parse_overview_page(html):\n",
    "    \"\"\"Parse the overview page to extract model names and their URLs.\"\"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    models = {}\n",
    "    # Find all <a> tags whose href contains \"/docs/models/\"\n",
    "    for a in soup.find_all(\"a\", href=True):\n",
    "        href = a[\"href\"]\n",
    "        if \"/docs/models/\" in href:\n",
    "            parts = href.split(\"/\")\n",
    "            if len(parts) > 2:\n",
    "                model_id = parts[-1].strip()\n",
    "                # Filter out empty strings and duplicates\n",
    "                if model_id and model_id not in models:\n",
    "                    model_url = \"https://platform.openai.com\" + href\n",
    "                    models[model_id] = model_url\n",
    "    return models\n",
    "\n",
    "def parse_model_page(html):\n",
    "    \"\"\"Parse an individual model page to extract metadata and pricing info.\"\"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    metadata = {\n",
    "        \"max_input_tokens\": \"TBD\",\n",
    "        \"max_output_tokens\": \"TBD\",\n",
    "        \"context_window\": \"TBD\",\n",
    "        \"description\": \"TBD\",\n",
    "        \"pricing\": \"TBD\"\n",
    "    }\n",
    "    # Example: Try to extract description from a known container (adjust selector)\n",
    "    desc_elem = soup.find(\"div\", class_=\"model-description\")\n",
    "    if desc_elem:\n",
    "        metadata[\"description\"] = desc_elem.get_text(separator=\" \", strip=True)\n",
    "    \n",
    "    full_text = soup.get_text(separator=\" \", strip=True)\n",
    "    # Use regex to extract token limits and pricing\n",
    "    input_match = re.search(r\"Max Input Tokens:\\s*(\\d+)\", full_text)\n",
    "    output_match = re.search(r\"Max Output Tokens:\\s*(\\d+)\", full_text)\n",
    "    context_match = re.search(r\"Context Window:\\s*(\\d+)\", full_text)\n",
    "    pricing_match = re.search(r\"Pricing:\\s*([\\$\\d\\.]+)\", full_text)\n",
    "    \n",
    "    if input_match:\n",
    "        metadata[\"max_input_tokens\"] = int(input_match.group(1))\n",
    "    if output_match:\n",
    "        metadata[\"max_output_tokens\"] = int(output_match.group(1))\n",
    "    if context_match:\n",
    "        metadata[\"context_window\"] = int(context_match.group(1))\n",
    "    if pricing_match:\n",
    "        metadata[\"pricing\"] = pricing_match.group(1)\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "def scrape_all_models():\n",
    "    \"\"\"Scrape the OpenAI models overview page and then each model page for metadata.\"\"\"\n",
    "    driver = setup_driver()\n",
    "    overview_html = fetch_dynamic_page(OVERVIEW_URL, driver)\n",
    "    models = parse_overview_page(overview_html)\n",
    "    print(f\"Found {len(models)} models on the overview page.\")\n",
    "    \n",
    "    models_metadata = {}\n",
    "    for model_id, model_url in models.items():\n",
    "        print(f\"Scraping metadata for {model_id} from {model_url}\")\n",
    "        model_html = fetch_dynamic_page(model_url, driver)\n",
    "        if model_html:\n",
    "            metadata = parse_model_page(model_html)\n",
    "        else:\n",
    "            metadata = {\n",
    "                \"max_input_tokens\": \"TBD\",\n",
    "                \"max_output_tokens\": \"TBD\",\n",
    "                \"context_window\": \"TBD\",\n",
    "                \"description\": \"TBD\",\n",
    "                \"pricing\": \"TBD\"\n",
    "            }\n",
    "        models_metadata[model_id] = metadata\n",
    "    driver.quit()\n",
    "    return models_metadata\n",
    "\n",
    "def save_metadata(metadata, filename=\"models_metadata_scraped.json\"):\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "    print(f\"Models metadata saved to {filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    metadata = scrape_all_models()\n",
    "    save_metadata(metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d223470-3d41-4b38-ae6e-07eba0c03784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic page source saved to dynamic_page_source.html\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get(\"https://platform.openai.com/docs/models\")\n",
    "time.sleep(5)  # wait for dynamic content to load\n",
    "page_source = driver.page_source\n",
    "driver.quit()\n",
    "\n",
    "with open(\"dynamic_page_source.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(page_source)\n",
    "print(\"Dynamic page source saved to dynamic_page_source.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d41cd6c1-09d6-4f0a-bd37-d007f79d97d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch page: 403\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://platform.openai.com/docs/models\"\n",
    "response = requests.get(url)\n",
    "if response.ok:\n",
    "    with open(\"page_source.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(response.text)\n",
    "    print(\"Page source saved to page_source.html\")\n",
    "else:\n",
    "    print(\"Failed to fetch page:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87301e20-fb22-4db8-b594-1f8502834656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found models:\n",
      "{}\n",
      "Model links saved to openai_model_links.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def setup_driver():\n",
    "    \"\"\"Set up Selenium Chrome driver in headless mode.\"\"\"\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    return driver\n",
    "\n",
    "def fetch_dynamic_page(url, driver, wait_time=15):\n",
    "    \"\"\"Fetch a dynamically rendered page using Selenium.\"\"\"\n",
    "    driver.get(url)\n",
    "    # Optionally scroll to bottom to force lazy-loading content\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(wait_time)\n",
    "    return driver.page_source\n",
    "\n",
    "def find_model_links(html):\n",
    "    \"\"\"\n",
    "    Parse the overview page HTML and extract links that follow the pattern:\n",
    "    \"https://platform.openai.com/docs/models/<model_id>\"\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    model_links = {}\n",
    "    \n",
    "    # Loop through all <a> tags that have an href\n",
    "    for a in soup.find_all(\"a\", href=True):\n",
    "        href = a['href']\n",
    "        # Check if the link points to a model page. It might be a relative URL.\n",
    "        if href.startswith(\"/docs/models/\") or href.startswith(\"https://platform.openai.com/docs/models/\"):\n",
    "            # Construct full URL if needed\n",
    "            if href.startswith(\"/docs/models/\"):\n",
    "                full_url = \"https://platform.openai.com\" + href\n",
    "            else:\n",
    "                full_url = href\n",
    "            # Extract model id from the URL (the last part)\n",
    "            model_id = full_url.split(\"/\")[-1].strip()\n",
    "            if model_id and model_id not in model_links:\n",
    "                model_links[model_id] = full_url\n",
    "    return model_links\n",
    "\n",
    "def main():\n",
    "    overview_url = \"https://platform.openai.com/docs/models\"\n",
    "    driver = setup_driver()\n",
    "    html = fetch_dynamic_page(overview_url, driver, wait_time=15)\n",
    "    driver.quit()\n",
    "    \n",
    "    model_links = find_model_links(html)\n",
    "    print(\"Found models:\")\n",
    "    print(json.dumps(model_links, indent=4))\n",
    "    \n",
    "    # Save the model links to a JSON file\n",
    "    with open(\"openai_model_links.json\", \"w\") as f:\n",
    "        json.dump(model_links, f, indent=4)\n",
    "    print(\"Model links saved to openai_model_links.json\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b05e812-f064-4747-961c-ed3c0a11db99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout waiting for dynamic content: Message: \n",
      "Stacktrace:\n",
      "0   chromedriver                        0x000000010f755818 chromedriver + 6105112\n",
      "1   chromedriver                        0x000000010f74d41a chromedriver + 6071322\n",
      "2   chromedriver                        0x000000010f1e8600 chromedriver + 415232\n",
      "3   chromedriver                        0x000000010f23a2c0 chromedriver + 750272\n",
      "4   chromedriver                        0x000000010f23a511 chromedriver + 750865\n",
      "5   chromedriver                        0x000000010f28a9c4 chromedriver + 1079748\n",
      "6   chromedriver                        0x000000010f26063d chromedriver + 906813\n",
      "7   chromedriver                        0x000000010f287c3d chromedriver + 1068093\n",
      "8   chromedriver                        0x000000010f2603e3 chromedriver + 906211\n",
      "9   chromedriver                        0x000000010f22c29a chromedriver + 692890\n",
      "10  chromedriver                        0x000000010f22d3f1 chromedriver + 697329\n",
      "11  chromedriver                        0x000000010f714d10 chromedriver + 5840144\n",
      "12  chromedriver                        0x000000010f718be4 chromedriver + 5856228\n",
      "13  chromedriver                        0x000000010f6ef946 chromedriver + 5687622\n",
      "14  chromedriver                        0x000000010f7195db chromedriver + 5858779\n",
      "15  chromedriver                        0x000000010f6de034 chromedriver + 5615668\n",
      "16  chromedriver                        0x000000010f73b378 chromedriver + 5997432\n",
      "17  chromedriver                        0x000000010f73b53f chromedriver + 5997887\n",
      "18  chromedriver                        0x000000010f74cff8 chromedriver + 6070264\n",
      "19  libsystem_pthread.dylib             0x00007ff80270d253 _pthread_start + 99\n",
      "20  libsystem_pthread.dylib             0x00007ff802708bef thread_start + 15\n",
      "\n",
      "Found 0 models on the overview page.\n",
      "Models metadata saved to models_metadata_scraped.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the OpenAI models overview page\n",
    "OVERVIEW_URL = \"https://platform.openai.com/docs/models\"\n",
    "\n",
    "def setup_driver():\n",
    "    \"\"\"Set up Selenium Chrome driver in headless mode.\"\"\"\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    return driver\n",
    "\n",
    "def fetch_dynamic_page(url, driver, wait_time=15):\n",
    "    \"\"\"Fetch a dynamically rendered page using Selenium.\"\"\"\n",
    "    driver.get(url)\n",
    "    # Scroll to bottom to force lazy-loading\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    try:\n",
    "        # Wait for an <a> tag in the sidebar that starts with /docs/models/\n",
    "        WebDriverWait(driver, wait_time).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"nav a[href^='/docs/models/']\"))\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"Timeout waiting for dynamic content:\", e)\n",
    "    time.sleep(2)  # Extra wait time\n",
    "    return driver.page_source\n",
    "\n",
    "def parse_overview_page(html):\n",
    "    \"\"\"Parse the overview page to extract model links based on side navigation.\"\"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    models = {}\n",
    "    \n",
    "    # First, try to find the navigation element that likely contains model links.\n",
    "    nav = soup.find(\"nav\")\n",
    "    if nav:\n",
    "        for a in nav.find_all(\"a\", href=True):\n",
    "            href = a[\"href\"]\n",
    "            if href.startswith(\"/docs/models/\"):\n",
    "                model_id = href.split(\"/\")[-1].strip()\n",
    "                if model_id:\n",
    "                    full_url = \"https://platform.openai.com\" + href\n",
    "                    models[model_id] = full_url\n",
    "    else:\n",
    "        # Fallback: search all <a> tags\n",
    "        for a in soup.find_all(\"a\", href=True):\n",
    "            href = a[\"href\"]\n",
    "            if \"/docs/models/\" in href:\n",
    "                model_id = href.split(\"/\")[-1].strip()\n",
    "                if model_id:\n",
    "                    full_url = \"https://platform.openai.com\" + href if href.startswith(\"/\") else href\n",
    "                    models[model_id] = full_url\n",
    "    return models\n",
    "\n",
    "def parse_model_page(html):\n",
    "    \"\"\"Parse an individual model page to extract metadata and pricing info.\"\"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    metadata = {\n",
    "        \"max_input_tokens\": \"TBD\",\n",
    "        \"max_output_tokens\": \"TBD\",\n",
    "        \"context_window\": \"TBD\",\n",
    "        \"description\": \"TBD\",\n",
    "        \"pricing\": \"TBD\"\n",
    "    }\n",
    "    \n",
    "    # Example: Extract description from a container with a specific class (adjust as needed)\n",
    "    desc_elem = soup.find(\"div\", class_=\"model-description\")\n",
    "    if desc_elem:\n",
    "        metadata[\"description\"] = desc_elem.get_text(separator=\" \", strip=True)\n",
    "    \n",
    "    # Use regex to extract token limits and pricing from the full page text\n",
    "    full_text = soup.get_text(separator=\" \", strip=True)\n",
    "    input_match = re.search(r\"Max Input Tokens:\\s*(\\d+)\", full_text)\n",
    "    output_match = re.search(r\"Max Output Tokens:\\s*(\\d+)\", full_text)\n",
    "    context_match = re.search(r\"Context Window:\\s*(\\d+)\", full_text)\n",
    "    pricing_match = re.search(r\"Pricing:\\s*([\\$\\d\\.]+)\", full_text)\n",
    "    \n",
    "    if input_match:\n",
    "        metadata[\"max_input_tokens\"] = int(input_match.group(1))\n",
    "    if output_match:\n",
    "        metadata[\"max_output_tokens\"] = int(output_match.group(1))\n",
    "    if context_match:\n",
    "        metadata[\"context_window\"] = int(context_match.group(1))\n",
    "    if pricing_match:\n",
    "        metadata[\"pricing\"] = pricing_match.group(1)\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "def scrape_all_models():\n",
    "    \"\"\"Scrape the OpenAI models overview page, then each model page for metadata.\"\"\"\n",
    "    driver = setup_driver()\n",
    "    overview_html = fetch_dynamic_page(OVERVIEW_URL, driver, wait_time=15)\n",
    "    models = parse_overview_page(overview_html)\n",
    "    print(f\"Found {len(models)} models on the overview page.\")\n",
    "    \n",
    "    models_metadata = {}\n",
    "    for model_id, model_url in models.items():\n",
    "        print(f\"Scraping metadata for {model_id} from {model_url}\")\n",
    "        model_html = fetch_dynamic_page(model_url, driver, wait_time=10)\n",
    "        if model_html:\n",
    "            metadata = parse_model_page(model_html)\n",
    "        else:\n",
    "            metadata = {\n",
    "                \"max_input_tokens\": \"TBD\",\n",
    "                \"max_output_tokens\": \"TBD\",\n",
    "                \"context_window\": \"TBD\",\n",
    "                \"description\": \"TBD\",\n",
    "                \"pricing\": \"TBD\"\n",
    "            }\n",
    "        models_metadata[model_id] = metadata\n",
    "    driver.quit()\n",
    "    return models_metadata\n",
    "\n",
    "def save_metadata(metadata, filename=\"models_metadata_scraped.json\"):\n",
    "    \"\"\"Save the scraped metadata to a JSON file.\"\"\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "    print(f\"Models metadata saved to {filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    metadata = scrape_all_models()\n",
    "    save_metadata(metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1769ad11-e125-425f-b4d0-219705f10905",
   "metadata": {},
   "source": [
    "Featured models\n",
    "https://platform.openai.com/docs/models/gpt-4.5-preview\n",
    "https://platform.openai.com/docs/models/o3-mini\n",
    "https://platform.openai.com/docs/models/gpt-4o\n",
    "\n",
    "Reasoning models \n",
    "o-series models that excel at complex, multi-step tasks.\n",
    "https://platform.openai.com/docs/models/o3-mini\n",
    "https://platform.openai.com/docs/models/o1\n",
    "https://platform.openai.com/docs/models/o1-mini\n",
    "https://platform.openai.com/docs/models/o1-pro\n",
    "\n",
    "Flagship chat models \n",
    "Our versatile, high-intelligence flagship models.\n",
    "https://platform.openai.com/docs/models/gpt-4.5-preview\n",
    "https://platform.openai.com/docs/models/gpt-4o-audio-preview\n",
    "https://platform.openai.com/docs/models/gpt-4o\n",
    "https://platform.openai.com/docs/models/chatgpt-4o-latest\n",
    "\n",
    "Cost-optimized models \n",
    "Smaller, faster models that cost less to run.\n",
    "https://platform.openai.com/docs/models/gpt-4o-mini\n",
    "https://platform.openai.com/docs/models/gpt-4o-mini-audio-preview\n",
    "\n",
    "Realtime models \n",
    "Models capable of realtime text and audio inputs and outputs.\n",
    "https://platform.openai.com/docs/models/gpt-4o-realtime-preview\n",
    "https://platform.openai.com/docs/models/gpt-4o-mini-realtime-preview\n",
    "\n",
    "Older GPT models \n",
    "Supported older versions of our general purpose and chat models.\n",
    "https://platform.openai.com/docs/models/gpt-4-turbo\n",
    "https://platform.openai.com/docs/models/gpt-4\n",
    "https://platform.openai.com/docs/models/gpt-3.5-turbo\n",
    "\n",
    "DALL·E\n",
    "Models that can generate and edit images, given a natural language prompt.\n",
    "https://platform.openai.com/docs/models/dall-e-3\n",
    "https://platform.openai.com/docs/models/dall-e-2\n",
    "\n",
    "Text-to-speech\n",
    "Models that can convert text into natural sounding spoken audio.\n",
    "https://platform.openai.com/docs/models/gpt-4o-mini-tts\n",
    "https://platform.openai.com/docs/models/tts-1-hd\n",
    "https://platform.openai.com/docs/models/tts-1\n",
    "\n",
    "Transcription\n",
    "Model that can transcribe and translate audio into text.\n",
    "https://platform.openai.com/docs/models/gpt-4o-transcribe\n",
    "https://platform.openai.com/docs/models/whisper-1\n",
    "https://platform.openai.com/docs/models/gpt-4o-mini-transcribe\n",
    "\n",
    "Embeddings\n",
    "A set of models that can convert text into vector representations.\n",
    "https://platform.openai.com/docs/models/text-embedding-3-small\n",
    "https://platform.openai.com/docs/models/text-embedding-ada-002\n",
    "https://platform.openai.com/docs/models/text-embedding-3-large\n",
    "\n",
    "Moderation\n",
    "Fine-tuned models that detect whether input may be sensitive or unsafe.\n",
    "https://platform.openai.com/docs/models/omni-moderation-latest\n",
    "https://platform.openai.com/docs/models/text-moderation-latest\n",
    "\n",
    "Tool-specific models\n",
    "Models to support specific built-in tools.\n",
    "https://platform.openai.com/docs/models/gpt-4o-search-preview\n",
    "https://platform.openai.com/docs/models/gpt-4o-mini-search-preview\n",
    "https://platform.openai.com/docs/models/computer-use-preview\n",
    "\n",
    "GPT base models\n",
    "Older models that aren't trained with instruction following.\n",
    "https://platform.openai.com/docs/models/babbage-002\n",
    "https://platform.openai.com/docs/models/davinci-002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268e79dc-9e56-4997-8cba-93b24080bebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355bd970-faa7-4608-98c6-c7e15f71b6b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
