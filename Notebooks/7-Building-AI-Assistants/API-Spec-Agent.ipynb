{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75f84369-3fa4-4ded-b25a-cf03b8c96cf5",
   "metadata": {},
   "source": [
    "Integrating an agent to dynamically retrieve and display model specifications from various AI providers' API documentation is an excellent approach to ensure up-to-date and comprehensive information. Here's how you can implement this:\n",
    "\n",
    "**1. Define the Agent's Responsibilities:**\n",
    "\n",
    "- **Fetch Model Lists:** Retrieve the current list of available models from each provider's API.\n",
    "\n",
    "- **Gather Model Specifications:** For each model, extract relevant details such as context window size, input/output token limits, supported modalities, and any other pertinent information.\n",
    "\n",
    "- **Update Local Database:** Maintain a local repository of these specifications to facilitate quick access and reduce redundant API calls.\n",
    "\n",
    "**2. Implementing the Agent:**\n",
    "\n",
    "You can create a Python script or module that performs the following tasks:\n",
    "\n",
    "- **API Endpoints:** Identify and utilize the appropriate API endpoints or documentation URLs for each provider. For example:\n",
    "\n",
    "  - **OpenAI:** Use the [Models API](https://platform.openai.com/docs/models) to list available models and their details.\n",
    "\n",
    "  - **Anthropic:** Refer to the [Models List API](https://docs.anthropic.com/en/api/models-list) for information on Claude models.\n",
    "\n",
    "  - **Google:** Access the [Vertex AI Model Garden](https://cloud.google.com/vertex-ai/docs/model-garden/overview) for details on available models.\n",
    "\n",
    "- **Data Extraction:** Parse the JSON responses or HTML content to extract model specifications.\n",
    "\n",
    "- **Database Update:** Store the extracted information in a structured format, such as a JSON or SQLite database, for easy retrieval.\n",
    "\n",
    "**3. Scheduling Regular Updates:**\n",
    "\n",
    "To ensure the information remains current, schedule the agent to run at regular intervals (e.g., daily or weekly) using a task scheduler like `cron` (Linux/macOS) or Task Scheduler (Windows).\n",
    "\n",
    "**4. Integrating with our Application:**\n",
    "\n",
    "Modify our Streamlit application to query this local database when displaying model information. This approach ensures that users always see the most recent data without incurring the latency of real-time API calls.\n",
    "\n",
    "**5. Handling API Changes:**\n",
    "\n",
    "Implement error handling and logging within the agent to detect and alert you to any changes in the API structures or endpoints, allowing for prompt updates to the agent's code.\n",
    "\n",
    "**6. Providing Fallback Information:**\n",
    "\n",
    "In cases where API access is limited or unavailable, consider maintaining a fallback dataset with basic model information to ensure continuous functionality.\n",
    "\n",
    "By implementing such an agent, you can automate the process of keeping our application's model specifications up-to-date, providing users with accurate and timely information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8007a4d9-f137-4060-8b9e-337db8710a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install requests\n",
    "#!pip install openai\n",
    "#!pip install anthropic\n",
    "#!pip install google-genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e136ecb-8b39-4642-9ab0-96eda802ba6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models list saved to models_list.json with a total count of: 93\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "def get_env_var(var: str):\n",
    "    \"\"\"Retrieve an environment variable; raises error if not found.\"\"\"\n",
    "    value = os.getenv(var)\n",
    "    if value is None:\n",
    "        raise ValueError(f\"{var} not found in environment variables. Ensure it is set in our .env file.\")\n",
    "    return value\n",
    "\n",
    "# Retrieve API keys from environment variables\n",
    "openai_api_key     = get_env_var(\"OPENAI_API_COURSE_KEY\")\n",
    "anthropic_api_key  = get_env_var(\"ANTHROPIC_API_KEY\")\n",
    "google_api_key     = get_env_var(\"GOOGLE_API_KEY\")\n",
    "xai_api_key        = get_env_var(\"XAI_API_KEY\")\n",
    "\n",
    "def get_openai_models(api_key):\n",
    "    url = \"https://api.openai.com/v1/models\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        if response.ok:\n",
    "            # Return only models starting with \"gpt-\"\n",
    "            return [m[\"id\"] for m in response.json().get(\"data\", []) if m[\"id\"].startswith(\"gpt-\")]\n",
    "        else:\n",
    "            print(\"Failed to retrieve OpenAI models:\", response.status_code, response.text)\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(\"Error retrieving OpenAI models:\", e)\n",
    "        return []\n",
    "\n",
    "def get_anthropic_models(api_key):\n",
    "    url = \"https://api.anthropic.com/v1/models\"\n",
    "    headers = {\n",
    "        \"x-api-key\": api_key,\n",
    "        \"anthropic-version\": \"2023-06-01\",  # Ensure this version matches our API documentation\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        if response.ok:\n",
    "            return [m[\"id\"] for m in response.json().get(\"data\", []) if m[\"id\"].startswith(\"claude\")]\n",
    "        else:\n",
    "            print(\"Failed to retrieve Anthropic models:\", response.status_code, response.text)\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(\"Error retrieving Anthropic models:\", e)\n",
    "        return []\n",
    "\n",
    "def get_google_models(api_key):\n",
    "    try:\n",
    "        client = genai.Client(api_key=api_key)\n",
    "        # Return model names (adjust if more details are needed)\n",
    "        return [model.name for model in client.models.list()]\n",
    "    except Exception as e:\n",
    "        print(\"Failed to retrieve Google models:\", e)\n",
    "        return []\n",
    "\n",
    "def get_grok_models(api_key):\n",
    "    url = \"https://api.x.ai/v1/models\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        models_data = response.json().get(\"data\", [])\n",
    "        return [model[\"id\"] for model in models_data if \"id\" in model]\n",
    "    except Exception as e:\n",
    "        print(\"Failed to retrieve Grok models:\", e)\n",
    "        return []\n",
    "\n",
    "# Fetch available models from each provider\n",
    "openai_models    = get_openai_models(openai_api_key)\n",
    "anthropic_models = get_anthropic_models(anthropic_api_key)\n",
    "google_models    = get_google_models(google_api_key)\n",
    "grok_models      = get_grok_models(xai_api_key)\n",
    "\n",
    "# Assuming 'all_models' is our dictionary containing the model data:\n",
    "all_models = {\n",
    "    \"openai\": openai_models,\n",
    "    \"anthropic\": anthropic_models,\n",
    "    \"google\": google_models,\n",
    "    \"grok\": grok_models\n",
    "}\n",
    "\n",
    "def count_total_models(models_dict):\n",
    "    \"\"\"Count the total number of models in the dictionary.\"\"\"\n",
    "    return sum(len(models) for models in models_dict.values())\n",
    "\n",
    "# Count models and add the total to the dictionary\n",
    "total_models = count_total_models(all_models)\n",
    "all_models[\"total_models\"] = total_models\n",
    "\n",
    "# Save the updated dictionary to models_list.json\n",
    "with open('models_list.json', 'w') as f:\n",
    "    json.dump(all_models, f, indent=4)\n",
    "\n",
    "print(\"Models list saved to models_list.json with a total count of:\", total_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afd9446e-a4d7-40bd-b3c2-d6f846c62fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying details for model: gpt-4o-mini-transcribe\n",
      "Model details:\n",
      "{\n",
      "    \"id\": \"gpt-4o-mini-transcribe\",\n",
      "    \"object\": \"model\",\n",
      "    \"created\": 1742068596,\n",
      "    \"owned_by\": \"system\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Get the first model from the OpenAI models list\n",
    "if openai_models:\n",
    "    first_model_id = openai_models[0]\n",
    "    print(\"Querying details for model:\", first_model_id)\n",
    "\n",
    "    # Build the URL for the model details endpoint\n",
    "    model_url = f\"https://api.openai.com/v1/models/{first_model_id}\"\n",
    "    headers = {\"Authorization\": f\"Bearer {openai_api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    # Query the model details\n",
    "    response = requests.get(model_url, headers=headers, timeout=10)\n",
    "    if response.ok:\n",
    "        model_details = response.json()\n",
    "        print(\"Model details:\")\n",
    "        print(json.dumps(model_details, indent=4))\n",
    "    else:\n",
    "        print(f\"Failed to retrieve model details: {response.status_code} {response.text}\")\n",
    "else:\n",
    "    print(\"No OpenAI models found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86f22080-8d5e-4b4b-a88f-994c2880244a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Anthropic Model Details ===\n",
      "{\n",
      "    \"type\": \"model\",\n",
      "    \"id\": \"claude-3-7-sonnet-20250219\",\n",
      "    \"display_name\": \"Claude 3.7 Sonnet\",\n",
      "    \"created_at\": \"2025-02-24T00:00:00Z\"\n",
      "}\n",
      "\n",
      "=== Google Model Details ===\n",
      "{\n",
      "    \"name\": \"models/chat-bison-001\",\n",
      "    \"description\": \"A legacy text-only model optimized for chat conversations\"\n",
      "}\n",
      "\n",
      "=== Grok Model Details ===\n",
      "{\n",
      "    \"id\": \"grok-2-1212\",\n",
      "    \"created\": 1737331200,\n",
      "    \"object\": \"model\",\n",
      "    \"owned_by\": \"xai\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "def get_env_var(var: str):\n",
    "    value = os.getenv(var)\n",
    "    if value is None:\n",
    "        raise ValueError(f\"{var} not found in environment variables. Ensure it is set in our .env file.\")\n",
    "    return value\n",
    "\n",
    "# Retrieve API keys\n",
    "openai_api_key     = get_env_var(\"OPENAI_API_COURSE_KEY\")\n",
    "anthropic_api_key  = get_env_var(\"ANTHROPIC_API_KEY\")\n",
    "google_api_key     = get_env_var(\"GOOGLE_API_KEY\")\n",
    "xai_api_key        = get_env_var(\"XAI_API_KEY\")\n",
    "\n",
    "# For Anthropic: Query details for the first Anthropic model in our list\n",
    "def query_anthropic_model_details(api_key, model_id):\n",
    "    url = f\"https://api.anthropic.com/v1/models/{model_id}\"\n",
    "    headers = {\n",
    "        \"x-api-key\": api_key,\n",
    "        \"anthropic-version\": \"2023-06-01\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        if response.ok:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"Failed to retrieve Anthropic model details: {response.status_code} {response.text}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(\"Error retrieving Anthropic model details:\", e)\n",
    "        return None\n",
    "\n",
    "# For Google: Try to get details using the GenAI client.\n",
    "# Note: The GenAI SDK might only return model names, so detailed metadata may not be available.\n",
    "def query_google_model_details(api_key, model_name):\n",
    "    try:\n",
    "        client = genai.Client(api_key=api_key)\n",
    "        # The GenAI client may not expose a dedicated \"get details\" method.\n",
    "        # Here we simply return the model object from the list that matches the name.\n",
    "        models = client.models.list()\n",
    "        for model in models:\n",
    "            if model.name == model_name:\n",
    "                # Print available attributes; the SDK might not provide much detail.\n",
    "                return {\"name\": model.name, \"description\": getattr(model, \"description\", \"No description provided\")}\n",
    "        print(\"Model not found in Google models list.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(\"Error retrieving Google model details:\", e)\n",
    "        return None\n",
    "\n",
    "# For Grok: Query details for a given Grok model.\n",
    "def query_grok_model_details(api_key, model_id):\n",
    "    url = f\"https://api.x.ai/v1/models/{model_id}\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        if response.ok:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"Failed to retrieve Grok model details: {response.status_code} {response.text}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(\"Error retrieving Grok model details:\", e)\n",
    "        return None\n",
    "\n",
    "# Example lists (normally these come from our listing functions)\n",
    "# For this example, assume we've already retrieved the lists:\n",
    "anthropic_models = [\"claude-3-7-sonnet-20250219\", \"claude-3-5-sonnet-20241022\", \"claude-3-5-haiku-20241022\"]\n",
    "google_models    = [\"models/chat-bison-001\", \"models/text-bison-001\"]  # using the model names as returned\n",
    "grok_models      = [\"grok-2-1212\", \"grok-2-vision-1212\"]\n",
    "\n",
    "# Query details for the first model from each provider\n",
    "print(\"=== Anthropic Model Details ===\")\n",
    "if anthropic_models:\n",
    "    anthro_details = query_anthropic_model_details(anthropic_api_key, anthropic_models[0])\n",
    "    print(json.dumps(anthro_details, indent=4))\n",
    "else:\n",
    "    print(\"No Anthropic models found.\")\n",
    "\n",
    "print(\"\\n=== Google Model Details ===\")\n",
    "if google_models:\n",
    "    google_details = query_google_model_details(google_api_key, google_models[0])\n",
    "    print(json.dumps(google_details, indent=4))\n",
    "else:\n",
    "    print(\"No Google models found.\")\n",
    "\n",
    "print(\"\\n=== Grok Model Details ===\")\n",
    "if grok_models:\n",
    "    grok_details = query_grok_model_details(xai_api_key, grok_models[0])\n",
    "    print(json.dumps(grok_details, indent=4))\n",
    "else:\n",
    "    print(\"No Grok models found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec626d71-531c-4b33-b7bb-9534327bc73a",
   "metadata": {},
   "source": [
    "Based on the responses we received:\n",
    "\n",
    "**Anthropic returns:**\n",
    "- **type:** The kind of object (in this case, a model)\n",
    "- **id:** The unique identifier for the model\n",
    "- **display_name:** A human-friendly name (e.g., \"Claude 3.7 Sonnet\")\n",
    "- **created_at:** A timestamp indicating when the model was created\n",
    "\n",
    "**Google (via the GenAI SDK) returns:**\n",
    "- **name:** The model’s identifier (including a path-like string, e.g., \"models/chat-bison-001\")\n",
    "- **description:** A brief description of the model (e.g., \"A legacy text-only model optimized for chat conversations\")\n",
    "\n",
    "**Grok (xAI) returns:**\n",
    "- **id:** The unique identifier for the model\n",
    "- **created:** A creation timestamp (in Unix time)\n",
    "- **object:** Typically indicating the object type (here, \"model\")\n",
    "- **owned_by:** The owner (e.g., \"xai\")\n",
    "\n",
    "**OpenAI returns:**\n",
    "- **id:** The unique identifier for the model (e.g., \"gpt-4o-mini-transcribe\")\n",
    "- **object:** The object type (typically \"model\")\n",
    "- **created:** The creation timestamp (in Unix time)\n",
    "- **owned_by:** The owner (which can be \"system\" or \"openai\")\n",
    "\n",
    "This consolidated view helps you compare the metadata available from each provider and determine what additional details you might need to supplement through internal configuration or documentation.\n",
    "\n",
    "**What Else Can Be Retrieved Automatically?**\n",
    "\n",
    "The information you can automatically retrieve depends on each provider’s API design. Here are some possibilities:\n",
    "\n",
    "1. **Basic Metadata:**  \n",
    "   Most endpoints return basic metadata like model IDs, creation timestamps, and sometimes a human-friendly name or description.\n",
    "\n",
    "2. **Permissions and Access Controls:**  \n",
    "   Some APIs may include fields indicating who can access or use a particular model (e.g., `\"owned_by\"` or `\"permissions\"` lists).\n",
    "\n",
    "3. **Status Information:**  \n",
    "   In some cases, the API might include information on the model’s current status or whether it’s in preview, beta, or fully released.\n",
    "\n",
    "4. **Versioning:**  \n",
    "   The response might contain version-related details (e.g., in the model ID or a dedicated version field).\n",
    "\n",
    "**What Isn’t Typically Retrieved Automatically?**\n",
    "\n",
    "Many technical details like:\n",
    "  \n",
    "- **Parameter Count or Model Size**\n",
    "- **Maximum Context Window (Input/Output Token Limits)**\n",
    "- **Supported Modalities (e.g., text, image, audio)**\n",
    "- **Latency or Performance Metrics**\n",
    "\n",
    "...are usually not provided in the basic listing endpoints. This extra information is often found in provider documentation or requires separate endpoints or manual configuration.\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "If you need more detailed technical specifications (like context window size or parameter counts), you may need to:\n",
    "  \n",
    "- **Reference the API Documentation:** Supplement the API response with data from official documentation.\n",
    "- **Create an Internal Repository:** Manually compile and maintain these details in our application (or use a scheduled process that parses documentation pages if available).\n",
    "\n",
    "This approach lets you combine automatically retrieved metadata with additional technical details necessary for our application's logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3c7b38-21b9-44c6-ac71-87fea82581b5",
   "metadata": {},
   "source": [
    "Based on OpenAI's official API documentation and the response we received, here's what we can automatically retrieve from the `/v1/models` endpoint for an OpenAI model:\n",
    "\n",
    "- **id:** The unique identifier for the model (e.g., `\"gpt-4o-mini-transcribe\"`).\n",
    "- **object:** The type of the returned object (typically `\"model\"`).\n",
    "- **created:** A Unix timestamp indicating when the model was created.\n",
    "- **owned_by:** Information about who owns the model (this might be `\"system\"` for system-managed models or `\"openai\"` for those managed by OpenAI).\n",
    "\n",
    "### What Else Might Be Available?\n",
    "\n",
    "When analyzing OpenAI's API information on their documentation page, you'll notice that the models endpoint intentionally returns only minimal metadata. Additional technical details like:\n",
    "\n",
    "- **Maximum Context Length (Input/Output Token Limits)**\n",
    "- **Parameter Count or Model Size**\n",
    "- **Supported Modalities (e.g., text, image, audio)**\n",
    "- **Performance Metrics or Latency Data**\n",
    "\n",
    "...are not included in the automatic API response. These details are typically found in the official documentation and not returned via the API itself.\n",
    "\n",
    "### Why Is This the Case?\n",
    "\n",
    "OpenAI’s design for the `/v1/models` endpoint is to provide a list of models and basic metadata. The assumption is that any deeper technical details (e.g., context window or parameter count) will be managed internally or referenced from their documentation. This means that if you need to display or utilize such details in our application, you’ll likely have to supplement the API response with internal configuration (such as our `MODEL_TOKEN_LIMITS` dictionary) or a manual update based on the latest documentation.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Review the Documentation:**  \n",
    "   Check OpenAI's API reference pages (such as [Models API](https://platform.openai.com/docs/api-reference/models)) for any additional details that might be documented but not exposed via the API.\n",
    "\n",
    "2. **Supplement Data:**  \n",
    "   If you need details like context window size or parameter count, consider maintaining an internal reference table (like our existing `MODEL_TOKEN_LIMITS` dictionary) or manually parsing their documentation.\n",
    "\n",
    "3. **Consider Future Endpoints:**  \n",
    "   Occasionally, APIs evolve. Keep an eye on OpenAI's announcements or API changelogs in case they decide to expose more metadata in the future.\n",
    "\n",
    "In summary, the automatically retrievable information from OpenAI's models endpoint is limited to basic metadata, and additional details must be supplemented by manual configuration or referenced from external documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11560ea-f81f-4279-931c-2fc08c40310f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "665943cd-8a28-4da2-bc66-6edade380cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model details:\n",
      "{\n",
      "    \"id\": \"gpt-4o-2024-05-13\",\n",
      "    \"object\": \"model\",\n",
      "    \"created\": 1715368132,\n",
      "    \"owned_by\": \"system\"\n",
      "}\n",
      "\n",
      "Debug/Rate Limiting Headers:\n",
      "{\n",
      "    \"openai-organization\": null,\n",
      "    \"openai-processing-ms\": \"105\",\n",
      "    \"openai-version\": \"2020-10-01\",\n",
      "    \"x-request-id\": \"2ac1c625553f3c3d339759af2ab56f08\",\n",
      "    \"x-ratelimit-limit-requests\": null,\n",
      "    \"x-ratelimit-limit-tokens\": null,\n",
      "    \"x-ratelimit-remaining-requests\": null,\n",
      "    \"x-ratelimit-remaining-tokens\": null,\n",
      "    \"x-ratelimit-reset-requests\": null,\n",
      "    \"x-ratelimit-reset-tokens\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "def get_env_var(var: str):\n",
    "    value = os.getenv(var)\n",
    "    if value is None:\n",
    "        raise ValueError(f\"{var} not found in environment variables.\")\n",
    "    return value\n",
    "\n",
    "openai_api_key = get_env_var(\"OPENAI_API_COURSE_KEY\")\n",
    "\n",
    "# Query details for a specific model\n",
    "model_id = \"gpt-4o-2024-05-13\"\n",
    "model_url = f\"https://api.openai.com/v1/models/{model_id}\"\n",
    "headers = {\"Authorization\": f\"Bearer {openai_api_key}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "response = requests.get(model_url, headers=headers, timeout=10)\n",
    "\n",
    "if response.ok:\n",
    "    model_details = response.json()\n",
    "    print(\"Model details:\")\n",
    "    print(json.dumps(model_details, indent=4))\n",
    "    \n",
    "    # Extract and print relevant headers for debugging and rate limiting\n",
    "    response_headers = response.headers\n",
    "    debug_info = {\n",
    "        \"openai-organization\": response_headers.get(\"openai-organization\"),\n",
    "        \"openai-processing-ms\": response_headers.get(\"openai-processing-ms\"),\n",
    "        \"openai-version\": response_headers.get(\"openai-version\"),\n",
    "        \"x-request-id\": response_headers.get(\"x-request-id\"),\n",
    "        \"x-ratelimit-limit-requests\": response_headers.get(\"x-ratelimit-limit-requests\"),\n",
    "        \"x-ratelimit-limit-tokens\": response_headers.get(\"x-ratelimit-limit-tokens\"),\n",
    "        \"x-ratelimit-remaining-requests\": response_headers.get(\"x-ratelimit-remaining-requests\"),\n",
    "        \"x-ratelimit-remaining-tokens\": response_headers.get(\"x-ratelimit-remaining-tokens\"),\n",
    "        \"x-ratelimit-reset-requests\": response_headers.get(\"x-ratelimit-reset-requests\"),\n",
    "        \"x-ratelimit-reset-tokens\": response_headers.get(\"x-ratelimit-reset-tokens\"),\n",
    "    }\n",
    "    print(\"\\nDebug/Rate Limiting Headers:\")\n",
    "    print(json.dumps(debug_info, indent=4))\n",
    "else:\n",
    "    print(f\"Failed to retrieve model details: {response.status_code} {response.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502466d1-59a7-42b9-bb0d-c660c823f9af",
   "metadata": {},
   "source": [
    "The response for the model `\"gpt-4o-2024-05-13\"` is very similar to the previous one in structure. Here’s what we can glean from it:\n",
    "\n",
    "- **Model Details:**\n",
    "  - **id:** `\"gpt-4o-2024-05-13\"`  \n",
    "    This uniquely identifies the model.\n",
    "  - **object:** `\"model\"`  \n",
    "    Indicates the type of the object returned.\n",
    "  - **created:** `1715368132`  \n",
    "    A Unix timestamp indicating when the model was created.\n",
    "  - **owned_by:** `\"system\"`  \n",
    "    Indicates that this model is managed by the system.\n",
    "\n",
    "- **Debug/Rate Limiting Headers:**\n",
    "  - **openai-processing-ms:** `\"105\"`  \n",
    "    Indicates that the API took 105 milliseconds to process the request.\n",
    "  - **openai-version:** `\"2020-10-01\"`  \n",
    "    Shows the API version used.\n",
    "  - **x-request-id:** `\"2ac1c625553f3c3d339759af2ab56f08\"`  \n",
    "    Provides a unique identifier for this API request, useful for debugging.\n",
    "  - **Rate Limiting Headers:**  \n",
    "    All related headers (like limits and remaining counts) are null, which is expected for this endpoint.\n",
    "\n",
    "### Why This Information Might Be Useful\n",
    "\n",
    "- **Request Identification & Debugging:**  \n",
    "  The `x-request-id` can help you trace and debug issues with API requests, particularly in production or when working with support teams.\n",
    "\n",
    "- **Performance Insights:**  \n",
    "  The `openai-processing-ms` value gives you an idea of the latency for the API call, which can be valuable for performance monitoring.\n",
    "\n",
    "- **API Versioning:**  \n",
    "  Knowing the `openai-version` ensures you are aware of which version of the API you are interacting with, which is crucial for compatibility.\n",
    "\n",
    "### Summary\n",
    "\n",
    "While the model details endpoint provides only minimal metadata, the accompanying HTTP headers give you valuable information for debugging and monitoring purposes. For deeper technical details (like maximum context window or model size), you would typically rely on OpenAI's documentation or internal configurations.\n",
    "\n",
    "If you need to automatically enrich our model information, you might combine these API responses with manually maintained data (like our `MODEL_TOKEN_LIMITS` dictionary) or use separate endpoints if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab3ef1b7-eabd-44fe-b478-8b2afc5cc24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading metadata from models_metadata.json: Expecting property name enclosed in double quotes: line 20 column 5 (char 684)\n",
      "Models list saved to models_list.json with a total count of: 93\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "def get_env_var(var: str):\n",
    "    \"\"\"Retrieve an environment variable; raises error if not found.\"\"\"\n",
    "    value = os.getenv(var)\n",
    "    if value is None:\n",
    "        raise ValueError(f\"{var} not found in environment variables. Ensure it is set in our .env file.\")\n",
    "    return value\n",
    "\n",
    "# Retrieve API keys from environment variables\n",
    "openai_api_key     = get_env_var(\"OPENAI_API_COURSE_KEY\")\n",
    "anthropic_api_key  = get_env_var(\"ANTHROPIC_API_KEY\")\n",
    "google_api_key     = get_env_var(\"GOOGLE_API_KEY\")\n",
    "xai_api_key        = get_env_var(\"XAI_API_KEY\")\n",
    "\n",
    "# Functions to dynamically list models from each provider\n",
    "def get_openai_models(api_key):\n",
    "    url = \"https://api.openai.com/v1/models\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        if response.ok:\n",
    "            return [m[\"id\"] for m in response.json().get(\"data\", []) if m[\"id\"].startswith(\"gpt-\")]\n",
    "        else:\n",
    "            print(\"Failed to retrieve OpenAI models:\", response.status_code, response.text)\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(\"Error retrieving OpenAI models:\", e)\n",
    "        return []\n",
    "\n",
    "def get_anthropic_models(api_key):\n",
    "    url = \"https://api.anthropic.com/v1/models\"\n",
    "    headers = {\n",
    "        \"x-api-key\": api_key,\n",
    "        \"anthropic-version\": \"2023-06-01\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        if response.ok:\n",
    "            return [m[\"id\"] for m in response.json().get(\"data\", []) if m[\"id\"].startswith(\"claude\")]\n",
    "        else:\n",
    "            print(\"Failed to retrieve Anthropic models:\", response.status_code, response.text)\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(\"Error retrieving Anthropic models:\", e)\n",
    "        return []\n",
    "\n",
    "def get_google_models(api_key):\n",
    "    try:\n",
    "        client = genai.Client(api_key=api_key)\n",
    "        return [model.name for model in client.models.list()]\n",
    "    except Exception as e:\n",
    "        print(\"Failed to retrieve Google models:\", e)\n",
    "        return []\n",
    "\n",
    "def get_grok_models(api_key):\n",
    "    url = \"https://api.x.ai/v1/models\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        models_data = response.json().get(\"data\", [])\n",
    "        return [model[\"id\"] for model in models_data if \"id\" in model]\n",
    "    except Exception as e:\n",
    "        print(\"Failed to retrieve Grok models:\", e)\n",
    "        return []\n",
    "\n",
    "# Load dynamic models from all providers\n",
    "openai_models    = get_openai_models(openai_api_key)\n",
    "anthropic_models = get_anthropic_models(anthropic_api_key)\n",
    "google_models    = get_google_models(google_api_key)\n",
    "grok_models      = get_grok_models(xai_api_key)\n",
    "\n",
    "dynamic_models = {\n",
    "    \"openai\": openai_models,\n",
    "    \"anthropic\": anthropic_models,\n",
    "    \"google\": google_models,\n",
    "    \"grok\": grok_models\n",
    "}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Load additional metadata from a JSON file (if available)\n",
    "# -----------------------------------------------------------------------------\n",
    "def load_models_metadata(filename=\"models_metadata.json\"):\n",
    "    if os.path.exists(filename):\n",
    "        try:\n",
    "            with open(filename, \"r\") as f:\n",
    "                return json.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading metadata from {filename}: {e}\")\n",
    "            return {}\n",
    "    else:\n",
    "        print(f\"{filename} not found. No additional metadata will be added.\")\n",
    "        return {}\n",
    "\n",
    "models_metadata = load_models_metadata(\"models_metadata.json\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Enrich dynamic models with metadata (if available)\n",
    "# -----------------------------------------------------------------------------\n",
    "def enrich_models(dynamic_models, metadata):\n",
    "    enriched = {}\n",
    "    for provider, models in dynamic_models.items():\n",
    "        enriched[provider] = []\n",
    "        for model in models:\n",
    "            model_metadata = metadata.get(model, {})  # Get metadata if exists; else empty dict\n",
    "            enriched[provider].append({\n",
    "                \"model_id\": model,\n",
    "                \"metadata\": model_metadata\n",
    "            })\n",
    "    return enriched\n",
    "\n",
    "enriched_models = enrich_models(dynamic_models, models_metadata)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Count total number of models and add to the dictionary\n",
    "# -----------------------------------------------------------------------------\n",
    "def count_total_models(models_dict):\n",
    "    return sum(len(models) for models in models_dict.values())\n",
    "\n",
    "total_models = count_total_models(dynamic_models)\n",
    "enriched_models[\"total_models\"] = total_models\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Save enriched models list to models_list.json\n",
    "# -----------------------------------------------------------------------------\n",
    "with open('models_list.json', 'w') as f:\n",
    "    json.dump(enriched_models, f, indent=4)\n",
    "\n",
    "print(\"Models list saved to models_list.json with a total count of:\", total_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bb11f82-bcfd-4de0-838f-3bef6d3e2b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching page: 403\n",
      "Scraped models metadata saved to models_metadata.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "\n",
    "# URL of the OpenAI models information page (example URL; update as needed)\n",
    "url = \"https://platform.openai.com/docs/api-reference/models\"\n",
    "\n",
    "# Fetch the page\n",
    "response = requests.get(url)\n",
    "if response.status_code != 200:\n",
    "    print(\"Error fetching page:\", response.status_code)\n",
    "    exit()\n",
    "\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Initialize a dictionary to store metadata for each model.\n",
    "# This is a draft approach; you will need to adjust the selectors based on the actual HTML.\n",
    "models_metadata = {}\n",
    "\n",
    "# Suppose that each model is described within a section with a specific CSS class.\n",
    "# (This is a placeholder selector; update according to the actual page.)\n",
    "model_sections = soup.find_all(\"div\", class_=\"model-section\")\n",
    "\n",
    "for section in model_sections:\n",
    "    # Attempt to extract the model ID/name from a heading.\n",
    "    model_id_elem = section.find(\"h2\")\n",
    "    if not model_id_elem:\n",
    "        continue\n",
    "    model_id = model_id_elem.text.strip()\n",
    "    \n",
    "    # Extract a description. For example, assume there's a <p> with class \"description\".\n",
    "    description_elem = section.find(\"p\", class_=\"description\")\n",
    "    description = description_elem.text.strip() if description_elem else \"TBD\"\n",
    "    \n",
    "    # Get the full text of the section to search for token limits\n",
    "    section_text = section.get_text()\n",
    "    \n",
    "    # Use regular expressions to look for token limits; adjust patterns as needed.\n",
    "    max_input_match = re.search(r\"Max Input Tokens:\\s*(\\d+)\", section_text)\n",
    "    max_output_match = re.search(r\"Max Output Tokens:\\s*(\\d+)\", section_text)\n",
    "    context_window_match = re.search(r\"Context Window:\\s*(\\d+)\", section_text)\n",
    "    \n",
    "    max_input_tokens = int(max_input_match.group(1)) if max_input_match else \"TBD\"\n",
    "    max_output_tokens = int(max_output_match.group(1)) if max_output_match else \"TBD\"\n",
    "    context_window = int(context_window_match.group(1)) if context_window_match else \"TBD\"\n",
    "    \n",
    "    models_metadata[model_id] = {\n",
    "        \"max_input_tokens\": max_input_tokens,\n",
    "        \"max_output_tokens\": max_output_tokens,\n",
    "        \"context_window\": context_window,\n",
    "        \"description\": description\n",
    "    }\n",
    "\n",
    "# For demonstration purposes, add a sample entry if no sections were found:\n",
    "if not models_metadata:\n",
    "    models_metadata = {\n",
    "        \"gpt-4\": {\n",
    "            \"max_input_tokens\": 8192,\n",
    "            \"max_output_tokens\": 8192,\n",
    "            \"context_window\": 8192,\n",
    "            \"description\": \"GPT-4: A large multimodal model capable of processing text and images. Input: text, images; Output: text.\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Save the metadata to models_metadata_scraped.json\n",
    "with open(\"models_metadata.json\", \"w\") as f:\n",
    "    json.dump(models_metadata, f, indent=4)\n",
    "\n",
    "print(\"Scraped models metadata saved to models_metadata.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c27a519-c2d1-421e-a525-616dc9402996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.29.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/Cellar/jupyterlab/4.3.5_1/libexec/lib/python3.13/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Downloading trio-0.29.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/opt/certifi/lib/python3.13/site-packages (from selenium) (2025.1.31)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/Cellar/jupyterlab/4.3.5_1/libexec/lib/python3.13/site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in /usr/local/Cellar/jupyterlab/4.3.5_1/libexec/lib/python3.13/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /usr/local/Cellar/jupyterlab/4.3.5_1/libexec/lib/python3.13/site-packages (from trio~=0.17->selenium) (25.1.0)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: idna in /usr/local/Cellar/jupyterlab/4.3.5_1/libexec/lib/python3.13/site-packages (from trio~=0.17->selenium) (3.10)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/Cellar/jupyterlab/4.3.5_1/libexec/lib/python3.13/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3,>=1.26->selenium)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/Cellar/jupyterlab/4.3.5_1/libexec/lib/python3.13/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Downloading selenium-4.29.0-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading trio-0.29.0-py3-none-any.whl (492 kB)\n",
      "Downloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Installing collected packages: sortedcontainers, wsproto, pysocks, outcome, trio, trio-websocket, selenium\n",
      "Successfully installed outcome-1.3.0.post0 pysocks-1.7.1 selenium-4.29.0 sortedcontainers-2.4.0 trio-0.29.0 trio-websocket-0.12.2 wsproto-1.2.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/usr/local/Cellar/jupyterlab/4.3.5_1/libexec/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4759932-988a-42ec-a446-3a41aeac95c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 models on the overview page.\n",
      "Models metadata saved to models_metadata_scraped.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL for the OpenAI models page\n",
    "OVERVIEW_URL = \"https://platform.openai.com/docs/models\"\n",
    "\n",
    "def fetch_dynamic_page(url):\n",
    "    # Configure Selenium to run in headless mode\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    # Set up the webdriver (make sure chromedriver is installed and in PATH)\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "    # Wait for the dynamic content to load (adjust sleep as needed)\n",
    "    time.sleep(5)\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    return html\n",
    "\n",
    "def parse_overview_page(html):\n",
    "    \"\"\"Parse the dynamically loaded overview page to extract model names and their URLs.\"\"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    models = {}\n",
    "    \n",
    "    # Inspect the page source (using our browser's developer tools) to find\n",
    "    # the appropriate selectors. For example, suppose model links are in <a> tags\n",
    "    # with a class \"model-link\":\n",
    "    for a in soup.find_all(\"a\", class_=\"model-link\", href=True):\n",
    "        href = a[\"href\"]\n",
    "        model_id = href.split(\"/\")[-1].strip()  # e.g., \"gpt-4\"\n",
    "        # Construct the full URL for the model page\n",
    "        model_url = \"https://platform.openai.com\" + href\n",
    "        models[model_id] = model_url\n",
    "    return models\n",
    "\n",
    "def parse_model_page(html):\n",
    "    \"\"\"Parse an individual model page to extract metadata and pricing info.\"\"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    metadata = {\n",
    "        \"max_input_tokens\": \"TBD\",\n",
    "        \"max_output_tokens\": \"TBD\",\n",
    "        \"context_window\": \"TBD\",\n",
    "        \"description\": \"TBD\",\n",
    "        \"pricing\": \"TBD\"\n",
    "    }\n",
    "    \n",
    "    # These selectors are examples. You will need to inspect the page and adjust:\n",
    "    desc_elem = soup.find(\"div\", class_=\"model-description\")\n",
    "    if desc_elem:\n",
    "        metadata[\"description\"] = desc_elem.get_text(separator=\" \", strip=True)\n",
    "    \n",
    "    full_text = soup.get_text(separator=\" \", strip=True)\n",
    "    # Use regex to find token limits and pricing if available\n",
    "    input_match = re.search(r\"Max Input Tokens:\\s*(\\d+)\", full_text)\n",
    "    output_match = re.search(r\"Max Output Tokens:\\s*(\\d+)\", full_text)\n",
    "    context_match = re.search(r\"Context Window:\\s*(\\d+)\", full_text)\n",
    "    pricing_match = re.search(r\"Pricing:\\s*([\\$\\d\\.]+)\", full_text)\n",
    "    \n",
    "    if input_match:\n",
    "        metadata[\"max_input_tokens\"] = int(input_match.group(1))\n",
    "    if output_match:\n",
    "        metadata[\"max_output_tokens\"] = int(output_match.group(1))\n",
    "    if context_match:\n",
    "        metadata[\"context_window\"] = int(context_match.group(1))\n",
    "    if pricing_match:\n",
    "        metadata[\"pricing\"] = pricing_match.group(1)\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "def scrape_all_models():\n",
    "    \"\"\"Scrape the OpenAI models overview page, then scrape each model page for metadata.\"\"\"\n",
    "    overview_html = fetch_dynamic_page(OVERVIEW_URL)\n",
    "    if not overview_html:\n",
    "        return {}\n",
    "    \n",
    "    models = parse_overview_page(overview_html)\n",
    "    print(f\"Found {len(models)} models on the overview page.\")\n",
    "    \n",
    "    models_metadata = {}\n",
    "    \n",
    "    for model_id, model_url in models.items():\n",
    "        print(f\"Scraping metadata for {model_id} from {model_url}\")\n",
    "        model_html = fetch_dynamic_page(model_url)\n",
    "        if model_html:\n",
    "            metadata = parse_model_page(model_html)\n",
    "        else:\n",
    "            metadata = {\n",
    "                \"max_input_tokens\": \"TBD\",\n",
    "                \"max_output_tokens\": \"TBD\",\n",
    "                \"context_window\": \"TBD\",\n",
    "                \"description\": \"TBD\",\n",
    "                \"pricing\": \"TBD\"\n",
    "            }\n",
    "        models_metadata[model_id] = metadata\n",
    "    \n",
    "    return models_metadata\n",
    "\n",
    "def save_metadata(metadata, filename=\"models_metadata_scraped.json\"):\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "    print(f\"Models metadata saved to {filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    metadata = scrape_all_models()\n",
    "    save_metadata(metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f94332bf-c369-4cd6-a9d8-ee9affc735e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout waiting for dynamic content: Message: \n",
      "Stacktrace:\n",
      "0   chromedriver                        0x0000000103315818 chromedriver + 6105112\n",
      "1   chromedriver                        0x000000010330d41a chromedriver + 6071322\n",
      "2   chromedriver                        0x0000000102da8600 chromedriver + 415232\n",
      "3   chromedriver                        0x0000000102dfa2c0 chromedriver + 750272\n",
      "4   chromedriver                        0x0000000102dfa511 chromedriver + 750865\n",
      "5   chromedriver                        0x0000000102e4a9c4 chromedriver + 1079748\n",
      "6   chromedriver                        0x0000000102e2063d chromedriver + 906813\n",
      "7   chromedriver                        0x0000000102e47c3d chromedriver + 1068093\n",
      "8   chromedriver                        0x0000000102e203e3 chromedriver + 906211\n",
      "9   chromedriver                        0x0000000102dec29a chromedriver + 692890\n",
      "10  chromedriver                        0x0000000102ded3f1 chromedriver + 697329\n",
      "11  chromedriver                        0x00000001032d4d10 chromedriver + 5840144\n",
      "12  chromedriver                        0x00000001032d8be4 chromedriver + 5856228\n",
      "13  chromedriver                        0x00000001032af946 chromedriver + 5687622\n",
      "14  chromedriver                        0x00000001032d95db chromedriver + 5858779\n",
      "15  chromedriver                        0x000000010329e034 chromedriver + 5615668\n",
      "16  chromedriver                        0x00000001032fb378 chromedriver + 5997432\n",
      "17  chromedriver                        0x00000001032fb53f chromedriver + 5997887\n",
      "18  chromedriver                        0x000000010330cff8 chromedriver + 6070264\n",
      "19  libsystem_pthread.dylib             0x00007ff80270d253 _pthread_start + 99\n",
      "20  libsystem_pthread.dylib             0x00007ff802708bef thread_start + 15\n",
      "\n",
      "Found 0 models on the overview page.\n",
      "Models metadata saved to models_metadata_scraped.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the OpenAI models overview page\n",
    "OVERVIEW_URL = \"https://platform.openai.com/docs/models\"\n",
    "\n",
    "def setup_driver():\n",
    "    \"\"\"Set up Selenium Chrome driver in headless mode.\"\"\"\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    # You may add further options if needed\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    return driver\n",
    "\n",
    "def fetch_dynamic_page(url, driver, wait_time=10):\n",
    "    \"\"\"Fetch a dynamically rendered page using Selenium and wait for model links.\"\"\"\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        # Wait for at least one <a> tag containing '/docs/models/' in href\n",
    "        WebDriverWait(driver, wait_time).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"a[href*='/docs/models/']\"))\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"Timeout waiting for dynamic content:\", e)\n",
    "    # Give an extra second for safety\n",
    "    time.sleep(1)\n",
    "    return driver.page_source\n",
    "\n",
    "def parse_overview_page(html):\n",
    "    \"\"\"Parse the overview page to extract model names and their URLs.\"\"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    models = {}\n",
    "    # Find all <a> tags whose href contains \"/docs/models/\"\n",
    "    for a in soup.find_all(\"a\", href=True):\n",
    "        href = a[\"href\"]\n",
    "        if \"/docs/models/\" in href:\n",
    "            parts = href.split(\"/\")\n",
    "            if len(parts) > 2:\n",
    "                model_id = parts[-1].strip()\n",
    "                # Filter out empty strings and duplicates\n",
    "                if model_id and model_id not in models:\n",
    "                    model_url = \"https://platform.openai.com\" + href\n",
    "                    models[model_id] = model_url\n",
    "    return models\n",
    "\n",
    "def parse_model_page(html):\n",
    "    \"\"\"Parse an individual model page to extract metadata and pricing info.\"\"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    metadata = {\n",
    "        \"max_input_tokens\": \"TBD\",\n",
    "        \"max_output_tokens\": \"TBD\",\n",
    "        \"context_window\": \"TBD\",\n",
    "        \"description\": \"TBD\",\n",
    "        \"pricing\": \"TBD\"\n",
    "    }\n",
    "    # Example: Try to extract description from a known container (adjust selector)\n",
    "    desc_elem = soup.find(\"div\", class_=\"model-description\")\n",
    "    if desc_elem:\n",
    "        metadata[\"description\"] = desc_elem.get_text(separator=\" \", strip=True)\n",
    "    \n",
    "    full_text = soup.get_text(separator=\" \", strip=True)\n",
    "    # Use regex to extract token limits and pricing\n",
    "    input_match = re.search(r\"Max Input Tokens:\\s*(\\d+)\", full_text)\n",
    "    output_match = re.search(r\"Max Output Tokens:\\s*(\\d+)\", full_text)\n",
    "    context_match = re.search(r\"Context Window:\\s*(\\d+)\", full_text)\n",
    "    pricing_match = re.search(r\"Pricing:\\s*([\\$\\d\\.]+)\", full_text)\n",
    "    \n",
    "    if input_match:\n",
    "        metadata[\"max_input_tokens\"] = int(input_match.group(1))\n",
    "    if output_match:\n",
    "        metadata[\"max_output_tokens\"] = int(output_match.group(1))\n",
    "    if context_match:\n",
    "        metadata[\"context_window\"] = int(context_match.group(1))\n",
    "    if pricing_match:\n",
    "        metadata[\"pricing\"] = pricing_match.group(1)\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "def scrape_all_models():\n",
    "    \"\"\"Scrape the OpenAI models overview page and then each model page for metadata.\"\"\"\n",
    "    driver = setup_driver()\n",
    "    overview_html = fetch_dynamic_page(OVERVIEW_URL, driver)\n",
    "    models = parse_overview_page(overview_html)\n",
    "    print(f\"Found {len(models)} models on the overview page.\")\n",
    "    \n",
    "    models_metadata = {}\n",
    "    for model_id, model_url in models.items():\n",
    "        print(f\"Scraping metadata for {model_id} from {model_url}\")\n",
    "        model_html = fetch_dynamic_page(model_url, driver)\n",
    "        if model_html:\n",
    "            metadata = parse_model_page(model_html)\n",
    "        else:\n",
    "            metadata = {\n",
    "                \"max_input_tokens\": \"TBD\",\n",
    "                \"max_output_tokens\": \"TBD\",\n",
    "                \"context_window\": \"TBD\",\n",
    "                \"description\": \"TBD\",\n",
    "                \"pricing\": \"TBD\"\n",
    "            }\n",
    "        models_metadata[model_id] = metadata\n",
    "    driver.quit()\n",
    "    return models_metadata\n",
    "\n",
    "def save_metadata(metadata, filename=\"models_metadata_scraped.json\"):\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "    print(f\"Models metadata saved to {filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    metadata = scrape_all_models()\n",
    "    save_metadata(metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d223470-3d41-4b38-ae6e-07eba0c03784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic page source saved to dynamic_page_source.html\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get(\"https://platform.openai.com/docs/models\")\n",
    "time.sleep(5)  # wait for dynamic content to load\n",
    "page_source = driver.page_source\n",
    "driver.quit()\n",
    "\n",
    "with open(\"dynamic_page_source.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(page_source)\n",
    "print(\"Dynamic page source saved to dynamic_page_source.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d41cd6c1-09d6-4f0a-bd37-d007f79d97d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch page: 403\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://platform.openai.com/docs/models\"\n",
    "response = requests.get(url)\n",
    "if response.ok:\n",
    "    with open(\"page_source.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(response.text)\n",
    "    print(\"Page source saved to page_source.html\")\n",
    "else:\n",
    "    print(\"Failed to fetch page:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87301e20-fb22-4db8-b594-1f8502834656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found models:\n",
      "{}\n",
      "Model links saved to openai_model_links.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def setup_driver():\n",
    "    \"\"\"Set up Selenium Chrome driver in headless mode.\"\"\"\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    return driver\n",
    "\n",
    "def fetch_dynamic_page(url, driver, wait_time=15):\n",
    "    \"\"\"Fetch a dynamically rendered page using Selenium.\"\"\"\n",
    "    driver.get(url)\n",
    "    # Optionally scroll to bottom to force lazy-loading content\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(wait_time)\n",
    "    return driver.page_source\n",
    "\n",
    "def find_model_links(html):\n",
    "    \"\"\"\n",
    "    Parse the overview page HTML and extract links that follow the pattern:\n",
    "    \"https://platform.openai.com/docs/models/<model_id>\"\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    model_links = {}\n",
    "    \n",
    "    # Loop through all <a> tags that have an href\n",
    "    for a in soup.find_all(\"a\", href=True):\n",
    "        href = a['href']\n",
    "        # Check if the link points to a model page. It might be a relative URL.\n",
    "        if href.startswith(\"/docs/models/\") or href.startswith(\"https://platform.openai.com/docs/models/\"):\n",
    "            # Construct full URL if needed\n",
    "            if href.startswith(\"/docs/models/\"):\n",
    "                full_url = \"https://platform.openai.com\" + href\n",
    "            else:\n",
    "                full_url = href\n",
    "            # Extract model id from the URL (the last part)\n",
    "            model_id = full_url.split(\"/\")[-1].strip()\n",
    "            if model_id and model_id not in model_links:\n",
    "                model_links[model_id] = full_url\n",
    "    return model_links\n",
    "\n",
    "def main():\n",
    "    overview_url = \"https://platform.openai.com/docs/models\"\n",
    "    driver = setup_driver()\n",
    "    html = fetch_dynamic_page(overview_url, driver, wait_time=15)\n",
    "    driver.quit()\n",
    "    \n",
    "    model_links = find_model_links(html)\n",
    "    print(\"Found models:\")\n",
    "    print(json.dumps(model_links, indent=4))\n",
    "    \n",
    "    # Save the model links to a JSON file\n",
    "    with open(\"openai_model_links.json\", \"w\") as f:\n",
    "        json.dump(model_links, f, indent=4)\n",
    "    print(\"Model links saved to openai_model_links.json\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b05e812-f064-4747-961c-ed3c0a11db99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout waiting for dynamic content: Message: \n",
      "Stacktrace:\n",
      "0   chromedriver                        0x000000010f755818 chromedriver + 6105112\n",
      "1   chromedriver                        0x000000010f74d41a chromedriver + 6071322\n",
      "2   chromedriver                        0x000000010f1e8600 chromedriver + 415232\n",
      "3   chromedriver                        0x000000010f23a2c0 chromedriver + 750272\n",
      "4   chromedriver                        0x000000010f23a511 chromedriver + 750865\n",
      "5   chromedriver                        0x000000010f28a9c4 chromedriver + 1079748\n",
      "6   chromedriver                        0x000000010f26063d chromedriver + 906813\n",
      "7   chromedriver                        0x000000010f287c3d chromedriver + 1068093\n",
      "8   chromedriver                        0x000000010f2603e3 chromedriver + 906211\n",
      "9   chromedriver                        0x000000010f22c29a chromedriver + 692890\n",
      "10  chromedriver                        0x000000010f22d3f1 chromedriver + 697329\n",
      "11  chromedriver                        0x000000010f714d10 chromedriver + 5840144\n",
      "12  chromedriver                        0x000000010f718be4 chromedriver + 5856228\n",
      "13  chromedriver                        0x000000010f6ef946 chromedriver + 5687622\n",
      "14  chromedriver                        0x000000010f7195db chromedriver + 5858779\n",
      "15  chromedriver                        0x000000010f6de034 chromedriver + 5615668\n",
      "16  chromedriver                        0x000000010f73b378 chromedriver + 5997432\n",
      "17  chromedriver                        0x000000010f73b53f chromedriver + 5997887\n",
      "18  chromedriver                        0x000000010f74cff8 chromedriver + 6070264\n",
      "19  libsystem_pthread.dylib             0x00007ff80270d253 _pthread_start + 99\n",
      "20  libsystem_pthread.dylib             0x00007ff802708bef thread_start + 15\n",
      "\n",
      "Found 0 models on the overview page.\n",
      "Models metadata saved to models_metadata_scraped.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the OpenAI models overview page\n",
    "OVERVIEW_URL = \"https://platform.openai.com/docs/models\"\n",
    "\n",
    "def setup_driver():\n",
    "    \"\"\"Set up Selenium Chrome driver in headless mode.\"\"\"\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    return driver\n",
    "\n",
    "def fetch_dynamic_page(url, driver, wait_time=15):\n",
    "    \"\"\"Fetch a dynamically rendered page using Selenium.\"\"\"\n",
    "    driver.get(url)\n",
    "    # Scroll to bottom to force lazy-loading\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    try:\n",
    "        # Wait for an <a> tag in the sidebar that starts with /docs/models/\n",
    "        WebDriverWait(driver, wait_time).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"nav a[href^='/docs/models/']\"))\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"Timeout waiting for dynamic content:\", e)\n",
    "    time.sleep(2)  # Extra wait time\n",
    "    return driver.page_source\n",
    "\n",
    "def parse_overview_page(html):\n",
    "    \"\"\"Parse the overview page to extract model links based on side navigation.\"\"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    models = {}\n",
    "    \n",
    "    # First, try to find the navigation element that likely contains model links.\n",
    "    nav = soup.find(\"nav\")\n",
    "    if nav:\n",
    "        for a in nav.find_all(\"a\", href=True):\n",
    "            href = a[\"href\"]\n",
    "            if href.startswith(\"/docs/models/\"):\n",
    "                model_id = href.split(\"/\")[-1].strip()\n",
    "                if model_id:\n",
    "                    full_url = \"https://platform.openai.com\" + href\n",
    "                    models[model_id] = full_url\n",
    "    else:\n",
    "        # Fallback: search all <a> tags\n",
    "        for a in soup.find_all(\"a\", href=True):\n",
    "            href = a[\"href\"]\n",
    "            if \"/docs/models/\" in href:\n",
    "                model_id = href.split(\"/\")[-1].strip()\n",
    "                if model_id:\n",
    "                    full_url = \"https://platform.openai.com\" + href if href.startswith(\"/\") else href\n",
    "                    models[model_id] = full_url\n",
    "    return models\n",
    "\n",
    "def parse_model_page(html):\n",
    "    \"\"\"Parse an individual model page to extract metadata and pricing info.\"\"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    metadata = {\n",
    "        \"max_input_tokens\": \"TBD\",\n",
    "        \"max_output_tokens\": \"TBD\",\n",
    "        \"context_window\": \"TBD\",\n",
    "        \"description\": \"TBD\",\n",
    "        \"pricing\": \"TBD\"\n",
    "    }\n",
    "    \n",
    "    # Example: Extract description from a container with a specific class (adjust as needed)\n",
    "    desc_elem = soup.find(\"div\", class_=\"model-description\")\n",
    "    if desc_elem:\n",
    "        metadata[\"description\"] = desc_elem.get_text(separator=\" \", strip=True)\n",
    "    \n",
    "    # Use regex to extract token limits and pricing from the full page text\n",
    "    full_text = soup.get_text(separator=\" \", strip=True)\n",
    "    input_match = re.search(r\"Max Input Tokens:\\s*(\\d+)\", full_text)\n",
    "    output_match = re.search(r\"Max Output Tokens:\\s*(\\d+)\", full_text)\n",
    "    context_match = re.search(r\"Context Window:\\s*(\\d+)\", full_text)\n",
    "    pricing_match = re.search(r\"Pricing:\\s*([\\$\\d\\.]+)\", full_text)\n",
    "    \n",
    "    if input_match:\n",
    "        metadata[\"max_input_tokens\"] = int(input_match.group(1))\n",
    "    if output_match:\n",
    "        metadata[\"max_output_tokens\"] = int(output_match.group(1))\n",
    "    if context_match:\n",
    "        metadata[\"context_window\"] = int(context_match.group(1))\n",
    "    if pricing_match:\n",
    "        metadata[\"pricing\"] = pricing_match.group(1)\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "def scrape_all_models():\n",
    "    \"\"\"Scrape the OpenAI models overview page, then each model page for metadata.\"\"\"\n",
    "    driver = setup_driver()\n",
    "    overview_html = fetch_dynamic_page(OVERVIEW_URL, driver, wait_time=15)\n",
    "    models = parse_overview_page(overview_html)\n",
    "    print(f\"Found {len(models)} models on the overview page.\")\n",
    "    \n",
    "    models_metadata = {}\n",
    "    for model_id, model_url in models.items():\n",
    "        print(f\"Scraping metadata for {model_id} from {model_url}\")\n",
    "        model_html = fetch_dynamic_page(model_url, driver, wait_time=10)\n",
    "        if model_html:\n",
    "            metadata = parse_model_page(model_html)\n",
    "        else:\n",
    "            metadata = {\n",
    "                \"max_input_tokens\": \"TBD\",\n",
    "                \"max_output_tokens\": \"TBD\",\n",
    "                \"context_window\": \"TBD\",\n",
    "                \"description\": \"TBD\",\n",
    "                \"pricing\": \"TBD\"\n",
    "            }\n",
    "        models_metadata[model_id] = metadata\n",
    "    driver.quit()\n",
    "    return models_metadata\n",
    "\n",
    "def save_metadata(metadata, filename=\"models_metadata_scraped.json\"):\n",
    "    \"\"\"Save the scraped metadata to a JSON file.\"\"\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "    print(f\"Models metadata saved to {filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    metadata = scrape_all_models()\n",
    "    save_metadata(metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1769ad11-e125-425f-b4d0-219705f10905",
   "metadata": {},
   "source": [
    "Featured models\n",
    "https://platform.openai.com/docs/models/gpt-4.5-preview\n",
    "https://platform.openai.com/docs/models/o3-mini\n",
    "https://platform.openai.com/docs/models/gpt-4o\n",
    "\n",
    "Reasoning models \n",
    "o-series models that excel at complex, multi-step tasks.\n",
    "https://platform.openai.com/docs/models/o3-mini\n",
    "https://platform.openai.com/docs/models/o1\n",
    "https://platform.openai.com/docs/models/o1-mini\n",
    "https://platform.openai.com/docs/models/o1-pro\n",
    "\n",
    "Flagship chat models \n",
    "Our versatile, high-intelligence flagship models.\n",
    "https://platform.openai.com/docs/models/gpt-4.5-preview\n",
    "https://platform.openai.com/docs/models/gpt-4o-audio-preview\n",
    "https://platform.openai.com/docs/models/gpt-4o\n",
    "https://platform.openai.com/docs/models/chatgpt-4o-latest\n",
    "\n",
    "Cost-optimized models \n",
    "Smaller, faster models that cost less to run.\n",
    "https://platform.openai.com/docs/models/gpt-4o-mini\n",
    "https://platform.openai.com/docs/models/gpt-4o-mini-audio-preview\n",
    "\n",
    "Realtime models \n",
    "Models capable of realtime text and audio inputs and outputs.\n",
    "https://platform.openai.com/docs/models/gpt-4o-realtime-preview\n",
    "https://platform.openai.com/docs/models/gpt-4o-mini-realtime-preview\n",
    "\n",
    "Older GPT models \n",
    "Supported older versions of our general purpose and chat models.\n",
    "https://platform.openai.com/docs/models/gpt-4-turbo\n",
    "https://platform.openai.com/docs/models/gpt-4\n",
    "https://platform.openai.com/docs/models/gpt-3.5-turbo\n",
    "\n",
    "DALL·E\n",
    "Models that can generate and edit images, given a natural language prompt.\n",
    "https://platform.openai.com/docs/models/dall-e-3\n",
    "https://platform.openai.com/docs/models/dall-e-2\n",
    "\n",
    "Text-to-speech\n",
    "Models that can convert text into natural sounding spoken audio.\n",
    "https://platform.openai.com/docs/models/gpt-4o-mini-tts\n",
    "https://platform.openai.com/docs/models/tts-1-hd\n",
    "https://platform.openai.com/docs/models/tts-1\n",
    "\n",
    "Transcription\n",
    "Model that can transcribe and translate audio into text.\n",
    "https://platform.openai.com/docs/models/gpt-4o-transcribe\n",
    "https://platform.openai.com/docs/models/whisper-1\n",
    "https://platform.openai.com/docs/models/gpt-4o-mini-transcribe\n",
    "\n",
    "Embeddings\n",
    "A set of models that can convert text into vector representations.\n",
    "https://platform.openai.com/docs/models/text-embedding-3-small\n",
    "https://platform.openai.com/docs/models/text-embedding-ada-002\n",
    "https://platform.openai.com/docs/models/text-embedding-3-large\n",
    "\n",
    "Moderation\n",
    "Fine-tuned models that detect whether input may be sensitive or unsafe.\n",
    "https://platform.openai.com/docs/models/omni-moderation-latest\n",
    "https://platform.openai.com/docs/models/text-moderation-latest\n",
    "\n",
    "Tool-specific models\n",
    "Models to support specific built-in tools.\n",
    "https://platform.openai.com/docs/models/gpt-4o-search-preview\n",
    "https://platform.openai.com/docs/models/gpt-4o-mini-search-preview\n",
    "https://platform.openai.com/docs/models/computer-use-preview\n",
    "\n",
    "GPT base models\n",
    "Older models that aren't trained with instruction following.\n",
    "https://platform.openai.com/docs/models/babbage-002\n",
    "https://platform.openai.com/docs/models/davinci-002"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8959b718-682f-49a8-80a0-f0f5b33b7401",
   "metadata": {},
   "source": [
    "Solid and scalable approach. Here's how we can organize and name things effectively for our **Streamlit application** and future multi-provider support:\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Recommended File Naming & Structure\n",
    "\n",
    "#### **For OpenAI models:**\n",
    "- ✅ **`openai_models_metadata.json`**\n",
    "  - Lowercase and snake_case is common for config files.\n",
    "  - Includes all model metadata related to OpenAI (GPT-4, GPT-4o, Whisper, TTS, DALL·E, etc).\n",
    "\n",
    "#### **For other providers:**\n",
    "Create **separate metadata files** per provider:\n",
    "- `anthropic_models_metadata.json`\n",
    "- `mistral_models_metadata.json`\n",
    "- `cohere_models_metadata.json`\n",
    "- `google_gemini_models_metadata.json`\n",
    "- `huggingface_models_metadata.json`\n",
    "\n",
    "> This keeps things modular, and easy to swap in/out or update independently.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Dynamically Loading Metadata in Streamlit\n",
    "\n",
    "In our `streamlit_app.py` or similar:\n",
    "\n",
    "```python\n",
    "import json\n",
    "\n",
    "def load_model_metadata(provider: str):\n",
    "    path = f\"metadata/{provider.lower()}_models_metadata.json\"\n",
    "    with open(path, \"r\") as file:\n",
    "        return json.load(file)\n",
    "\n",
    "# Example usage\n",
    "openai_metadata = load_model_metadata(\"openai\")\n",
    "```\n",
    "\n",
    "You can then filter/display models based on provider, use-case, speed, or price.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Future-Proofing Tips\n",
    "\n",
    "- Consider wrapping each provider's loader into its own module later (`providers/openai.py`, `providers/anthropic.py`, etc.).\n",
    "- Include a `provider` field in each model’s metadata for traceability when aggregating models from different files.\n",
    "- Optional: versioning with a `metadata_version` field.\n",
    "\n",
    "---\n",
    "\n",
    "Here's a modular, extensible `ModelMetadataLoader` class that supports dynamic loading of metadata across multiple LLM providers (OpenAI, Anthropic, etc.) and can easily plug into our **Streamlit** app or backend services.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Folder Structure Assumption\n",
    "\n",
    "```plaintext\n",
    "our_project/\n",
    "│\n",
    "├── metadata/\n",
    "│   ├── openai_models_metadata.json\n",
    "│   ├── anthropic_models_metadata.json\n",
    "│   └── ... more providers\n",
    "│\n",
    "├── loaders/\n",
    "│   └── model_metadata_loader.py\n",
    "│\n",
    "└── streamlit_app.py\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ `model_metadata_loader.py`\n",
    "\n",
    "```python\n",
    "import os\n",
    "import json\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "class ModelMetadataLoader:\n",
    "    def __init__(self, metadata_dir: str = \"metadata\"):\n",
    "        self.metadata_dir = metadata_dir\n",
    "        self._cache = {}\n",
    "\n",
    "    def load_provider(self, provider: str) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Load metadata for a specific provider (e.g., 'openai').\n",
    "        \"\"\"\n",
    "        provider = provider.lower()\n",
    "        if provider in self._cache:\n",
    "            return self._cache[provider]\n",
    "\n",
    "        file_path = os.path.join(self.metadata_dir, f\"{provider}_models_metadata.json\")\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"No metadata file found for provider: {provider}\")\n",
    "\n",
    "        with open(file_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Inject provider name for traceability\n",
    "        for model in data:\n",
    "            model[\"provider\"] = provider\n",
    "\n",
    "        self._cache[provider] = data\n",
    "        return data\n",
    "\n",
    "    def load_all(self) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Load all provider metadata files in the directory.\n",
    "        \"\"\"\n",
    "        all_models = []\n",
    "        for filename in os.listdir(self.metadata_dir):\n",
    "            if filename.endswith(\"_models_metadata.json\"):\n",
    "                provider = filename.split(\"_\")[0]\n",
    "                all_models.extend(self.load_provider(provider))\n",
    "        return all_models\n",
    "\n",
    "    def get_models_by_capability(\n",
    "        self,\n",
    "        capability: str,\n",
    "        provider: Optional[str] = None\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Filter models based on a capability (e.g., 'image_generation', 'text_to_speech').\n",
    "        \"\"\"\n",
    "        models = self.load_provider(provider) if provider else self.load_all()\n",
    "        return [model for model in models if capability in model.get(\"capabilities\", [])]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Example Usage in `streamlit_app.py`\n",
    "\n",
    "```python\n",
    "from loaders.model_metadata_loader import ModelMetadataLoader\n",
    "\n",
    "loader = ModelMetadataLoader()\n",
    "\n",
    "# Load OpenAI models only\n",
    "openai_models = loader.load_provider(\"openai\")\n",
    "\n",
    "# Load all models across providers\n",
    "all_models = loader.load_all()\n",
    "\n",
    "# Filter models by capability (assuming you added a \"capabilities\" field to our metadata)\n",
    "image_models = loader.get_models_by_capability(\"image_generation\")\n",
    "\n",
    "# In Streamlit\n",
    "import streamlit as st\n",
    "\n",
    "st.title(\"LLM Model Explorer\")\n",
    "\n",
    "selected_provider = st.selectbox(\"Choose a provider\", [\"openai\", \"anthropic\", \"mistral\"])\n",
    "models = loader.load_provider(selected_provider)\n",
    "\n",
    "for model in models:\n",
    "    st.subheader(model.get(\"name\", \"Unnamed model\"))\n",
    "    st.write(model)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Next Steps\n",
    "\n",
    "1. Make sure each model in our JSON has a `capabilities` list (e.g., `[\"text_completion\", \"image_generation\"]`).\n",
    "2. Optional: Add filters for speed, pricing, token limits, etc.\n",
    "3. Optional: Cache metadata with `streamlit.cache_data` for performance.\n",
    "\n",
    "Here’s a complete **starter metadata schema format** and a **JSON validator** script to ensure all our model metadata files are consistent and loadable across providers.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Suggested JSON Schema for LLM Model Metadata\n",
    "\n",
    "This schema helps define structure and validation rules for each model entry:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
    "  \"title\": \"LLM Model Metadata\",\n",
    "  \"type\": \"array\",\n",
    "  \"items\": {\n",
    "    \"type\": \"object\",\n",
    "    \"required\": [\"id\", \"name\", \"performance\", \"speed\", \"price\", \"input\", \"output\", \"modalities\", \"endpoints\"],\n",
    "    \"properties\": {\n",
    "      \"id\": { \"type\": \"string\" },\n",
    "      \"name\": { \"type\": \"string\" },\n",
    "      \"description\": { \"type\": \"string\" },\n",
    "      \"performance\": { \"type\": \"string\", \"enum\": [\"Low\", \"Average\", \"High\", \"Higher\"] },\n",
    "      \"speed\": { \"type\": \"string\", \"enum\": [\"Slowest\", \"Slow\", \"Medium\", \"Fast\", \"Very fast\"] },\n",
    "      \"price\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"input_per_million\": { \"type\": \"number\" },\n",
    "          \"output_per_million\": { \"type\": \"number\" },\n",
    "          \"audio_input_per_million\": { \"type\": \"number\" },\n",
    "          \"audio_output_per_million\": { \"type\": \"number\" }\n",
    "        },\n",
    "        \"additionalProperties\": false\n",
    "      },\n",
    "      \"input\": {\n",
    "        \"type\": \"array\",\n",
    "        \"items\": { \"type\": \"string\", \"enum\": [\"text\", \"image\", \"audio\"] }\n",
    "      },\n",
    "      \"output\": {\n",
    "        \"type\": \"array\",\n",
    "        \"items\": { \"type\": \"string\", \"enum\": [\"text\", \"image\", \"audio\"] }\n",
    "      },\n",
    "      \"capabilities\": {\n",
    "        \"type\": \"array\",\n",
    "        \"items\": {\n",
    "          \"type\": \"string\",\n",
    "          \"examples\": [\"text_completion\", \"image_generation\", \"speech_generation\", \"transcription\", \"translation\", \"moderation\"]\n",
    "        }\n",
    "      },\n",
    "      \"context_window\": { \"type\": \"integer\" },\n",
    "      \"max_output_tokens\": { \"type\": \"integer\" },\n",
    "      \"knowledge_cutoff\": { \"type\": \"string\", \"format\": \"date\" },\n",
    "      \"endpoints\": {\n",
    "        \"type\": \"array\",\n",
    "        \"items\": { \"type\": \"string\" }\n",
    "      },\n",
    "      \"features\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"streaming\": { \"type\": \"boolean\" },\n",
    "          \"function_calling\": { \"type\": \"boolean\" },\n",
    "          \"structured_outputs\": { \"type\": \"boolean\" },\n",
    "          \"fine_tuning\": { \"type\": \"boolean\" }\n",
    "        },\n",
    "        \"additionalProperties\": true\n",
    "      }\n",
    "    },\n",
    "    \"additionalProperties\": true\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "Save this schema file as:  \n",
    "`schemas/llm_model_schema.json`\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Validation Script\n",
    "\n",
    "Here’s a Python script to validate our `*_models_metadata.json` files using the schema above:\n",
    "\n",
    "```python\n",
    "import json\n",
    "import os\n",
    "from jsonschema import validate, ValidationError\n",
    "\n",
    "SCHEMA_PATH = \"schemas/llm_model_schema.json\"\n",
    "METADATA_DIR = \"metadata\"\n",
    "\n",
    "def load_schema(path: str):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def validate_metadata_file(file_path: str, schema: dict):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    try:\n",
    "        validate(instance=data, schema=schema)\n",
    "        print(f\"✅ {file_path} is valid.\")\n",
    "    except ValidationError as e:\n",
    "        print(f\"❌ Validation error in {file_path}:\\n{e.message}\")\n",
    "\n",
    "def run_all_validations():\n",
    "    schema = load_schema(SCHEMA_PATH)\n",
    "    for file in os.listdir(METADATA_DIR):\n",
    "        if file.endswith(\"_models_metadata.json\"):\n",
    "            full_path = os.path.join(METADATA_DIR, file)\n",
    "            validate_metadata_file(full_path, schema)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_all_validations()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🧪 Example JSON Entry (OpenAI)\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"gpt-4o\",\n",
    "  \"name\": \"GPT-4o\",\n",
    "  \"performance\": \"High\",\n",
    "  \"speed\": \"Medium\",\n",
    "  \"price\": {\n",
    "    \"input_per_million\": 2.5,\n",
    "    \"output_per_million\": 10.0\n",
    "  },\n",
    "  \"input\": [\"text\", \"image\"],\n",
    "  \"output\": [\"text\"],\n",
    "  \"capabilities\": [\"text_completion\", \"vision\", \"function_calling\"],\n",
    "  \"context_window\": 128000,\n",
    "  \"max_output_tokens\": 16384,\n",
    "  \"knowledge_cutoff\": \"2023-09-30\",\n",
    "  \"endpoints\": [\"v1/chat/completions\", \"v1/responses\"],\n",
    "  \"features\": {\n",
    "    \"streaming\": true,\n",
    "    \"function_calling\": true,\n",
    "    \"structured_outputs\": true,\n",
    "    \"fine_tuning\": false\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "A script to **merge all provider files** into one master `all_models_metadata.json` for display or analytics use?\n",
    "\n",
    "Here’s a complete Python script to **merge multiple LLM provider metadata files** (e.g., `openai_models_metadata.json`, `anthropic_models_metadata.json`, etc.) into a single `all_models_metadata.json` file.\n",
    "\n",
    "---\n",
    "\n",
    "## 🛠️ Script: `merge_model_metadata.py`\n",
    "\n",
    "```python\n",
    "import os\n",
    "import json\n",
    "\n",
    "METADATA_DIR = \"metadata\"\n",
    "OUTPUT_FILE = \"all_models_metadata.json\"\n",
    "\n",
    "def merge_metadata_files(directory: str, output_file: str):\n",
    "    merged_models = []\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\"_models_metadata.json\"):\n",
    "            path = os.path.join(directory, filename)\n",
    "            try:\n",
    "                with open(path, \"r\") as f:\n",
    "                    data = json.load(f)\n",
    "                    if isinstance(data, list):\n",
    "                        merged_models.extend(data)\n",
    "                    else:\n",
    "                        print(f\"⚠️ Skipping {filename} — expected a list of models.\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error reading {filename}: {e}\")\n",
    "\n",
    "    with open(output_file, \"w\") as out_file:\n",
    "        json.dump(merged_models, out_file, indent=2)\n",
    "        print(f\"✅ Merged {len(merged_models)} models into {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    merge_metadata_files(METADATA_DIR, OUTPUT_FILE)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Folder Structure\n",
    "\n",
    "Make sure our structure looks something like this:\n",
    "\n",
    "```\n",
    ".\n",
    "├── metadata/\n",
    "│   ├── openai_models_metadata.json\n",
    "│   ├── anthropic_models_metadata.json\n",
    "│   ├── google_models_metadata.json\n",
    "│   └── ... etc.\n",
    "├── schemas/\n",
    "│   └── llm_model_schema.json\n",
    "├── merge_model_metadata.py\n",
    "└── validate_model_metadata.py  # (Optional) if you used the earlier validator\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🧪 Optional: Tag Models by Provider (Advanced)\n",
    "\n",
    "If you'd like to keep track of the source provider, modify the script to add a `\"provider\"` field to each model:\n",
    "\n",
    "```python\n",
    "provider = filename.replace(\"_models_metadata.json\", \"\")\n",
    "for model in data:\n",
    "    model[\"provider\"] = provider\n",
    "```\n",
    "\n",
    "This would allow our Streamlit UI to dynamically group/filter models by provider.\n",
    "\n",
    "---\n",
    "\n",
    "Saving our file as `OpenAI_models_metadata.json` is a great naming convention—it’s explicit and keeps everything organized by provider.\n",
    "\n",
    "Given the structure and direction of our Streamlit app, here's a recommended setup:\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ File Naming Convention\n",
    "Keep one JSON file per provider:\n",
    "- `OpenAI_models_metadata.json`\n",
    "- `Anthropic_models_metadata.json`\n",
    "- `Google_models_metadata.json`\n",
    "- `XAI_models_metadata.json`\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Folder Organization\n",
    "Put them in a structured folder, like:\n",
    "\n",
    "```\n",
    "llm_metadata/\n",
    "├── OpenAI_models_metadata.json\n",
    "├── Anthropic_models_metadata.json\n",
    "├── Google_models_metadata.json\n",
    "└── XAI_models_metadata.json\n",
    "```\n",
    "\n",
    "Then load dynamically based on the selected provider:\n",
    "\n",
    "```python\n",
    "import json\n",
    "\n",
    "def load_model_metadata(provider: str):\n",
    "    filepath = f\"llm_metadata/{provider}_models_metadata.json\"\n",
    "    try:\n",
    "        with open(filepath, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        st.error(f\"Metadata file for {provider} not found.\")\n",
    "        return []\n",
    "```\n",
    "\n",
    "Use it like:\n",
    "\n",
    "```python\n",
    "if llm_provider == \"OpenAI Dynamic\":\n",
    "    metadata = load_model_metadata(\"OpenAI\")\n",
    "    # optionally use this metadata to display tooltips or categorize models\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Bonus: Enhance the Model Dropdown\n",
    "Use the metadata to show more helpful info in the dropdown (like pricing or capabilities):\n",
    "\n",
    "```python\n",
    "model_labels = [f\"{m['id']} — {m.get('price', 'n/a')} / {m.get('speed', 'n/a')}\" for m in metadata]\n",
    "selected_model = st.sidebar.selectbox(\"Choose Model\", model_labels)\n",
    "```\n",
    "\n",
    "```python\n",
    "\n",
    "# from utils.load_model_metadata import load_model_metadata\n",
    "\n",
    "# utils/load_model_metadata.py\n",
    "import json\n",
    "import os\n",
    "import streamlit as st\n",
    "\n",
    "def load_model_metadata(provider: str, folder: str = \"llm_metadata\"):\n",
    "    \"\"\"\n",
    "    Loads the model metadata JSON file for the specified provider.\n",
    "\n",
    "    Parameters:\n",
    "        provider (str): Provider name (e.g., 'OpenAI', 'Anthropic', 'Google', 'XAI')\n",
    "        folder (str): Path to the folder containing metadata files\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: Parsed JSON metadata or an empty list on error\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(folder, f\"{provider}_models_metadata.json\")\n",
    "    try:\n",
    "        with open(file_path, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        st.error(f\"Metadata file for {provider} not found at {file_path}.\")\n",
    "    except json.JSONDecodeError:\n",
    "        st.error(f\"Metadata file for {provider} is not valid JSON.\")\n",
    "    return []\n",
    "\n",
    "```\n",
    "\n",
    "you can now import this helper in our main Streamlit app like so:\n",
    "\n",
    "```python\n",
    "from utils.load_model_metadata import load_model_metadata\n",
    "```\n",
    "\n",
    "Then dynamically load models based on provider:\n",
    "\n",
    "```python\n",
    "if llm_provider == \"OpenAI Dynamic\":\n",
    "    openai_models_metadata = load_model_metadata(\"OpenAI\")\n",
    "    model_ids = [m[\"id\"] for m in openai_models_metadata]\n",
    "    selected_openai_model = st.sidebar.selectbox(\"Select an OpenAI Model\", model_ids)\n",
    "```\n",
    "\n",
    "Here's how you can **add filtering logic by capability** (like `chat-completions`, `realtime`, `embeddings`, etc.) using our `models_metadata.json` structure.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Step 1: Update `load_model_metadata.py`\n",
    "\n",
    "We'll add a `filter_models` function that supports filtering by **capability** (and optionally by **performance**, **price**, etc. later if desired):\n",
    "\n",
    "```python\n",
    "# utils/load_model_metadata.py\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "METADATA_PATH = os.path.join(os.path.dirname(__file__), \"../models_metadata.json\")\n",
    "\n",
    "def load_model_metadata(provider: str) -> list:\n",
    "    with open(METADATA_PATH, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return data.get(provider, [])\n",
    "\n",
    "def filter_models(metadata: list, capability: str = None) -> list:\n",
    "    \"\"\"\n",
    "    Filter the given model metadata by capability (e.g., chat-completions, realtime).\n",
    "    \"\"\"\n",
    "    if capability:\n",
    "        return [model for model in metadata if capability in model.get(\"capabilities\", [])]\n",
    "    return metadata\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Step 2: Use Filtering in our Streamlit App\n",
    "\n",
    "Now modify our `streamlit` code like this:\n",
    "\n",
    "```python\n",
    "from utils.load_model_metadata import load_model_metadata, filter_models\n",
    "\n",
    "# ...\n",
    "\n",
    "if llm_provider == \"OpenAI Dynamic\":\n",
    "    openai_models_metadata = load_model_metadata(\"OpenAI\")\n",
    "    filtered_openai_models = filter_models(openai_models_metadata, capability=\"chat-completions\")\n",
    "    model_ids = [m[\"id\"] for m in filtered_openai_models]\n",
    "    selected_openai_model = st.sidebar.selectbox(\"Select an OpenAI Model\", model_ids)\n",
    "```\n",
    "\n",
    "You can apply the same logic for other providers:\n",
    "\n",
    "```python\n",
    "if llm_provider == \"Anthropic Dynamic\":\n",
    "    anthropic_models_metadata = load_model_metadata(\"Anthropic\")\n",
    "    filtered_anthropic_models = filter_models(anthropic_models_metadata, capability=\"chat-completions\")\n",
    "    model_ids = [m[\"id\"] for m in filtered_anthropic_models]\n",
    "    selected_anthropic_model = st.sidebar.selectbox(\"Select an Anthropic Model\", model_ids)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Step 3 (Optional): Allow Dynamic Capability Selection via Sidebar\n",
    "\n",
    "You can let users pick a capability dynamically in the sidebar like this:\n",
    "\n",
    "```python\n",
    "capability_choice = st.sidebar.selectbox(\"Filter by Capability\", [\"chat-completions\", \"realtime\", \"embeddings\", \"speech\", \"transcription\"])\n",
    "```\n",
    "\n",
    "Then plug it into the `filter_models` call:\n",
    "\n",
    "```python\n",
    "filtered_openai_models = filter_models(openai_models_metadata, capability=capability_choice)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "We can add:\n",
    "\n",
    "- Capability-to-endpoint mapping  \n",
    "- Model details/metadata hover tooltips  \n",
    "- Multiple capabilities filtering (e.g., `chat-completions` **and** `realtime`)  \n",
    "- Or auto-recommender logic (e.g., pick best \"cheap + capable\" model)  \n",
    "\n",
    "\n",
    "here’s how we can integrate those features into our Streamlit app:\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 1. **Capability-to-Endpoint Mapping**\n",
    "Add a JSON or dictionary structure to our `models_metadata.json` (or in-memory dict) like:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"gpt-4o-mini-realtime-preview\": {\n",
    "    \"provider\": \"OpenAI\",\n",
    "    \"capabilities\": [\"chat-completions\", \"realtime\", \"audio\"],\n",
    "    \"endpoint\": \"v1/realtime\",\n",
    "    \"performance\": \"Average\",\n",
    "    \"speed\": \"Fast\",\n",
    "    \"price\": {\n",
    "      \"input_per_1M\": 0.15,\n",
    "      \"output_per_1M\": 0.60\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "This lets you dynamically map capabilities to endpoints for routing.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 2. **Model Metadata Hover Tooltips**\n",
    "Use Streamlit's `st.selectbox` with `format_func`:\n",
    "\n",
    "```python\n",
    "selected_model = st.selectbox(\n",
    "    \"Choose Model\",\n",
    "    models,\n",
    "    format_func=lambda m: f\"{m} — {metadata[m]['performance']} | {metadata[m]['price']['input_per_1M']}/M in\",\n",
    "    help=metadata[selected_model].get(\"description\", \"\")\n",
    ")\n",
    "```\n",
    "\n",
    "Or display a collapsible `st.expander()` with full metadata below the dropdown.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 3. **Multi-Capability Filtering**\n",
    "Add a multi-select filter above our model selector:\n",
    "\n",
    "```python\n",
    "capability_filter = st.multiselect(\n",
    "    \"Filter by Capabilities\",\n",
    "    [\"chat-completions\", \"realtime\", \"audio\", \"image\", \"embedding\"],\n",
    "    default=[\"chat-completions\"]\n",
    ")\n",
    "\n",
    "filtered_models = {\n",
    "    model: meta for model, meta in metadata.items()\n",
    "    if all(cap in meta[\"capabilities\"] for cap in capability_filter)\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 4. **Auto-Recommender Logic**\n",
    "Let users select an auto mode, or add a toggle:\n",
    "\n",
    "```python\n",
    "if st.checkbox(\"Auto-pick best (cheap + capable)\"):\n",
    "    def score_model(m):\n",
    "        price = m[\"price\"][\"input_per_1M\"] + m[\"price\"][\"output_per_1M\"]\n",
    "        perf = {\"High\": 3, \"Average\": 2, \"Low\": 1}.get(m[\"performance\"], 1)\n",
    "        return price / perf\n",
    "\n",
    "    best_model = min(filtered_models.items(), key=lambda x: score_model(x[1]))[0]\n",
    "    st.success(f\"Selected auto-recommended model: {best_model}\")\n",
    "    selected_model = best_model\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Let me know if you want me to plug this directly into our app and update our `models_metadata.json` format — I can help wire the whole thing up in a modular way!\n",
    "\n",
    "\n",
    "```python\n",
    "# ... all your imports and setup remain unchanged above auto-recommend mod\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Sidebar: Configuration Panel (Dynamic Providers Only)\n",
    "# -----------------------------------------------------------------------------\n",
    "st.sidebar.title(\"Configuration Panel\")\n",
    "\n",
    "llm_provider = st.sidebar.selectbox(\n",
    "    \"Choose LLM Provider\",\n",
    "    [\"OpenAI Dynamic\", \"Anthropic Dynamic\", \"Google Dynamic\", \"XAI Dynamic\"],\n",
    "    help=\"Select the LLM provider.\"\n",
    ")\n",
    "\n",
    "auto_recommend = st.sidebar.toggle(\"Auto-Recommend Best Model\", value=True, help=\"Automatically choose the cheapest capable model\")\n",
    "\n",
    "user_persona = st.sidebar.text_input(\"User Persona\", \"General User\", help=\"User's role/identity.\")\n",
    "system_persona = st.sidebar.text_input(\"System Persona\", \"AI Assistant\", help=\"AI assistant's persona.\")\n",
    "\n",
    "response_length = st.sidebar.radio(\"Response Length\", list(LENGTH_PRESETS.keys()), help=\"Select a preset controlling response detail.\")\n",
    "preset = LENGTH_PRESETS[response_length]\n",
    "temperature_slider = st.sidebar.slider(\"Temperature (Creativity)\", 0.0, 1.0, preset[\"temperature\"], 0.1)\n",
    "max_tokens_slider = st.sidebar.slider(\"Max Output Tokens\", 50, 4096, preset[\"max_tokens\"], 50)\n",
    "top_p_slider = st.sidebar.slider(\"Top-p (Nucleus Sampling)\", 0.0, 1.0, preset[\"top_p\"], 0.05)\n",
    "top_k_slider = st.sidebar.slider(\"Top-k\", 0, 200, preset[\"top_k\"], 5)\n",
    "llm_params = {\"temperature\": temperature_slider, \"max_tokens\": max_tokens_slider, \"top_p\": top_p_slider, \"top_k\": top_k_slider}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Dynamic model dropdowns with auto-recommend logic (OpenAI example shown)\n",
    "# -----------------------------------------------------------------------------\n",
    "from llm_model_utils import load_model_metadata, auto_recommend_model, render_model_dropdown, display_model_details\n",
    "\n",
    "if llm_provider == \"OpenAI Dynamic\":\n",
    "    metadata = load_model_metadata(\"OpenAI_models_metadata.json\")\n",
    "    if auto_recommend:\n",
    "        selected_openai_model, _ = auto_recommend_model(metadata, capabilities=[\"chat-completions\"])\n",
    "        st.sidebar.success(f\"Auto-selected: {selected_openai_model}\")\n",
    "    else:\n",
    "        selected_openai_model = render_model_dropdown(metadata)\n",
    "    display_model_details(metadata, selected_openai_model)\n",
    "\n",
    "# Repeat similar logic for Anthropic, Google, XAI if needed\n",
    "\n",
    "# ... rest of your code remains unchanged below\n",
    "\n",
    "```\n",
    "\n",
    "✅ We've added a modular `auto_recommend` toggle to our Streamlit sidebar and structured the logic so you can use it across different providers. Here's what’s included:\n",
    "\n",
    "- `auto_recommend` toggle in sidebar.\n",
    "- Support for loading from `OpenAI_models_metadata.json`.\n",
    "- Automatic selection of the best “cheap + capable” model if toggle is on.\n",
    "- Manual dropdown + model detail hover if toggle is off.\n",
    "\n",
    "Let me know if you want the supporting `llm_model_utils.py` utility file for `load_model_metadata`, `auto_recommend_model`, `render_model_dropdown`, and `display_model_details`.\n",
    "\n",
    "✅ Modular utilities added:\n",
    "\n",
    "- `load_model_metadata`: Load JSON model metadata for a provider  \n",
    "- `auto_recommend_model`: Recommend best model using performance + price  \n",
    "- `render_model_dropdown`: Render dropdown with tooltip/caption  \n",
    "- `display_model_details`: Optional, show full metadata under UI  \n",
    "\n",
    "Next, we’ll:\n",
    "1. Add a toggle in the sidebar to enable Auto-Recommend.\n",
    "2. Use these utilities to control model selection behavior based on that toggle.\n",
    "\n",
    "Would you like that plugged into `\"OpenAI Dynamic\"` first as the working example?\n",
    "\n",
    "\n",
    "✅ Auto-recommend mode has been added! You’ll now see a toggle in the sidebar labeled **\"🧠 Auto-Recommend Best Model\"**. When enabled:\n",
    "\n",
    "- It analyzes your selected provider’s metadata (like performance and cost).\n",
    "- Picks the best model that supports `chat-completions`.\n",
    "- Displays details with hover tooltips and expandable metadata for context.\n",
    "\n",
    "Let me know if you'd like to add multi-capability filtering (e.g. both `chat-completions` and `realtime`) or extend this logic to other providers next!\n",
    "\n",
    "\n",
    "```python\n",
    "# --- insert this near top ---\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# --- utility to load model metadata ---\n",
    "@st.cache_data(show_spinner=False)\n",
    "def load_model_metadata(provider: str) -> List[Dict[str, Any]]:\n",
    "    file_path = f\"{provider.lower()}_models_metadata.json\"\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    else:\n",
    "        st.warning(f\"Metadata file not found: {file_path}\")\n",
    "        return []\n",
    "\n",
    "# --- utility to recommend best model ---\n",
    "def auto_recommend_model(metadata: List[Dict[str, Any]], capabilities: List[str]) -> str:\n",
    "    def score(model):\n",
    "        perf = model.get(\"performance\", \"Average\")\n",
    "        price = model.get(\"pricing\", {}).get(\"output\", 100.0)\n",
    "        score_map = {\"Higher\": 3, \"High\": 2, \"Average\": 1, \"Low\": 0}\n",
    "        score = score_map.get(perf, 0) - price  # reward perf, penalize cost\n",
    "        if all(cap in model.get(\"capabilities\", []) for cap in capabilities):\n",
    "            return score\n",
    "        return -float(\"inf\")\n",
    "\n",
    "    best = max(metadata, key=score, default={})\n",
    "    return best.get(\"id\", \"\")\n",
    "\n",
    "# --- utility to render dropdown with hover tooltips ---\n",
    "def render_model_dropdown(label: str, models: List[Dict[str, Any]], default_id: str = \"\") -> str:\n",
    "    options = {model[\"id\"]: model for model in models}\n",
    "    selected_id = st.selectbox(\n",
    "        label,\n",
    "        options=list(options.keys()),\n",
    "        index=list(options.keys()).index(default_id) if default_id in options else 0,\n",
    "        format_func=lambda mid: f\"{mid} (⚙️ {options[mid].get('performance', 'N/A')})\"\n",
    "    )\n",
    "    if selected_id:\n",
    "        meta = options[selected_id]\n",
    "        with st.expander(\"Model Details\"):\n",
    "            st.markdown(f\"**Model ID:** `{selected_id}`\")\n",
    "            for k, v in meta.items():\n",
    "                if isinstance(v, dict):\n",
    "                    st.json(v)\n",
    "                else:\n",
    "                    st.write(f\"**{k.title()}**: {v}\")\n",
    "    return selected_id\n",
    "\n",
    "# --- insert this into sidebar ---\n",
    "st.sidebar.markdown(\"---\")\n",
    "auto_mode = st.sidebar.toggle(\"🧠 Auto-Recommend Best Model\", value=False)\n",
    "\n",
    "# --- update OpenAI section ---\n",
    "if llm_provider == \"OpenAI Dynamic\":\n",
    "    openai_metadata = load_model_metadata(\"OpenAI\")\n",
    "    if auto_mode:\n",
    "        selected_openai_model = auto_recommend_model(openai_metadata, [\"chat-completions\"])\n",
    "        st.sidebar.success(f\"Auto-picked model: {selected_openai_model}\")\n",
    "    selected_openai_model = render_model_dropdown(\"Select an OpenAI Model\", openai_metadata, selected_openai_model or \"gpt-4\")\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355bd970-faa7-4608-98c6-c7e15f71b6b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
