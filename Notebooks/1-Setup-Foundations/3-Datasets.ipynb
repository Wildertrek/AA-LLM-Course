{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29d46864-bcc7-481c-a060-3fe65a9461e5",
   "metadata": {},
   "source": [
    "## Open-Source & Open-Access Healthcare Datasets (Curated)\n",
    "\n",
    "| Dataset Name                                           | Link                                                                                                                                   | Description                                                                                                                                                        |\n",
    "| ------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n",
    "| **MIMIC-IV**                                           | [https://physionet.org/content/mimiciv/](https://physionet.org/content/mimiciv/)                                                       | Large, de-identified ICU dataset (2008–2019) including vitals, labs, meds, procedures, diagnoses, and clinical notes; gold standard for critical-care ML research. |\n",
    "| **eICU Collaborative Research Database**               | [https://physionet.org/content/eicu-crd/](https://physionet.org/content/eicu-crd/)                                                     | Multi-center ICU dataset covering 200k+ patient stays across 200+ hospitals; ideal for comparative ICU outcomes and treatment effectiveness studies.               |\n",
    "| **NIH Chest X-ray Dataset**                            | [https://www.kaggle.com/datasets/nih-chest-xrays/data](https://www.kaggle.com/datasets/nih-chest-xrays/data)                           | 100k+ labeled chest X-ray images across 14 thoracic disease categories; widely used for medical imaging and diagnostic AI.                                         |\n",
    "| **The Cancer Genome Atlas (TCGA)**                     | [https://www.cancer.gov/ccg/research/genome-sequencing/tcga](https://www.cancer.gov/ccg/research/genome-sequencing/tcga)               | Comprehensive multi-omics cancer dataset (33 cancer types, 20k+ samples) enabling biomarker discovery and precision oncology research.                             |\n",
    "| **UK Biobank**                                         | [https://www.ukbiobank.ac.uk/](https://www.ukbiobank.ac.uk/)                                                                           | Longitudinal biomedical dataset of ~500k participants combining genetics, imaging, clinical records, and lifestyle data.                                           |\n",
    "| **PhysioNet**                                          | [https://physionet.org/](https://physionet.org/)                                                                                       | Open repository of physiological signals (ECG, EEG, ICU waveforms, wearables); foundational for biomedical signal processing and monitoring research.              |\n",
    "| **Human Connectome Project (HCP)**                     | [https://www.humanconnectome.org/](https://www.humanconnectome.org/)                                                                   | High-resolution MRI/fMRI datasets mapping human brain connectivity; critical for neuroscience and brain-network analysis.                                          |\n",
    "| **BioASQ**                                             | [http://bioasq.org/](http://bioasq.org/)                                                                                               | Biomedical NLP dataset with PubMed articles, expert-curated QA pairs, and semantic indexing labels; core resource for medical QA systems.                          |\n",
    "| **COVID-19 Open Research Dataset (CORD-19)**           | [https://allenai.org/data/cord-19](https://allenai.org/data/cord-19)                                                                   | Large corpus of COVID-19-related scientific literature released by Allen Institute; benchmark dataset for biomedical text mining and NLP.                          |\n",
    "| **OpenNeuro**                                          | [https://openneuro.org/](https://openneuro.org/)                                                                                       | Open platform for neuroimaging datasets (fMRI, MRI, EEG, MEG, PET) following BIDS standards; supports reproducible neuroscience research.                          |\n",
    "| **HCUP (Healthcare Cost and Utilization Project)**     | [https://www.hcup-us.ahrq.gov/](https://www.hcup-us.ahrq.gov/)                                                                         | U.S. hospital utilization and cost databases (NIS, SID, KID, etc.) used for health services research and policy analysis.                                          |\n",
    "| **National Sleep Research Resource (NSRR)**            | [https://sleepdata.org/](https://sleepdata.org/)                                                                                       | Repository of polysomnography and sleep health data enabling research on sleep disorders, circadian rhythms, and cardiovascular outcomes.                          |\n",
    "| **CheXpert**                                           | [https://stanfordmlgroup.github.io/competitions/chexpert/](https://stanfordmlgroup.github.io/competitions/chexpert/)                   | 220k+ chest X-ray images with expert labels and uncertainty annotations; benchmark dataset for radiology AI.                                                       |\n",
    "| **OMOP Common Data Model (OHDSI)**                     | [https://www.ohdsi.org/data-standardization/the-common-data-model/](https://www.ohdsi.org/data-standardization/the-common-data-model/) | Standardized schema and vocabulary enabling federated observational health studies across institutions.                                                            |\n",
    "| **gnomAD**                                             | [https://gnomad.broadinstitute.org/](https://gnomad.broadinstitute.org/)                                                               | Aggregated population genomics database providing allele frequencies and variant annotations for rare disease and precision medicine.                              |\n",
    "| **ADNI (Alzheimer’s Disease Neuroimaging Initiative)** | [https://adni.loni.usc.edu/](https://adni.loni.usc.edu/)                                                                               | Longitudinal neuroimaging, biomarker, and cognitive data for Alzheimer’s disease research and progression modeling.                                                |\n",
    "| **All of Us Research Program**                         | [https://allofus.nih.gov/](https://allofus.nih.gov/)                                                                                   | NIH precision-medicine dataset with EHRs, genomics, surveys, and wearable data from a diverse U.S. cohort.                                                         |\n",
    "| **DeepLesion**                                         | [https://nihcc.app.box.com/v/DeepLesion](https://nihcc.app.box.com/v/DeepLesion)                                                       | Large CT imaging dataset with bounding-box-annotated lesions across organs; designed for universal lesion detection models.                                        |\n",
    "\n",
    "---\n",
    "\n",
    "## Blunt Assessment \n",
    "\n",
    "* **MIMIC-IV, PhysioNet, TCGA, UK Biobank, gnomAD, and OMOP** are *infrastructure-grade datasets* — they underpin serious, publishable research.\n",
    "* **CheXpert, NIH Chest X-ray, DeepLesion, OpenNeuro, HCP** dominate **medical imaging and neuro-AI** benchmarks.\n",
    "* **BioASQ and CORD-19** are essential for **biomedical NLP**, not clinical decision systems.\n",
    "* **HCUP and All of Us** matter most for **policy, population health, and outcomes modeling**.\n",
    "* Most datasets **require data use agreements** — “open” does not mean frictionless.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bd911a-8670-4fb9-b780-e0e310f638fc",
   "metadata": {},
   "source": [
    "## Unified Healthcare Dataset Decision Table\n",
    "\n",
    "*(Optimized for GenAI, AI Assistants, and Agentic Systems)*\n",
    "\n",
    "**Legend**\n",
    "\n",
    "* **GenAI Suitability**\n",
    "\n",
    "  * ⭐⭐⭐ = Strong fit for Assistants / Agents / RAG\n",
    "  * ⭐⭐ = Conditional / supporting role\n",
    "  * ⭐ = Poor fit (benchmarks only)\n",
    "* **Fed / IRB**\n",
    "\n",
    "  * ✅ = Commonly approved / production-adjacent\n",
    "  * ⚠️ = Restricted / research-only / DUA-heavy\n",
    "  * ❌ = Not suitable beyond experimentation\n",
    "\n",
    "---\n",
    "\n",
    "### Master Table\n",
    "\n",
    "| Dataset              | Primary Modality   | AI Use-Cases                    | GenAI / Agent Suitability | Fed / IRB | Recommendation                                                                                          |\n",
    "| -------------------- | ------------------ | ------------------------------- | ------------------------- | --------- | ------------------------------------------------------------------------------------------------------- |\n",
    "| **MIMIC-IV**         | EHR + Notes        | Prediction, NLP, RAG            | ⭐⭐⭐                       | ✅         | **Top-tier dataset for clinical AI assistants** (care summaries, risk reasoning, note-grounded agents). |\n",
    "| **eICU**             | EHR                | Prediction, cohort analysis     | ⭐⭐                        | ✅         | Strong for **predictive agents**, weaker for conversational GenAI due to limited notes.                 |\n",
    "| **PhysioNet**        | Signals            | Prediction, signal ML           | ⭐⭐                        | ✅         | Excellent **agent signal input**, not a standalone conversational corpus.                               |\n",
    "| **TCGA**             | Genomics           | Prediction, biomarker discovery | ⭐⭐                        | ✅         | Good for **expert agents** (oncology/genomics), not general assistants.                                 |\n",
    "| **HCUP**             | EHR / Claims       | Prediction, policy analysis     | ⭐⭐                        | ✅         | Best for **policy, utilization, and cost-analysis agents**, not clinical chat.                          |\n",
    "| **OMOP CDM**         | Data Model         | RAG (schema), Prediction        | ⭐⭐⭐                       | ✅         | **Foundational for GenAI at scale** — enables interoperable, governed assistants.                       |\n",
    "| **gnomAD (summary)** | Genomics           | Variant interpretation          | ⭐⭐                        | ✅         | Use as **reference knowledge** inside GenAI pipelines, not conversational source.                       |\n",
    "| **UK Biobank**       | Multimodal         | Prediction, CV                  | ⭐⭐                        | ⚠️        | Powerful but **governance-heavy**; not ideal for early GenAI deployments.                               |\n",
    "| **All of Us**        | Multimodal         | Prediction, NLP                 | ⭐⭐                        | ⚠️        | Suitable for **controlled cloud-based agents**, not on-prem or open RAG.                                |\n",
    "| **NIH Chest X-ray**  | Imaging            | CV                              | ⭐                         | ⚠️        | **Model training only** — do not use for assistant reasoning.                                           |\n",
    "| **CheXpert**         | Imaging            | CV                              | ⭐                         | ⚠️        | Benchmark dataset; **not assistant-ready**.                                                             |\n",
    "| **DeepLesion**       | Imaging            | CV                              | ⭐                         | ⚠️        | Detection-focused; **no GenAI value beyond vision models**.                                             |\n",
    "| **HCP**              | Neuroimaging       | CV, networks                    | ⭐                         | ⚠️        | Research neuroscience only.                                                                             |\n",
    "| **OpenNeuro**        | Imaging            | CV, signal ML                   | ⭐                         | ⚠️        | Open but **not clinically grounded for assistants**.                                                    |\n",
    "| **ADNI**             | Imaging + Clinical | Prediction                      | ⭐                         | ⚠️        | Aging-specific; **narrow agent applicability**.                                                         |\n",
    "| **BioASQ**           | NLP                | NLP, QA                         | ⭐⭐                        | ❌         | Good for **LLM benchmarking**, not real healthcare assistants.                                          |\n",
    "| **CORD-19**          | NLP                | NLP, RAG                        | ⭐⭐                        | ❌         | Fine for **literature agents**, not patient-facing or operational AI.                                   |\n",
    "\n",
    "---\n",
    "\n",
    "## Blunt Recommendations for GenAI & Agents\n",
    "\n",
    "### ✅ **Best Choices for AI Assistants / Agents**\n",
    "\n",
    "If your goal is **clinical, operational, or compliance-aware GenAI**:\n",
    "\n",
    "1. **MIMIC-IV** – gold standard for grounded clinical assistants\n",
    "2. **OMOP CDM** – mandatory if you want scalable, governed GenAI\n",
    "3. **PhysioNet** – for agents that reason over physiological state\n",
    "4. **HCUP** – for utilization, cost, and policy agents\n",
    "\n",
    "These datasets **support explainability, traceability, and auditability** — the three things GenAI dies without in regulated environments.\n",
    "\n",
    "---\n",
    "\n",
    "### ⚠️ **Use Carefully (Supporting Role Only)**\n",
    "\n",
    "* UK Biobank\n",
    "* All of Us\n",
    "* TCGA\n",
    "* gnomAD\n",
    "\n",
    "These are **excellent knowledge sources**, but:\n",
    "\n",
    "* heavy governance\n",
    "* not conversational by nature\n",
    "* best used as **retrieval or reference layers**, not chat corpora\n",
    "\n",
    "---\n",
    "\n",
    "### ❌ **Not GenAI-First (Despite Popularity)**\n",
    "\n",
    "* CORD-19\n",
    "* BioASQ\n",
    "* Imaging-only datasets\n",
    "\n",
    "These are **LLM evaluation or CV benchmarks**, not real-world assistant substrates. Using them for “clinical copilots” is how teams get shut down by IRBs.\n",
    "\n",
    "---\n",
    "\n",
    "## Strategic Bottom Line (Tell-it-like-it-is)\n",
    "\n",
    "If someone asks:\n",
    "\n",
    "> *“What dataset should we use to build a healthcare AI assistant?”*\n",
    "\n",
    "The honest answer is:\n",
    "\n",
    "> **MIMIC-IV + OMOP, or don’t pretend it’s production-grade.**\n",
    "\n",
    "Everything else is either:\n",
    "\n",
    "* a training set,\n",
    "* a benchmark,\n",
    "* or a reference library.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06fb3d6-bdcc-483a-ac85-d058dded291b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Unified Open Healthcare Dataset Reference Table\n",
    "\n",
    "**Legend**\n",
    "\n",
    "* **GenAI Suitability**: ⭐⭐⭐ Strong | ⭐⭐ Conditional | ⭐ Poor\n",
    "* **Fed / IRB**: ✅ Commonly approved | ⚠️ Restricted / DUA-heavy | ❌ Not suitable beyond research\n",
    "\n",
    "| Dataset                            | Link                                                                                                                                   | Primary Modality      | AI Use-Cases                    | GenAI / Agent Suitability | Fed / IRB | Blunt Recommendation                                                                           |\n",
    "| ---------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------- | --------------------- | ------------------------------- | ------------------------- | --------- | ---------------------------------------------------------------------------------------------- |\n",
    "| **MIMIC-IV**                       | [https://physionet.org/content/mimiciv/](https://physionet.org/content/mimiciv/)                                                       | EHR + Clinical Notes  | Prediction, NLP, RAG            | ⭐⭐⭐                       | ✅         | **Best single dataset for clinical AI assistants**; supports explainable, note-grounded GenAI. |\n",
    "| **eICU**                           | [https://physionet.org/content/eicu-crd/](https://physionet.org/content/eicu-crd/)                                                     | EHR                   | Prediction, cohort analysis     | ⭐⭐                        | ✅         | Strong for **predictive agents**; weaker for conversational assistants.                        |\n",
    "| **NIH Chest X-ray**                | [https://www.kaggle.com/datasets/nih-chest-xrays/data](https://www.kaggle.com/datasets/nih-chest-xrays/data)                           | Imaging               | CV                              | ⭐                         | ⚠️        | **Training benchmark only**; no GenAI reasoning value.                                         |\n",
    "| **TCGA**                           | [https://www.cancer.gov/ccg/research/genome-sequencing/tcga](https://www.cancer.gov/ccg/research/genome-sequencing/tcga)               | Genomics              | Prediction, biomarker discovery | ⭐⭐                        | ✅         | Excellent for **oncology/genomics expert agents**, not general assistants.                     |\n",
    "| **UK Biobank**                     | [https://www.ukbiobank.ac.uk/](https://www.ukbiobank.ac.uk/)                                                                           | Multimodal            | Prediction, CV, NLP             | ⭐⭐                        | ⚠️        | Extremely powerful but **governance-heavy**; not ideal for early GenAI.                        |\n",
    "| **PhysioNet**                      | [https://physionet.org/](https://physionet.org/)                                                                                       | Physiological Signals | Prediction, signal ML           | ⭐⭐                        | ✅         | Ideal as **real-time agent input** (monitoring, alerts), not standalone chat.                  |\n",
    "| **Human Connectome Project (HCP)** | [https://www.humanconnectome.org/](https://www.humanconnectome.org/)                                                                   | Neuroimaging          | CV, network analysis            | ⭐                         | ⚠️        | Research neuroscience only; **not assistant-ready**.                                           |\n",
    "| **BioASQ**                         | [http://bioasq.org/](http://bioasq.org/)                                                                                               | NLP                   | NLP, QA                         | ⭐⭐                        | ❌         | Useful for **LLM benchmarking**, not regulated assistants.                                     |\n",
    "| **CORD-19**                        | [https://allenai.org/data/cord-19](https://allenai.org/data/cord-19)                                                                   | NLP                   | NLP, RAG                        | ⭐⭐                        | ❌         | Good for **literature review agents**, not clinical or operational AI.                         |\n",
    "| **OpenNeuro**                      | [https://openneuro.org/](https://openneuro.org/)                                                                                       | Neuroimaging          | CV, signal ML                   | ⭐                         | ⚠️        | Open but **non-clinical**; limited GenAI relevance.                                            |\n",
    "| **HCUP**                           | [https://www.hcup-us.ahrq.gov/](https://www.hcup-us.ahrq.gov/)                                                                         | EHR / Claims          | Prediction, policy analysis     | ⭐⭐                        | ✅         | Best for **policy, utilization, and cost-analysis agents**.                                    |\n",
    "| **NSRR**                           | [https://sleepdata.org/](https://sleepdata.org/)                                                                                       | Physiological Signals | Prediction, signal ML           | ⭐⭐                        | ⚠️        | Strong for **sleep-specific agents**; narrow scope.                                            |\n",
    "| **CheXpert**                       | [https://stanfordmlgroup.github.io/competitions/chexpert/](https://stanfordmlgroup.github.io/competitions/chexpert/)                   | Imaging               | CV                              | ⭐                         | ⚠️        | Radiology benchmark; **no assistant reasoning value**.                                         |\n",
    "| **OMOP CDM (OHDSI)**               | [https://www.ohdsi.org/data-standardization/the-common-data-model/](https://www.ohdsi.org/data-standardization/the-common-data-model/) | Data Model            | RAG (schema), Prediction        | ⭐⭐⭐                       | ✅         | **Foundational for governed GenAI**; enables interoperability and auditability.                |\n",
    "| **gnomAD**                         | [https://gnomad.broadinstitute.org/](https://gnomad.broadinstitute.org/)                                                               | Genomics              | Variant interpretation          | ⭐⭐                        | ✅         | Use as **reference knowledge**, not conversational corpus.                                     |\n",
    "| **ADNI**                           | [https://adni.loni.usc.edu/](https://adni.loni.usc.edu/)                                                                               | Imaging + Clinical    | Prediction                      | ⭐                         | ⚠️        | Alzheimer’s-specific; limited general agent utility.                                           |\n",
    "| **All of Us**                      | [https://allofus.nih.gov/](https://allofus.nih.gov/)                                                                                   | Multimodal            | Prediction, NLP                 | ⭐⭐                        | ⚠️        | Suitable for **cloud-restricted GenAI**, not open or on-prem assistants.                       |\n",
    "| **DeepLesion**                     | [https://nihcc.app.box.com/v/DeepLesion](https://nihcc.app.box.com/v/DeepLesion)                                                       | Imaging               | CV                              | ⭐                         | ⚠️        | Detection-focused CV dataset; **not GenAI-first**.                                             |\n",
    "\n",
    "---\n",
    "\n",
    "## Executive Bottom Line (Tell-It-Like-It-Is)\n",
    "\n",
    "If your goal is **GenAI, AI Assistants, or Agents in healthcare**:\n",
    "\n",
    "* **Start with**: **MIMIC-IV + OMOP**\n",
    "* **Augment with**: PhysioNet, HCUP, TCGA (use-case specific)\n",
    "* **Treat imaging datasets as model-training inputs only**\n",
    "* **Do not claim “clinical assistants”** if your data is BioASQ or CORD-19 — reviewers and IRBs will shut it down immediately\n",
    "\n",
    "This table is already at the level where it can drive:\n",
    "\n",
    "* dataset selection policy\n",
    "* GenAI architecture decisions\n",
    "* IRB conversations\n",
    "* Fed / VA / NIH governance reviews\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40807f49-7f06-4d71-a3d0-ace9b0cdb226",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
