{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b669b815-cf4b-4061-a20e-13a64110ba13",
   "metadata": {},
   "source": [
    "# Set up your environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deedde1-147e-41de-a6b1-33ba720e7774",
   "metadata": {},
   "source": [
    "Let's use a `.env` file and the `dotenv` library. This allows you to keep your API key secure and separated from your code.\n",
    "\n",
    "Hereâ€™s how you can setup to load the OpenAI API key using a `.env` file:\n",
    "\n",
    "### Step 1: Install Dependencies\n",
    "Make sure you have `python-dotenv` installed if you're using `.env` files:\n",
    "```bash\n",
    "pip install python-dotenv\n",
    "```\n",
    "\n",
    "### Step 2: Create a `.env` File\n",
    "In your project directory, create a `.env` file with the following content:\n",
    "```\n",
    "OPENAI_API_KEY=your-api-key-here\n",
    "```\n",
    "\n",
    "### Step 3: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94a134a4-878c-4270-a8b1-ca214909e237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Function to load environment variables or raise an error if not found\n",
    "def get_env_var(var: str):\n",
    "    value = os.getenv(var)\n",
    "    if value is None:\n",
    "        raise ValueError(f\"{var} not found in environment variables. Make sure it is set in your .env file.\")\n",
    "    return value\n",
    "\n",
    "# Load API keys from the environment \n",
    "openai_api_key = get_env_var(\"OPENAI_API_KEY\")\n",
    "tavily_api_key = get_env_var(\"TAVILY_API_KEY\")\n",
    "\n",
    "# Now, you can use the keys in our setup as needed\n",
    "from langchain_openai import ChatOpenAI\n",
    "gpt4o_chat = ChatOpenAI(model=\"gpt-4o\", temperature=0, openai_api_key=openai_api_key)\n",
    "gpt35_chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aaa1a2c-ea45-4552-9075-198123903ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 11, 'total_tokens': 20, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_e375328146', 'finish_reason': 'stop', 'logprobs': None}, id='run-16722a96-9796-468a-8b1e-8e388edba9b5-0', usage_metadata={'input_tokens': 11, 'output_tokens': 9, 'total_tokens': 20})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Create a message\n",
    "msg = HumanMessage(content=\"Hello world\", name=\"Lance\")\n",
    "\n",
    "# Message list\n",
    "messages = [msg]\n",
    "\n",
    "# Invoke the model with a list of messages \n",
    "gpt4o_chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1acfc41-e0cc-404a-8c4e-c107b18884bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 9, 'total_tokens': 18, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_3537616b13', 'finish_reason': 'stop', 'logprobs': None}, id='run-a7c19b00-e391-46d7-a459-07b9ff02812d-0', usage_metadata={'input_tokens': 9, 'output_tokens': 9, 'total_tokens': 18})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt4o_chat.invoke(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93bcdd11-9a59-4e39-8daf-cdff98ec116c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 9, 'total_tokens': 18, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-90a6694a-76b6-4781-b6f7-36c0e786d2d1-0', usage_metadata={'input_tokens': 9, 'output_tokens': 9, 'total_tokens': 18})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt35_chat.invoke(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf97e30f-a1ab-41c1-80f2-c5fd729a495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Tavily using the API key from the environment\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tavily_search = TavilySearchResults(max_results=3, api_key=tavily_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a31011e-cffb-4c8d-8482-b0b70d94771f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.langchain.com/langgraph',\n",
       "  'content': 'LangGraph is a stateful, orchestration framework that brings added control to agent workflows. LangGraph Cloud is a service for deploying and scaling LangGraph applications, with a built-in Studio for prototyping, debugging, and sharing LangGraph applications.'},\n",
       " {'url': 'https://www.datacamp.com/tutorial/langgraph-tutorial',\n",
       "  'content': 'LangGraph is a library within the LangChain ecosystem designed to tackle these challenges head-on. LangGraph provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner. It simplifies the development process by enabling the creation of cyclical graphs, which are essential for developing ...'},\n",
       " {'url': 'https://towardsdatascience.com/from-basics-to-advanced-exploring-langgraph-e8c1cf4db787',\n",
       "  'content': \"LangGraph is a low-level framework that offers extensive customisation options, allowing you to build precisely what you need. Since LangGraph is built on top of LangChain, it's seamlessly integrated into its ecosystem, making it easy to leverage existing tools and components. However, there are areas where LangGrpah could be improved:\"}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform a search with Tavily\n",
    "search_docs = tavily_search.invoke(\"What is LangGraph?\")\n",
    "search_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e728807-c67c-4044-a446-966349125272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
