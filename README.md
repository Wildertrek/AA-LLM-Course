# AA-LLM-Course


**Course Title: Advanced Applications of Large Language Models (LLMs)**

**Course Level: 650**

**Abstract:**

This advanced course offers a deep dive into the mechanisms and applications of Large Language Models (LLMs), tailored for students to independently develop and refine their skills in cutting-edge AI technologies. Throughout the semester, participants will engage in a series of individual projects that encompass prompt engineering, retrieval-augmented generation (RAG), fine-tuning techniques, and the creation of an interactive LLM-based agent.

The curriculum is designed to build a robust understanding of the theoretical underpinnings of LLMs, including transformer architectures and attention mechanisms, while also emphasizing practical skills in data preparation, model training, and deployment strategies. Students will explore how to enhance LLM outputs through sophisticated prompt design, integrate external knowledge using RAG systems, adapt LLMs to specialized tasks with fine-tuning, and develop functional LLM-based agents for real-world applications.

Each project is structured to challenge students to apply classroom knowledge to solve complex problems, fostering skills in AI project management and ethical AI deployment. By the end of the course, students will not only have a comprehensive grasp of LLM capabilities but will also be prepared to implement these models effectively and responsibly in various professional settings. This course is ideal for graduate students aiming to specialize in the dynamic field of language models, providing a foundation for both academic research and industry application.


**Course Structure for Advanced Applications of Large Language Models (LLMs)**

**Course Number: COSC 650**
**Semester: Fall 2024**
**Credit Hours: 3**
**Instructor: Dr. Jens Gregor, Joseph Raetano**


**Course Description:**
This course immerses students in the practical and theoretical aspects of Large Language Models (LLMs), through individual projects focused on prompt engineering, retrieval-augmented generation (RAG), fine-tuning techniques, and the creation of an LLM-based agent.

**Course Objectives:**
- Develop a deep understanding of LLMs through comprehensive individual projects.
- Apply theoretical knowledge to design, implement, and optimize LLMs for specific tasks.
- Explore and address ethical considerations and the societal impacts of deploying LLMs.

**Weekly Breakdown and Project Integration:**

**Week 1-2: Introduction and Fundamentals**
- **Learning:** Overview of LLMs, architecture of transformers, basics of tokenization and attention mechanisms and a survey of the families of LLMs. Overview of the various techniques for advanced applications using LLMs(Prompt Engineering, Fine Tuning, RAG, Agents).

- **Project Planning:** Introduction to the four projects, understanding project scopes, setting individual objectives.

**Week 3-4: Prompt Engineering with Function Calling**

**Learning:**
- Mastering prompt design to effectively guide LLM outputs.
- Introduction to **function calling** in LLMs: how to use prompts to dynamically call functions, APIs, and retrieve structured data (e.g., through OpenAI function calling or similar frameworks).
- Understanding how function calling can enhance LLMs' ability to provide accurate and actionable responses by interacting with external systems or services.

**Project 1 - Prompt Engineering with Function Calling:**
- **Objective:** Independently design and refine prompts to achieve desired responses from an LLM. Incorporate function calling into the prompt design to enable real-time interaction with APIs or custom functions (e.g., retrieving external data, performing calculations, or generating structured outputs).
- **Deliverable:** Demonstrate the application of prompt engineering with function calling to solve a practical problem, such as dynamically fetching information from a database or executing complex tasks based on user input.

**Week 5-6: Retrieval Augmented Generation (RAG)**
- **Learning:** Implementing RAG to supplement LLMs with external data.
- **Project 2 - RAG:** Build and fine-tune a retrieval system to improve the information richness of LLM responses.

**Week 7-8: Fine Tuning Techniques**
- **Learning:** Techniques for fine-tuning LLMs to specialized tasks or domains.
- **Project 3 - Fine Tuning:** Conduct fine-tuning on a pre-trained LLM for a selected domain, using a curated dataset.

**Week 9-10: Creating an LLM-Based Agent**
- **Learning:** Developing interactive agents powered by LLMs.
- **Project 4 - LLM-Based Agent:** Create an interactive, task-oriented agent using LLM technology.

**Week 11: Midterm Review and Feedback**
- **Presentation:** Individual presentations on the progress and challenges of Projects 1 and 2.
- **Feedback:** Receive detailed feedback from peers and the instructor to refine projects.

**Week 12-13: Advanced Integration and Applications**
- **Learning:** Advanced techniques for integrating LLMs with other AI systems, discussing ethical deployments.
- **Project Continuation:** Apply feedback and advanced insights to further develop and refine Projects 3 and 4.

**Week 14: Final Project Preparation**
- **Finalization:** Complete all projects, focusing on robust documentation and preparing for final presentations.
- **Review:** Opportunity for individual consultation with the instructor to ensure project completion and readiness for presentation.

**Week 15: Final Project Presentations**
- **Presentation:** Showcase final outcomes and solutions for all projects.
- **Evaluation:** Projects evaluated on technical merit, innovation, application of learned material, and presentation quality.

**Assessment Methods:**
- Projects 1-4: Each project 15% (Total 60%)
- Participation and Weekly Assignments: 10%
- Peer Reviews and Interaction: 10%
- Final Presentations: 20%

**Textbooks and Resources:**
- Primary Textbook: *Advanced Techniques in Large Language Models* by B. Scholar.
- Supplementary materials including research articles, online courses, and tutorials.

**Software and Tools:**
- Programming languages: Python
- AI frameworks: TensorFlow, PyTorch, OpenAI
- Cloud services and AI platforms: Azure, OpenSource

This course structure is designed to empower students to tackle complex projects independently, enhancing their problem-solving skills and understanding of LLMs in diverse applications.